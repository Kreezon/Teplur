IEEE,DOI,NAME OF JOURNAL,PUBLICATION YEAR,LEVEL
"Model of group data sharing according to the structure of the SBIBD is constructed. In this paper, a group data sharing model is established based on the definition of the SBIBD, which can be used to determine the way of communication among the participants. Regarding mathematical descriptions of the structure of the SBIBD, general formulas for computing the common conference key for multiple participants are derived",https://doi.org/10.1109/TDSC.2017.2725953,Block Design-Based Key Agreement for Group Data Sharing in Cloud Computing,12 July 2017,0
"Healthcare is a data-intensive domain where a large amount of data is created, disseminated, stored, and accessed daily. For example, data is created when a patient undergoes some tests (e.g. computerized tomography or computerized axial tomography scans), and the data will need to be disseminated to the radiographer and then a physician",https://doi.org/10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"The current Cloud Computing services are based on the “data center” approach, where hundreds of thousands of dedicated servers are setup to give the services. Setting up the data center for cloud is expensive and running the infrastructure needs expertise as well as a lot of resources such as high power for cooling, redundant power for assured availability, etc.",https://doi.org/10.1109/CLOUD.2017.99,"A ""No Data Center"" Solution to Cloud Computing",11 September 2017,0
"Based on simulation results, CBS saves costs of running workloads by 55% and 12% compared with costs of cloud sourcing and private cloud, respectively. It also improves resource utilization (89%) by judiciously activating/leasing resources.",https://doi.org/10.1109/CLOUD.2017.112,Cloud Bursting Scheduler for Cost Efficiency,11 September 2017,0
"In achieving these goals, we tried to establish a Eucalyptus [5] based private cloud on our already existing cluster resources. We have developed several customized machine images that can be used in solving problems from mobile web services, distributed computing and bio-informatics domains.",https://doi.org/10.1109/CCGRID.2010.56,SciCloud: Scientific Computing on the Cloud,24 June 2010,0
"Most literatures address those uncertainties and challenges from the technological perspective but few from managerial one. The goal of this paper is to identify the key consideration factors of adopting cloud computing for science and explore the interrelationship among these factors through the works of in-depth interview, survey, and scientific data analysis.",https://doi.org/10.1109/CloudCom.2012.6427610,Key consideration factors of adopting cloud computing for science,4 February 2013,0
"Lack of trust: Does not assume a level of trust exists between an end-user and the infrastructure provider; a relationship that currently exists between end-users, clouds, clusters and Grids.",https://doi.org/10.1109/CLOUD.2015.153,Ad Hoc Cloud Computing,20 August 2015,0
"A global 2000 company or a government agency typically has more than 5,000 applications on legacy platforms. These applications are placed into categories: ones that should move to the cloud and ones that should not. If they move to the cloud, then do they need to be altered to leverage cloud-native features (refactoring), or they could be moved with few or no changes (lift and shift)?",10.1109/MCC.2017.4250932,"Cloud-Native Applications and Cloud Migration: The Good, the Bad, and the Points Between",1 December 2017,0
"One of the potential business drivers for an edge marketplace using Internet of Things (IoT) devices, edge-computing resources, and data science is an enhanced ability to make quicker and better decisions. For example, the reduction in cost and increase in uptake of IoT-based environmental monitoring1 provides the potential for city managers to augment their decision making both on an operational front using real-time data and analytics and on a strategic front through access to multiple historic observations across multiple sectors.2",10.1109/MCC.2018.064181115,Realizing Edge Marketplaces: Challenges and Opportunities,29 November 2018,0
"Abicloud is a cloud computing platform developed by Abiquo, a company locates in Barcelona Spain that is mainly focused on the development of cloud platform. It can be used to build, integrate and manage public as well as private cloud in the homogeneous environments",https://doi.org/10.1109/ISISE.2009.94,Comparison of Several Cloud Computing Platforms,15 April 2010,0
"As an example, at Netflix there is an internal microservice that acts as a generic key-value store, and is used by other microservices. This store is not considered a critical service. We ran a chaos experiment where we intentionally injected latency for a small fraction of traffic so that calls to this service would exceed their timeouts and trigger fallback behavior. This experiment led to an unexpected increase in errors in a service that determines which content delivery network URLs to return to client devices, which is critical to video streaming. The exposed vulnerability was eliminated by adjusting timeout thresholds.",10.1109/MCC.2018.032591616,The Business Case for Chaos Engineering,12 June 2018,0
"Grid based and/or web based scientific workflow tools are used for bioinformatics related complex research to make scientists' and researchers' work easier. On average, scientists spend about 80% of their time assembling data to prepare for analysis. This is due largely in part to the fact that many of these resources required for data processing must be gathered from an external source.",https://doi.org/10.1109/CLOUD.2010.80,Cloud Computing Infrastructure for Biological Echo-Systems,26 August 2010,0
"So, what's the bottom line with artificial intelligence and the cloud? Most big-budget IT shops in the late 1980s learned the expensive way that not all AI applications that can be applied should be applied. Now that cloud providers' offer artificial intelligence services within their public clouds, AI is within reach of most enterprise budgets. It's time for a new round of lessons. However, enterprises that look for applications for this technology can, in some cases, find game changers for the business. There is actual value there for businesses, if correctly applied.",10.1109/MCC.2018.1081067,Making Sense of AI in Public Clouds,31 December 2017,0
"Resource utilization is becoming an important issue. Statistics show that only 10% of computer resources (CPU, RAM, Storage, Power, and Network) are being utilized, and the other 90% of computers resources are wasted, assuming that computers are run 24 hours, 7 days a week.",https://doi.org/10.1109/CCAA.2015.7148478,Virtual computing lab (VCL) open cloud deployment,6 July 2015,0
"In general, organizations have maximum flexibility in how risk assessments are conducted. Because risk assessments facilitate decision making at all three tiers (organization level, mission/business process level, and information system level), they're key processes of effective risk management and in maintaining the residual risk below the threshold, and therefore the methods employed to assess the risks are of crucial importance. We recommend reading NIST SP 800–30, Guide for Conducting Risk Assessment, which provides quantitative, qualitative, or semiqualitative methods that use scores or levels, respectively.7",10.1109/MCC.2015.122,Managing Risk in a Cloud Ecosystem,2 February 2016,0
"Cloud computing is a product of both inherited and learned characteristics. It blends conventional definitions of resources with innovative usage patterns and solutions to facilitate user access to ever more powerful hybrid systems and introspective data. Cloud computing characteristics, service models, and deployment models are well documented, and hopefully well understood. Less apparent are the key trends shaping hybrid cloud computing: where they come from, what they're driven by, how they interact, whom they impact, and why they're important to understand.",10.1109/MCC.2016.21,The Hybrid Cloud Security Professional,26 February 2016,0
"The cloud computing architecture consists of different deployment models and service delivery models. The types of cloud deployment models are public cloud, private cloud and hybrid cloud. The type depends on the environment the cloud is deployed. The public cloud is accessible to every user, as it does take into consideration the affiliation of user to any specific organization. The private cloud is can be used only by members or users of any particular organization. The hybrid cloud presents the mixture where both public and private cloud is available for use. The service delivery models are classified on basis of type of service delivered to users.",https://doi.org/10.1109/I-SMAC47947.2019.9032545,"A Survey of Cloud Computing Security Challenges, Issues and their Countermeasures",12 March 2020,0
"Such a tremendous boost for innovation in manufacturing arises from the current economic environment, which is extremely volatile and globalized. Enterprises need to rapidly respond to changing or uncertain market demands, provide customized products and services, and compete at the international level by targeting multiple potential markets around the world. Enterprises are deemed successful if they can provide a wide variety of high-quality products while keeping manufacturing and distribution costs low to meet customer expectations and needs. Moreover, the contemporary need to target multiple markets in different countries requires enterprises to expand their production capability by setting up multiple manufacturing sites around the world.",10.1109/MCC.2016.79,"Cloud Manufacturing: Security, Privacy, and Forensic Concerns",19 September 2016,0
"Because of the huge number of interconnected servers in a DC, scalability is a major issue. Treestructured DC architectures, such as ThreeTier, VL2, and FatTree, offer low scalability. Such DC architectures are capped by the number of network switch ports. Server-centric architectures, such as DCell and FiConn, and freely/randomly connected architectures, such as JellyFish and Scafida, offer high sculability.[2]",10.1109/MCC.2014.26,Trends and challenges in cloud datacenters,10 July 2014,0
"Salman et al., describes a fog computing architecture for integrating Mobile Edge Computing (MEC) with IoT and SDNs (Software Defined Networks)3. The examined architecture highlights Device, Network, Control and Application Layers that undertake different tasks for the orchestration of the offered fog services. However, this work only presents some conceptual information regarding fog architectures and for a particular use case. Another SDN-based fog computing approach is proposed, a “fog node”, which is an edge switch integrated with the SDN-Controller and is capable of acting as an MQTT broker, serving as a platform for data analytics and communicating with other “fog nodes” or with the end-host broker server4.",10.1109/MCC.2017.25,A Cooperative Fog Approach for Effective Workload Balancing,26 April 2017,0
"Certainly, cloud computing offers many attractive benefits to enterprises. The cloud model moves IT infrastructure from an upfront capital expense to an operational one. Companies can use the cloud for large batch-oriented tasks – those involving large spikes in requirements for processing power – that otherwise would be out of reach or require huge investment. Many enterprises provision computing resources for peak loads, which often exceed average use by a factor of 2 to 10.",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"The small applications have a high degree of internal cohesion around a single task and can cope with a simple responsibility. Here, we consider “responsibility” as doing (or being responsible for) one activity only. The activity can include serving or representing a particular resource. Practical examples include logging incoming messages within a database or a file, or managing a message queue by taking, processing, and discarding queued messages. Such a concept started within the industrial practice of splitting large monolithic applications into small cooperating pieces to improve their maintainability, scalability, and testability. Microservice architectures are receiving increasing focus, as evidenced by search statistics on Google Trends.2 Academia's interest in microservices is also evidenced by the publication of the first mature academic book in 2015.3",10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
"As noted in the previous installment of “Blue Skies” and shown in Figure 1, IoT devices can be sensors, mobile phones, radio frequency identification, actuators (such as machines/equipment fitted with sensors and deployed for mining, oil exploration, or manufacturing operations), lab instruments, and smart consumer appliances (TV, phone, and so on).5, 6 Social media, clickstreams, and business transactions are also workloads in IoT.",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
"Cloud computing offers new solutions for computational intensive applications, which are traditionally ran on HPC systems. For example, Amazon [1] and Microsoft Azure [2] offer almost unlimited computing and storage resources that can be configured and provisioned on demand as virtual parallel clusters. Research communities can easily use such cloud resources, for computational intensive applications [7].",https://doi.org/10.1109/CCGrid.2012.80,A Fault Tolerance Framework for High Performance Computing in Cloud,14 June 2012,0
"As cloud computing becomes an increasingly dominant means of providing computing resources, the legal and regulatory issues associated with data in the cloud become more pronounced. These issues derive primarily from four areas: contract, data protection, law enforcement, and regulatory and common law protections for particularly sensitive domains such as health, finance, fiduciary relations, and intellectual property assets. From a technical perspective, these legal requirements all impose information management obligations on data sharing and transmission within cloud-hosted applications and services. They might restrict how, when, where, and by whom data may flow and be accessed. These issues must be managed not only between applications, but also through the entire, potentially global, cloud supply chain.",10.1109/MCC.2015.69,Data Flow Management and Compliance in Cloud Computing,16 September 2015,0
"On Sunday, September 20, 2015 Amazon Web Service (AWS) experienced a significant outage. With an increasing number of companies running mission critical workloads, even their core customer facing services on AWS, such an outage can subsequently result in far reaching system outages. In this instance, Netflix, Airbnb, Nest, IMDb, and more all experienced down time, impacting their customers and ultimately their business's bottom lines. The core outage lasted more than 5 hours (or even beyond, depending on how you count), with even longer AWS customer downtimes before they had their systems fully functional.",10.1109/MCC.2017.4250927,Realizing Software Reliability in the Face of Infrastructure Instability,1 December 2017,0
"Collected and analyzed data from selected institutions, to understand the computing environment and identify requirements for establishing eco-efficient cloud computing solutions for HLIT.",https://doi.org/10.1109/SCAT.2014.7055151,Road map towards eco-efficient cloud computing adoption in higher learning institutions in Tanzania,5 March 2015,0
"Some might argue that distributed ledgers can entirely replace physical tags and labels, but we believe that there is an overlap between these technologies. There are definitely situations in which human- or machine-readable labels are valuable, or even essential. With the addition of a digital signature and incorporation of that signature into a blockchain, such tags can be checked easily with respect to their authenticity and uniqueness. Counterfeit parts can be excluded, and accidental duplications eliminated, through this method. Such approaches can also be applied to any sort of record management to ensure tamper resistance and authenticity of business records.3",10.1109/MCC.2017.3791019,Blockchain Standards for Compliance and Trust,12 October 2017,0
"Cloud Computing is a new model which is use to make, computer resources for a service to end users, available over the internet. Different types of definitions for the cloud computing exist in the community of users but it is the service of hardware and software over the network which will fulfil the user requirement and cost is to be paid according to the usage of the service. It reduces the costs and complexity of managing the hardware and software resources.",https://doi.org/10.1109/I2CT.2018.8529806,Approaches for Detection of Digital Evidence in Cloud Computing Environment,11 November 2018,0
"This paper discusses the problem of resource allocation considering the hierarchical infrastructure composed of edge capacity and cloud data centers, analyzing application classes along with different scheduling policies. To address this challenge, we introduce a number of scheduling approaches that consider user mobility and edge computing capacity, in the context of a Fog Computing infrastructure.1 We discuss the benefits of combining the application classes with scheduling policies in scenarios that illustrate these scheduling approaches, especially in the context of user mobility.",10.1109/MCC.2017.27,Mobility-Aware Application Scheduling in Fog Computing,26 April 2017,0
"Privacy is a key issue in cloud computing. In general, privacy is about the accountability of a cloud provider to customer, as well as the transparency to cloud provider's practice around personal data/information. Cloud computing is a rising technology in the field of Information Technology. Therefore, it is of preeminent importance to deal with issues and challenges of privacy. Offending and violation of privacy not only affects users but also cloud service provider because it maculates their credibility with customers. The concept of privacy varies widely among countries and jurisdictions.",https://doi.org/10.1109/CSNT.2015.141,Efficient Framework Approach to Extract Privacy Issues in Cloud Computing,1 October 2015,0
"National Institute of Standards and Technology has defined cloud computing as a model which has convenient on-demand network access for sharing hardware and software resources [1][5]. Expenditure towards IT infrastructure is very less for cloud computing which is making it popular for many users. Services for cloud is available at any place on-line. Amazon, Google, IBM, Microsoft are some of the cloud providers.",https://doi.org/10.1109/CUBE.2013.20,Designing of Cryptography Based Security System for Cloud Computing,9 January 2014,0
"In this paper, by considering the aforementioned limitations of current solutions for resource-limited smart devices, we propose a lightweight cryptographic scheme so that IoT smart devices can share data with others at the edge of cloud-assisted IoT wherein all security-oriented operations are offloaded to nearby edge servers. Furthermore, although initially we focus on data-sharing security, we also propose a data-searching scheme to search desired data/shared data by authorized users on storage where all data are in encrypted form. Finally, security and performance analysis shows that our proposed scheme is efficient and reduces the computation and communication overhead of all entities that are used in our scheme.",10.1109/MCC.2017.9,Secure Data Sharing and Searching at the Edge of Cloud-Assisted Internet of Things,15 March 2017,0
"Advances in hybrid high-end computing—processing capabilities offered by a combination of central processing unit (CPU) and graphics processing unit (GPU)—and cloud computing have fueled the deployment and adoption of machine learning technology that powers many aspects of modern society, from social media to recommendation systems on websitcs.1, 2 Deep learning is one such branch of machine learning that “achieves great power and flexibility by learning to represent the knowledge as nested hierarchy of concepts, with each concept defined in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones.”3",10.1109/MCC.2018.1081070,Deep Osmosis: Holistic Distributed Deep Learning in Osmotic Computing,31 December 2017,0
"The intelligent vehicle provides extension to entertainment services, access to Internet, and other similar services to the users. The powerful on-board devices also support new applications, including location-specific services, online gaming and various forms of mobile infotainment [3]. The need of using third-party applications in vehicle is high but it has been noticed that the on-board computing abilities present in the vehicles not be utilized efficiently by the applications.",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"Hypervisor-based resource virtualization (such as that used by Citrix and VMware) is a key concept in cloud computing. Hypervisor-based virtualization enables cloud providers to create unique virtual machines (VMs) that share a set of physical hardware resources (CPU, memory, network, and disk). Each VM executes distinct operating system instances (ranging from proprietary to open source), which supports fault-tolerant and isolated security context behavior.",10.1109/MCC.2016.112,Open Issues in Scheduling Microservices in the Cloud,11 November 2016,0
"One of the latest developments in cloud computing is usually called “serverless” computing, even though, of course, servers are still where processing takes place. For example, Amazon Web Services (AWS) offers “Lambda Functions,”1 Google has “Cloud Functions.”2 and Microsoft has “Azure Functions”.3 They differ in various ways; for example, Azure and IBM Bluemix “OpenWhisk”4 functions can run in a private or public cloud.",https://doi.org/10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"Cloud computing, as a new computing paradigm, provides customers with variety of on-demand and flexible services, such as infrastructure, platform and software, with the help of Internet. Cloud computing can significantly reduce costs and improve efficiency [3]. One thing to be noted is that only allowing users to have a convenient and quick access to the cloud anywhere and anytime, can cloud computing fully exert its advantages.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"Cloud has become the predecessor of Grid computing which has made a major breakthrough in the field of distributed computing. Cloud uses virtualization technology to efficiently use the underlying resources to serve the customers. Cloud service providers offer services in three standard forms as Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). Cloud considers four standard models as Public Cloud, Private Cloud, Hybrid Cloud, and Community Cloud for servicing its customers. They offer services like computing, storage, IoT, Machine Learning and many numerous amounts of services on-demand for low cost. Cloud can be thought of as a pool of infinite resources",https://doi.org/10.1109/SmartCloud49737.2020.00015,An Efficient Task Scheduling Algorithm using Total Resource Execution Time Aware Algorithm in Cloud Computing,27 November 2020,0
"Cloud comuting [9] is a kind of computing platform distributed in large-scale data center, which meets the needs of scientific research and e-commerce by dynamically providing several kinds of server resources. It can be viewed as the evolution of distributed computing, parallel computing and grid computing and so on. Cloud computing platform use the virtualizaton technology to dynamically and transparently supply virtual computing and storage resources to satisfy user's different requirements according to the relative scheduling strategy.",https://doi.org/10.1109/APWCS.2010.15,A New Architecture of Online Trading Platform Based on Cloud Computing,7 June 2010,0
"Cloud computing offers several benefits for enterprises. The cloud frees organisations from having to set up an IT infrastructure and allows them to rent resources and pay only for the services they use [3]. This can reduce costs and save a lot of money for both small and large enterprises. In addition, cloud computing increases flexibility and offers an attractive opportunity for enterprises to grow [4]. However, some organisations still concerns about the idea of shifting a present system to the cloud.",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
Public Clouds are provided by a designated service provider and may offer either a single-tenant (dedicated) or multi-tenant (shared) operating environment with all the benefits and functionality of elasticity and the accountability/utility model of Cloud.,https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"The methods and means of protection used to date are imperfect and are not able to fully satisfy the growing requirements for the safety of information and computing systems, and approaches to ensuring reliability and stability, which are reduced to reconfiguration, N-cut reservation or restoration of the system, are not able to prevent possible catastrophic consequences in the event of such threats [6].",https://doi.org/10.1109/SCM58628.2023.10159053,Model of a Self-Healing Computing Process of a Cloud Computing System under Conditions of Information and Technical Impacts,26 June 2023,0
"Cloud computing provide infrastructure as a service. Service provider offers control over different resources and appications to the organizations. Resources inccludes storage devices, hardware, servers, networking components and any more.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"Under EU and US data protection laws, organizations are fully responsible for sensitive information, such as their customers' and employees' personal data. They must guarantee data security even when a third party, such as a cloud provider, processes the data on their behalf. For this reason, data security has become an important consideration in any cloud provisioning arrangement. Data owners increasingly require that outsourcing contracts specify all details of the cloud providers' security procedures, including cloud-based cryptographic services. Still, many cloud users aren't prepared to trust cloud-based cryptographic services. Standardization bodies and security agencies worldwide are aware of this situation; the US National Institute of Standards and Technology (NIST) has even released a study discussing open issues and challenges in the management of cryptographic keys over the cloud.1",10.1109/MCC.2016.89,Securing Cryptographic Keys in the Cloud: A Survey,19 September 2016,0
"The proliferation of cloud computing has revolutionized hosting and delivery of Internet-based application services. In the standard cloud application deployment approach, an application is architected to be deployed and managed over a single datacenter (for example, Amazon or GoGrid). Such an approach has several shortcomings. Datacenter failure can leave thousands of application users without access to essential (and in some cases paid) services. Moreover, exploiting a single datacenter makes it extremely difficult to exploit location-based placement of data and processing driven by geolocation of application users.",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"In addition to fire safety systems, commercial and public buildings must have fire wardens on hand to coordinate the building evacuation in the event of a fire by assisting evacuees, using firefighting and suppression equipment, and relaying information to first responders. Extensive domain analysis, including a literature review and consultancy with a fire safety instructor, yielded the following summary of fire warden duties:",10.1109/MCC.2014.67,A Cloud-Enabled Building and Fire Emergency Evacuation Application,30 November 2014,0
"The dimensions of our attack taxonomy follow the natural flow of an attack on a cloud service (see Figure 1). The taxonomy's top level comprises five dimensions: source, vector, target, impact, and defense. For example, in a security incident, identifying the attack's source or the attacker will facilitate our understanding of the taxonomy's second level: context, motivation, opportunities, and skill level.",10.1109/MCC.2015.2,Cloud Attack and Risk Assessment Taxonomy,22 April 2015,0
"The cloud is also associated with other benefits, such as accelerated time to market and time to volume, and business agility and elasticity. However, these also directly correlate to revenue growth. Reducing time to market implies generating first-mover advantage, which in today's world can imply signing up sticky customers and ecosystem partners before someone else does. It also can imply gaining a larger share of the profit pool before it dissipates later in the product lifecycle across a sea of competitors. Resource elasticity helps revenue-generating services scale, ensuring revenue is maximized to the extent the market will allow. Finally, the concept of “business agility” can be a bit amorphous, but it generally refers to the ability to rapidly respond to shifts in market dynamics, customer needs, or competitor moves. While a portion of these benefits surely accrues to cost reduction, a majority generally is realized as enhanced revenue.",10.1109/MCC.2018.043221018,Revenue Growth is the Primary Benefit of the Cloud,14 August 2018,0
"The challenge associated with private cloud implementations is that, despite the perimeter solutions available to protect the enterprise, the typical organization is still unable to stop attacks such as advanced persistent threats (APTs) from the Internet. In addition, complex policy-based decisions made over long periods of time to allow a multitude of enterprise services and approved exceptions through the corporate firewall, combined with the increasingly common method of bypassing the perimeter using mobile devices, have rendered the enterprise perimeter essentially useless from an advanced threat perspective.[2]",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"The first driver is the loaded unit cost of a company's IT relative to the offered unit price of the cloud service provider. The cost structure for public cloud service providers might be better, but additional components can increase the offered price, such as a provider's profit, underutilized resources, taxes, and sales, general, and administrative expenses. If a company's IT shop is not cost-optimized or can't achieve scale and high utilization, the cloud might well offer a cost advantage, but for well-run organizations, the unit costs for public cloud services might actually be higher.",10.1109/MCC.2014.91,The Nuances of Cloud Economics,30 November 2014,0
"Existing streaming data analysis platforms including (e.g., Spark6, Heron7, Google Dataflow8, AWS, Kinesis1, StreamCloud, Apache Storm), are CDC-centric, hence they do not meet the resource management and scheduling requirements for IoT workflows that require coordinated mapping for data analysis activities to both CDC and EDC. Many workflow application management platforms such as Pegasus, Tri-ana, Taverna, Galaxy, e-Science Central, and Kepler support the development, deployment and execution of scientific workflow applications on CDC without considering newly evolved EDC capabilities. Apache Oozie and Linkedin Azkaban support a Hadoop workflow, but in a rather rigid manner that works well for only batch processing activities. Data analytics platforms such as YARN, Mesos Amazon IoT and Google Cloud Dataflow can support manual provisioning of multiple data transformation tasks on CDC resources, but only in a performance-agnostic way.",10.1109/MCC.2017.22,Osmotic Flow: Osmotic Computing + IoT Workflow,26 April 2017,0
"This disadvantage is a critical obstacle when building any cloud-assisted IoT system. Moreover, overcoming these security challenges is a big problem due to the versatile functions of cloud-assisted IoT systems and the versatile security requirements of users. Unlike the security of traditional IoT,3 this type of problem cannot be perfectly solved in a short time period. Normally, a trust-based system is applied as a solution to those risks. However, trust-based systems cannot provide provable security, which lowers the IoT security level. Similarly, in IoT scenarios, it is not practical to apply data anonymization and obfuscation4 to guarantee security for dynamic operations (insertion or deletion,) especially when merging with the cloud, since they are applied for privacy preservation without provable security. We therefore propose a framework based on cryptographic methods to support data security in cloud-assisted IoT. In this article, traditional IoT refers to IoT without the assistance of a cloud. Except for confidentiality, other types of security issues such as integrity and authentication are not considered.",10.1109/MCC.2018.111122026,"Secure Data Collection, Storage and Access in Cloud-Assisted IoT",12 January 2018,0
"A lot of effort has been put into resolving the issue of trust among different entities in the IoT application ecosystem. Unfortunately, there is not a single reference scheme that satisfies all stakeholders. The key issue for the traditional solutions is that they all depend on a trusted third-party, which has to be trusted by all stakeholders. Blockchain, as a new data-sharing model, addresses this issue by removing the need for a trusted third-party. It allows all stakeholders to participate in maintaining an immutable ledger in which the data is consistent among all stakeholders.",10.1109/MCC.2018.043221010,IoTChain: Establishing Trust in the Internet of Things Ecosystem Using Blockchain,14 August 2018,0
"In particular, the attack duration has enormous impact on the services running on the cloud due to the on-demand utility computing model of the cloud. Financial losses due to DDoS attacks have multiple components or symptoms, few of which are visible during the attack. However, the remaining part of the losses are visible only after the attack disappears. Most of these losses are difficult to measure, including the long-term reputation and ensuing business losses. There are recent and much talked about massive DDoS attacks on cloud services and cloud service providers that have shaped the socalled battlefields of the cyberattacks.",10.1109/MCC.2017.14,"Combating DDoS Attacks in the Cloud: Requirements, Trends, and Future Directions",15 March 2017,0
"A good irrigation system must provide water to the whole field uniformly. In the absence of uniformity in irrigation, the quality of cultivated products will be reduced. For example, varying grape quality and rate of ripening affect wine quality. Smart agriculture can be used to improve water distribution in the farm, achieve uniform maturity, and accordingly, increase product quality. Thermal imaging could be used to determine the relation between water status of the plant/field and radiation emission, and therefore can be utilized as a measure for water stress and irrigation distribution.",10.1109/MCC.2017.5,Cloud of Things in Smart Agriculture: Intelligent Irrigation Monitoring by Thermal Imaging,15 March 2017,0
"On the other hand, the business for Cloud Computing is a perfect competition environment [10]. It is a similar market with milk, gasoline, airline seats, and cell-phone service which are characterized by a number of supplier behaviors aimed to avoid the downsides of the perfect competition. With the result of the perfect competition, Cloud Computing usually does not meet those enterprise requirements for a deterministic behavior. It causes less quality service and function for enterprise customers which would like to get the production level quality of service for Cloud Computing. It is a major reason to be an inefficient operational support for industry solutions on Cloud Computing. This is a strong reason to build the infrastructure of Cloud Computing for industry solutions. Cloud Computing has much perceived benefits for industry solutions, and its users perceive the promised benefits for Cloud Computing [11]. Here is the list of benefits and challenges for industry solutions on Cloud Computing.",10.1109/CLOUD.2014.105,Industry Cloud - Effective Adoption of Cloud Computing for Industry Solutions,4 December 2014,0
"What is the real meaning of cloud computing and grid computing? Everyone who engages in the IT world is talking about them. And a lot of people in the business world are asking this question, “What is cloud computing, and what does it mean for my business?”",10.1109/ICCASM.2010.5623257,The comparison between cloud computing and grid computing,4 November 2010,0
"Cloud computing is a new multidisciplinary research field, considered to be the evolution and convergence of several independent computing trends such as Internet delivery, “pay-as-you-go” utility computing, elasticity, virtualization, grid computing, distributed computing, storage, content outsourcing, security, and Web 2.0. However, cloud computing's multidisciplinarity has raised questions in the research community about how novel this new paradigm is because it includes almost everything that existing technologies already do. Michael Armbrust and his colleagues try to clarify cloud computing's innovative aspects, identifying its major technical and nontechnical challenges.",10.1109/MIC.2010.113,Cloud Computing: The New Frontier of Internet Computing,2 September 2010,0
"it can be noticed that the executions of mobile application are currently supported by modren mobile platforms and operating systems. However, there is no obvious attention to the efficient mobile resource managemnt such as the applications running in the background, synchronizing email account or searching for Wi-Fi network. To reduce the power draining by such applications, some techniques are proposed, but most of them are insufficient to save enough energy on mobile devices [25].",10.1109/MobileCloud.2017.26,Energy-Aware Fault Tolerant Task offloading of Mobile Cloud Computing,12 June 2017,0
"To improve safety measures and to control traffic, a continuous monitoring and controlling system is required. This type of infrastructure requires mobile sensing, crowd sensing, location awareness and transportation management. To reduce the latency for the cloud users as well as to maintain the quality of service a privacy preserving scheme based on fog computing environment can be used. Such type of approach can achieve higher efficiency in terms of security, privacy, computation and networking capabilities .",10.1109/ICCCNT49239.2020.9225396,Detection and Prevention Mechanisms for DDoS Attack in Cloud Computing Environment,15 October 2020,0
"Data Centers are emitting lot of CO2 gases in the field of cloud computing which harms environment a lot because of the heat produced there. So there is a need to save the environment and surroundings. So, in this paper, we will discuss about the approaches for which we can save our environment. The term ""Green Cloud Computing"" will come into picture in order to have Green environment and we can protect the nature from getting harm.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"A data center comprises two fundamental elements, namely hardware and software. The optimization and enhancement of these layers might lead to the minimization of power consumption in data centers. The software layer can be divided into three distinct sublevels, namely the operating system, the virtualization and the application layer [9]. To attain the goals of green cloud computing, many solutions can be implemented at the distinct programme level.",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"Virtualization is a key enabling technology for Cloud Computing as it enables a more efficient and flexible use of resources. Virtualization represents a foundational element of Cloud for its multitudinous benefits such as flexibility, isolation, high resource utilization rate and so on.",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"To make understanding, consider an issue of a computing application which analysis complex data and generates different patterns to store, maintain and share huge repository of information securely. Currently, cloud adopts security policies explicitly, that is the data proprietor may not have any control of data storage. If stakeholder wants to avail the benefits of cloud computing, the user must also make use of resource allocation and must schedule.",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"Pricing differentiates cloud computing from previous service technologies, such as non-semantic and semantic web-services. The motivation for concentrating on pricing is the perceived view that cloud computing will move to a utility model for computing [1], where users will access self-service on-demand cloud services.",https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"City Eyes is built upon a distributed data storage and computing environment. Unlike most of the existing video surveillance systems, which only capture and archive video data but possess little intelligent video analysis capability, mobile devices and advanced video sensors [9] could also act as a source of computing power and video feeds in the scenario of machine-to-machine (M2M) networks, or Internet of Things (IoT)",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
"In order to increase the precision of this initial study, Cronbach's alpha was used to assess the reliability of the results. Field [20] and Pallant [21] suggested that a value ranging from 0.7 to 0.8 is acceptable. Therefore, the Cronbach's alpha of the interviews with the experts (0.719) is an acceptable value.",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"Pricing cloud computing has always been a big challenge not only to many Cloud Service Providers (CSPs) but also to many cloud consumers because of the exponential growth of new service features or characteristics appear almost daily. Although pricing of cloud service delivery has often been drawn an analogy as a new public utility service [1], the underlying structure of cloud pricing is much more complicated than the traditional public utility services due to the rapid development of cloud technologies and multiple layers of service delivery models (or Anything as a Service: XaaS).",10.1109/TCC.2018.2858266,Hedonic Pricing of Cloud Computing Services,23 July 2018,0
"With cloud computing gaining more prominence by the day and its application to different domains such as forensics [1], security [2] and enterprise resource planning [3], it has become imperative to consider its application to the evolvement of the semantic web as well. The semantic web is an emerging web in which documents on the web are annotated with descriptive data, which provides a meaning and defines a context for the documents. With the annotation, computers can understand different concepts such as people, places, organisations, etc. and process them accordingly. For instance, on the semantic web, ‘Jaguar’ as an animal and as an automobile can be understood and processed as appropriate based on annotation data. Cloud Computing on the other hand, is a computing paradigm which defines ""a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources such as networks, servers, storage, applications, and services that can be rapidly provisioned and released with minimal management effort or service provider interaction"" [4].",10.1109/DeSE51703.2020.9450748,A Cloud Computing Capability Model for Large-Scale Semantic Annotation,14 June 2021,0
"Typically, cloud computing architecture consists of the front end and the node as shown in figure 1 [6]. Front end on a specific implementation in Eucalyptus often referred or named with Cloud Controller [4], [5]. While node or Node Controller is a physical device that can run single or multiple Virtual Machines (VMs) based on demand. The management of the number allocates for VM(s), and VM capacities perform by the front end. With this capability, then the cloud computing capacity can be managed and allocated efficiently by allocating Virtual Machine (VM) in accordance with necessary needs. For example, at the peak time session, we can determine the VM with a large capacity as the host server or we can also duplicate VM with same specifications.",10.1109/ICCCSN.2012.6215751,Building crawler engine on cloud computing infrastructure,14 June 2012,0
"Cloud providers speak different languages. All the major providers offer unique, and often proprietary, data storage (for example, Google's BigTable, Amazon's Dynamo, and Facebook's Cassandra). Scalable data storage isn't yet a commodity and is unlikely to be so for a long time due to the fact that there is no simple generic solution for distributed data storage. Scalable relational database management systems (RDBMSs) remain an unsolved scientific problem leaving the CIO to choose between proprietary storage and huge challenges for interoperability. Exchanging data between different cloud providers is exacerbated by the network's limitations (the network being the slowest component and not growing by Moore's law).",10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"The Amazon Web Services (AWS) are a popular collection of public cloud service offerings. Due to their widespread use their API may be considered a de-facto standard for cloud services. Amongst others, the AWS include the Elastic Compute Cloud (EC2) to operate scalable virtual server in-stances, the Simple Storage Service (S3) for web objects and the persistent block level storage service Elastic Block Store (EBS). Implementations that adhere to the AWS API benefit from the growing ecosystem of compatible management tools and services. Various open source infrastructure solutions like Eucalyptus [2], Nimbus [3] and OpenNebula [4] exist and most of them implement at least a subset of the EC2, S3 and EBS APIs.",10.1109/CLOUD.2011.64,The KOALA Cloud Manager: Cloud Service Management the Easy Way,1 September 2011,0
"Nowadays Cloud Computing has reached a maturity state and high level of popularity that various Cloud services have become a part of our lives. These services are offered at different Cloud deployment models ranging from the lowest infrastructure level to the highest software or application level. Within Infrastructure as a Service (IaaS) solutions we can differentiate public, private, hybrid and community Clouds according to recent reports of standardization bodies. The previous two types may utilize more than one Cloud system, which is also called as a Cloud federation [3]. One of the open issues of such federations is the interoperable management of data among the participating systems. Another popular family of Cloud services is called Cloud storage services or Personal Clouds. With the help of such solutions, user data can be stored in a remote location, and can be accessed from anywhere. Mobile devices can also benefit from these Cloud services: the enormous data users produce with these devices are continuously posted to online services, which may require the use of several Cloud providers at the same time to efficiently store and retrieve these data. The aim of our research is to develop a solution that unites and manages separate Personal Clouds in an autonomous way to provide a suitable solution for these user needs.",10.1109/BDCloud.2014.41,Interoperating Cloud Services for Enhanced Data Management,9 February 2015,0
"Service execution and storage. This is the core of the deployment architecture and contains all the functional units that allow, the management of the services described with dmcc-schema and the distributed execution of the algorithms included in the platform.",10.1109/SERVICES.2019.00121,Delivering Data Mining Services in Cloud Computing,29 August 2019,0
"Amazon Cloud Computing Framework introduces Xen virtualization technology. This techonology allows us to start and control one or more virtual machines in Amazon virtual computing cloud. The mappings of virtual machines are formatted in AMI, which represents Amazon Machine Image. We produce a mapping of an existing server and deploy it to the Amazon cloud computing framework. All AMI mappings have been stored in Amazon S3. Amazon cloud computing framework and S3 are two applications closely related to each other. Moreover, Web Services provided by Amazon cloud computing framework can be accessed by a group of command-line tools.",https://doi.org/10.1109/APWCS.2010.15,A New Architecture of Online Trading Platform Based on Cloud Computing,7 June 2010,0
"We recommend to test with the cloud deployment first before deciding edge-cloud deployment and testing. This helps to make better decision on where components should be deployed and which configurations are suitable for them. In many situations, like in MECCA, we have to rely on several third party services. In the production deployment, one might not be able to influence where such third party services will be deployed - as they might be fixed. Therefore, in testing performance, if possible, one should also replicate such third party services or deploy own services close to the third party services to examine the connectivity impact between the application under test and its third party services. The replication of many third party services, especially the infrastructural ones, can be achieved due to the availability of data and software services. In our tests, we replicate third party services when possible for cloud-only deployment.",10.1109/CLOUD.2018.00091,Analytics of Performance and Data Quality for Mobile Edge Cloud Applications,11 September 2018,0
"An observer into our modern-day trends will certainly notice the popularity and rapid advancements in mobile devices. Mobile devices do not only provide the user with a plethora of resources (Camera, GPS, Microphone, accelerometer, etc.) but they also provide the user with portable and easily accessible applications, entertainment, location services, communication services, and many other conveniences. Companies around the globe are racing to provide the consumers with the latest mobile hardware; i.e the best built-in camera, or the biggest battery capacity.",10.1109/3ICT.2019.8910294,A Secure Framework for Mobile Cloud Computing,25 November 2019,0
"And yet, no RDBMS has had a complete redesign since the technology's inception. Of course, there have been extensions over the years, including support for compression, shared-disk architectures, bitmap indexes, and user-defined data types and operators. However, all the major commercial DBMSs are still built around the original System R architectural features.",10.1109/MCC.2014.25,Today's Tidbit: VoltDB,10 July 2014,0
"In this column and in articles covering the area of standards and compliance (for more information, see page 50), I hope to take just such an ecumenical approach in gathering and distributing news on the current state of cloud com-puting. With your cooperation, I intend to use your input to draw attention to appropriate innovations in standards, API innovations, use case requirements, and groups that are extending these meth-ods. These methods can be historical or modern, and old or new in approach, as long as they contribute to producing a successful standards-based framework for innovation.",10.1109/MCC.2014.6,Defining Our Terms,10 July 2014,0
"What about standards adoption? We shouldn't miss the opportunity to engage in this topic directly. Articles that document adoption efforts for both established and emerging standards sets are welcome here. Of course, standards that are experiencing substantial uptake are the best ones to document, and possibly the ones that least need documentation, but there's room also to put promising new efforts into the spotlight to provide exposure and possibly improve their uptake.",10.1109/MCC.2014.21,Setting Cloud Standards in a New World,10 July 2014,0
"The result is that private cloud infrastructures have devolved into architectures that are indistinguishable, at least to the security engineer, from public cloud systems. Purveyors of private clouds may have control over vendor selection, cloud service features, degree of sharing between users, and day-to-day system administration, but the idea that they're immune to external attacks because of enterprise perimeter protections is no longer justifiable. As such, private cloud deployments should never rely on an enterprise perimeter as their sole security control.",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"Overcoming these interoperability challenges will allow us to establish a resource-sharing environment consisting of multiple cloud datacenters (multi-clouds) that could belong to different providers. In a federated organization, every application owner will be able to deploy its application components across multiple datacenters, thereby improving their ability to handle disasters (such as a datacenter power failure); optimize the cost of using cloud resources via dynamic migration of application components to cheaper datacenters without worrying about low-level details such as the target datacenter's virtualization technologies or programming interface; and avoid vendor lock-in because they'll be able to seamlessly migrate their applications. Recent research projects that address some of the technical challenges related to cloud interoperability for establishing multi-cloud environments include Optimis,[8] Contrail,[9] Mosaic,[10] and Reservoir.",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"Serverless computing is sometimes conflated with “NoOps,” the extreme evolution of the DevOps movement. However, even though serverless options potentially abstract away load balancing, autoscaling, high availability, and the security maintenance of compute infrastructure, it's worth pointing out that all of these underlying operational concerns are simply distractions from operational responsibility. Sure, you don't need to manually spin up and manage compute, but you do need to ensure your services are tunable, testable, secure, performant, resilient, monitored, and KPI-instrumented.",https://doi.org/10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
Requirements ontology provides a mapping mechanism between high level requirements and low level descriptions of cloud service descriptions via a brokerage mechanism. This approach moves away from simplistic syntactical description of service provision.,https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"Cloud computations provide a model of the organization of remote access to configured separated computing resources, which can be freely allocated and exempted with minimal management or interaction with the provider of services [7]. The reference model of the cloud information and computing system proposed by NIST (National Institute of Standards and Technology) [8], is presented in Fig. 1",https://doi.org/10.1109/SCM58628.2023.10159053,Model of a Self-Healing Computing Process of a Cloud Computing System under Conditions of Information and Technical Impacts,26 June 2023,0
"To overcome these challenges, researchers have proposed various new DC architectures, such as FatTree, DCell, FiConn, Scafida, and JellyFish.[2] However, these proposed DC architectures overcome only a fraction of the challenges faced by legacy DC architectures. For instance, the FatTree architecture delivers high bisection bandwidth and a 1:1 oversubscription ratio, but it lacks scalability. The DCell, FiConn, Scafida, and Jellyfish architectures, on the other hand, deliver high scalability but at the cost of low performance and high packet delays with high network loads.",10.1109/MCC.2014.26,Trends and challenges in cloud datacenters,10 July 2014,0
"As a result, some researchers have devised methods that can automatically determine ways to partition applications over federated clouds to meet security requirements. One approach,[4],[5] inspired by traditional multilevel security appreaches,” models an application as a set of communicating distributed components, and uses rules to generate a set of inequalities that represent the security requirements.",10.1109/MCC.2014.46,Application Security through Federated Clouds,30 September 2014,0
"Direct sound transmission proved more popular with the public and with investors than a multiplexed version of the telegraph. As a result, an entire new field of communication was invented in a period that could be characterized in modern terms as “disruptive.” Telecommunications did not stand alone among the innovations of this period, but played a crucial role in allowing these developments to be useful to human interaction.",10.1109/MCC.2015.27,"Invention, Innovation, and New APIs",2 June 2015,0
"Contemporary healthcare strategies envision body sensor nodes as a vital component of advanced healthcare systems. Patients could wear these body sensors for both regular and emergency health monitoring.8,9 Thus, we can assume that some subgroup of victims in a disaster area (patients or elderly people) will be pre-equipped with body sensor nodes.[10]–​[12] The medical experts could analyze data from these nodes to obtain the physiological status of the live victims within the disaster-affected zones.",10.1109/MCC.2014.72,Evacuation and Emergency Management Using a Federated Cloud,30 November 2014,0
"The Globus transfer service provides core data management capabilities and implements an associated data access security fabric. Globus uses the GridFTP protocol[7] to transfer data between logical endpoints-a Globus representation of an accessible GridFTP server. GridFTP extends FTP to improve performance, enable third-party transfers, and support enhanced security models. The basic Globus model for accessing and moving data requires deploying a GridFTP server on a computer and registering a corresponding logical endpoint in Globus. The GridFTP server must be configured with an authentication provider that handles the mapping of credentials to user accounts. Often, authentication is provided by a co-located MyProxy credential management system,[8] which lets users obtain short-term X.509 certificate-based proxy credentials by authenticating with a plug-in authentication module (for example, local user accounts, Lightweight Directory Access Protocol [LDAP], or InCommon/CILogon).",10.1109/MCC.2014.52,"Efficient and Secure Transfer, Synchronization, and Sharing of Big Data",30 September 2014,0
"As we delve deeper into the “Digital Age,” we're witnessing an explosive growth in the volume, velocity, variety, veracity, and value (the 5Vs) of data produced over the Internet. According to recent Cisco[1] and IBM2 reports, we now generate 2.5 quintillion bytes of data per day, and this is set to explode to 40 yottabyes by 2020[3]-that is, 5,200 gigabytes for every person on the earth. As noted in previous “Blue Skies” columns, data generated by Internet of Things (loT) devices and sensors are part of the big data landscape. [4], [5] IoT comprises billions of Internet-connected devices (ICDs) or “things,” each of which can sense, communicate, compute, and potentially actuate, and can have intelligence, multimodal interfaces, physical/virtual identities, and attributes. ICDs can be mobile devices, sensors, medical imaging devices, individual archives, social networks, smart cameras, body sensors, automobile cosimulations, or software logs. In a nutshell, a large volume of veracity data is generated at high velocity from a variety of sources.",10.1109/MCC.2015.36,Trustworthy Processing of Healthcare Big Data in Hybrid Clouds,2 June 2015,0
"Misuse-based IDSs enjoy high detection accuracy but are vulnerable to all zero-day intrusions.3 This is due to the underlying detection mechanism that checks for a match with existing attack signatures. Obviously, an IDS can't generate signatures for an unknown attack. Anomaly-based IDSs show promise for detecting zeroday intrusions.4,5 but are prone to high false positives.",10.1109/MCC.2014.53,Enhancing Big Data Security with Collaborative Intrusion Detection,30 September 2014,0
"However, there are limited benchmarks and application kernels for heterogeneous datacenters. In fact, there's no agreement on available performance benchmarking for executing large-scale IoT applications across distributed data-centers. Actually, the lack of intercenter benchmarks and standards should be the key research agenda for the future. Currently, the National Institute of Standards and Technology (NIST), Open Grid Forum (OGF), Distributed Management Task Force (DMTF) Cloud working group, Cloud Security Alliance, and Cloud Standards Customer Council are all working on cloud standards.",10.1109/MCC.2015.14,Processing Distributed Internet of Things Data in Clouds,22 April 2015,0
"Service computing covers the science and technology of bridging the gap between business and IT services, and has attracted increasing attention from both industry and academia.1 Services are defined as software artifacts that are autonomous, self-described, reusable, and highly portable. They're the basic units for building rapid, low-cost, secure, and reliable applications. Thus, the service computing paradigm saves on development costs that would otherwise be spent creating new software components for each new business process. As emerging techniques such as cloud and mobile computing become more prevalent, the way we provide and consume services is ever-changing.",10.1109/MCC.2016.92,Toward Mobile Service Computing: Opportunities and Challenges,19 September 2016,0
"Containers are predicated on the goal of deploying and managing n-tier application designs. By their nature, containers manage n-tier application components, e.g., database servers, application servers, web servers, etc., at the operating system level. Indeed, portability is inherent because all operating system and application configuration dependencies are packaged and delivered inside a container to any other operating system platform. Containers are preferable to virtual machines here because they share compute platform resources very well whereas virtual machine platforms tend to acquire and hold resources on a machine-by-machine basis.",10.1109/MCC.2016.122,Moving to Autonomous and Self-Migrating Containers for Cloud Applications,30 December 2016,0
"Virtual infrastructures are infrastructure-level (virtual) entities, such as VMs and virtual networks, created in the cloud on behalf of users. Side-channel attacks target these virtual infrastructures. Researchers have proposed several solutions to defend against cross-VM side-channel attacks. Düppel, for example, aims to disrupt cache-based side channels. In this self-defensive approach, the target VM's guest operating system injects cache access noise (that is, flushes) so the collocated attack VM can't infer cache access patterns.4 This solution doesn't require modifying the underlying hypervisor or cloud platform. To defend against memory bus-based side channels, a simple and practical approach is to prevent a VM from locking the memory bus and let the hypervisor emulate the execution of atomic instructions that would otherwise require memory bus locking",10.1109/MCC.2014.20,Security and Privacy in Cloud Computing,10 July 2014,0
"Consider distributed file systems built on hundreds or thousands of servers in a single or multiple geodistributed cloud sites. Applying an ORAM-based algorithm for privacy-preserving access can lead to serious access load imbalance among the storage servers. Therefore, in this article, we study a data-placement problem to achieve a load-balanced storage system with improved availability and responsiveness. Given this problem's NP-hardness, we propose a low-complexity algorithm that can deal with a large-scale problem with respect to big data. We conduct extensive simulations to show that the proposed algorithm finds results close to the optimal solution, and significantly outperforms a random data-placement algorithm.",10.1109/MCC.2016.107,Privacy-Preserving Access to Big Data in the Cloud,11 November 2016,0
"In a cyber-physical system, for example, sensitive data from sensors in the physical environment will likely need to travel through different networks to user devices, and the communication path, if unsecured, will be vulnerable or exposed. An attacker could also use cyber-physical components (such as a remote terminal unit) as an attack vector to undertake network attacks (such as timing, data integrity, or replay attacks) against the connected cyber-physical infrastructure. Such attacks could result in power system blackouts, damaged user devices, and smart grid infrastructure failures. They could also result in leaked user data, which infringes on individual privacy. Expanding the preliminary research concept, demonstrated by George Grispos and his colleagues,4 that “residual artefacts generated by cloud-based synchronized applications can be used to identify broad user behaviour patterns” to interconnected transportation systems creates opportunities for profiling, theft, and physical attack. An attacker could realistically use the interconnected transportation system's data to profile daily life activities (such as identifying specific locations, common travel times, and most visited places), making the abuse of this data itself very risky. Couple this information with mobile devices, cloud storage data, social website interactions, and data from favorite restaurants, fuel stations, and stores, and the profile becomes a detailed roadmap for a host of illegal activities.",10.1109/MCC.2016.5,Forensic-by-Design Framework for Cyber-Physical Cloud Systems,26 February 2016,0
"In our approach, the health authority validates mobile users based on their identity and location attributes. A mobile user consults the domain server, which forwards the request to the health authority on the user's behalf. Based on this validation, the domain server informs the cloud service provider (CSP) to allow the requested information to be transmitted.",10.1109/MCC.2016.76,Hybrid Cryptographic Access Control for Cloud-Based EHR Systems,19 September 2016,0
"illustrates how cloud computing can be adopted within the healthcare domain for medical data management. Each healthcare provider has access to or hosts a cloud platform, which can be used to store, process, and share data among patients, healthcare personnel, and other relevant stakeholders (such as centers for disease control and prevention if an outbreak is detected). Such a platform can also host services for managing the identities of all registered users, patient consent, and patient health records and reports. The cloud platform can also support the healthcare provider's administrative processes, such as generating and updating billing reports and disbursing funds. To meet patients' mobility needs, public and private cloud platforms used by different healthcare providers can be federated using an intercloud infrastructure to share patient data, generate billing records, and so on.",10.1109/MCC.2016.139,Healthcare-Related Data in the Cloud: Challenges and Opportunities,30 December 2016,0
"However, further integration between IoT and cloud services as well as emerging complex applications require a uniform software layer view on top of these blended IoT elements and cloud services.",10.1109/MCC.2015.23,Principles for Engineering IoT Cloud Systems,2 June 2015,0
"All of this serves to focus us on the primary cloud computing concern for the enterprise, which can be framed in terms of information security and risk management. The need to provide comprehensive confidentiality, integrity, and availability protections for data hosted in the cloud continues to grow in lock step with cloud computing adoption across the enterprise, as does the need to understand how to integrate the data hosted in the cloud into the enterprise's risk management practices (for example, audit/compliance and business continuity/disaster recovery).",10.1109/MCC.2016.21,The Hybrid Cloud Security Professional,26 February 2016,0
"Now there might well be a silver bullet: microservices architectures and continuous integration enable companies such as Google and Amazon to build and release enormous systems such as Web search and e-commerce engines with far more than 10,000 function points, and evolve them with great speed. For example, Google search and applications are built from an interlinked set of more than 5,000 services. The company tests and releases its online systems from a single codebase with more than 2 billion lines of code, deploying about 75,000 committed changes per week.3",10.1109/MCC.2016.109,The Economics of Microservices,11 November 2016,0
"This article doesn't cover the challenges inherent in the cloud-to-cloud interoperability perspective-that is, the cloud integration model consisting of multiple cloud providers that cooperatively integrate (via federated middleware software) their datacenter resources to support seamless migration of application workload and components across each other. An interesting discussion on interoperability appears elsewhere.",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"Earlier, IT sector faced difficulty in allocation of resources in multi user environments. Therefore, many stakeholders were not in position to finish their software projects in time due to resources unavailability. As a result, cloud computing came into existence and provided a solution on persisting resource sharing problems. A cloud offers a resources as pay-per-use technique, which can be reconfigured instantly according to use requirements [18]. Due to this, cloud computing was deployed in infrastructural environments, share and bind more nodes together at a time.",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"Thermal imaging is a noncontact and nonintrusive technique, without the need for modifications in the surface temperature. It is also capable of displaying the temperature. This has been leveraged in many industrial and/or research fields when the temperature represents a key variable, including meteorology, environmental studies, medical diagnostics, and architecture.4 Several studies have demonstrated that thermal imaging is an appropriate approach to identifying key parameters to schedule irrigation. There are several critical features for irrigation, such as water stress, gas-exchange rate, evapotranspiration rate, stomatal conductance, and closing of stomata. In water stress condition, stomata begin to close and cease to transpire, plant heats up, and the canopy temperature will rise.5 Therefore, thermal remote sensing can potentially be used to measure plant temperature, stomatal conductance, and evapotranspiration rate by evaluating stomatal responses.6–​9 Thermal imaging has the advantage of providing a temperature value for all of the pixels within the sensor's field of view in comparison to thermometry, where the latter only provides an average value. Therefore, it is occasionally easier to discriminate between different components, such as sunlit versus covered plant portions and wet against dry soil surfaces",10.1109/MCC.2017.5,Cloud of Things in Smart Agriculture: Intelligent Irrigation Monitoring by Thermal Imaging,15 March 2017,0
"As reported by Arbor Networks, the percentage of attacks targeting cloud-based services is growing each year. Over 33 percent of reported DDoS attacks in 2015 targeted cloud services, which makes the cloud a major attack target. Motivation for the DDoS attacks range from extortion, demonstration of attack capabilities, and hacktivism to business rivalry. It is interesting to note the rise of DDoS-attack-for-hire payment-based services, also known as booters or stressers, that attack a target via the planting of attack guns (botnets).3 With the arrival of these methods, the attack frequencies to victim organizations have increased considerably in recent few years. DDoS attacks may last between a few seconds to even weeks in a few cases, which multiplies the economic and business losses multifold.",10.1109/MCC.2017.14,"Combating DDoS Attacks in the Cloud: Requirements, Trends, and Future Directions",15 March 2017,0
"Fire is one of the most common emergency events. It can spread rapidly, burn intensely, carry strong heat, and produce large volumes of fumes and smoke. Fire can prevent evacuees from escaping buildings by obstructing exits, and inflict casualties and loss of life. For early fire detection and suppression, building standards require installation of fire alarms, smoke detectors, carbon monoxide detectors, and firefighting equipment, such as extinguishers, fire blankets, and sprinkler systems. Standard fire safety systems are connected to a central panel that triggers the alarm and provides status information, while alarm systems, composed of strobe lights, lighted exit signs, and sirens, alert occupants and guide them to the nearest exit.",10.1109/MCC.2014.67,A Cloud-Enabled Building and Fire Emergency Evacuation Application,30 November 2014,0
"Attacks on cloud services and attacks on traditional computing systems have some overlapping characteristics because cloud and traditional systems share the same technological underpinnings. However, the cloud environment also has unique characteristics that must be taken into account when developing a cloud attack and risk assessment taxonomy. In particular, a cloud service's elasticity, abstract deployment, and multitenancy might impact the risk assessment.[7]",10.1109/MCC.2015.2,Cloud Attack and Risk Assessment Taxonomy,22 April 2015,0
"These form a virtuous cycle, enabled by the cloud. Faster, cheaper, and better innovation in products, services, and processes thanks to the cloud leads to differentiated offers in the marketplace. Together with precision marketing and global reach, this enables companies to find more customers, close sales, and deliver products and services to those customers, globally. Relationships with those customers move from mere anonymous transactions to a higher degree of intimacy, and advanced big data algorithms such as recommendation engines enable “collective intimacy.”",10.1109/MCC.2018.043221018,Revenue Growth is the Primary Benefit of the Cloud,14 August 2018,0
"Using a private cloud infrastructure within the enterprise, an organization gains the advantages of software virtualization, such as reduced hardware costs through shared virtual machines with high utilization, but without the security concerns that come from ubiquitous, open access. Enterprise auditors and regulators approve of this architecture because the familiar perimeter remains a primary control for security compliance. The safeguards inherent in the private cloud approach include the following:",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"Organizations must consider many quantitative and qualitative criteria when making this decision, such as focusing leadership time on “core vs. context” issues-that is, those that are critical to developing competitive advantage versus those that aren't.[5] For example, a movie studio should focus on scripting, cinematography, and casting, not datacenter technology and operations. From a rational economic cost-optimization perspective, however, there are several key drivers.",10.1109/MCC.2014.91,The Nuances of Cloud Economics,30 November 2014,0
"Nevertheless, the usage of an Osmotic Computing infrastructure (CDC+EDC) poses new challenges for IoT workflow application developers and operations managers as they need the awareness of resource/device (CDC server vs. IoT gateway) heterogeneity, virtualisation software heterogeneity (e.g., hypervisor vs. container), data analytic programming model heterogeneity (stream processing vs. batch processing), geographic distribution, and network performance uncertainties.",10.1109/MCC.2017.22,Osmotic Flow: Osmotic Computing + IoT Workflow,26 April 2017,0
"However, the convenience that cloud brings to IoT comes at the cost of potentially new security risks, which have never been considered in a traditional IoT system. In both theory and practice, a cloud is widely recognized as an honest-but-curious party.2 This means that a cloud will handle user-delegated tasks but hardly guarantee confidentiality of user data.",10.1109/MCC.2018.111122026,"Secure Data Collection, Storage and Access in Cloud-Assisted IoT",12 January 2018,0
"The data was collected using semi -structured interviews. The interviews were conducted with twenty IT experts at different organisations in Saudi Arabia. The aim of interviews was to improve the proposed model and explore other factors that were not mentioned in previous studies before carrying out a survey. All the participants were working in IT departments in different sectors, such as manufacturing, engineering and energy.",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"Though these smart devices bring great convenience to us in our daily life, news such as US cell carriers (including AT&T, T-Mobile. and Sprint) selling access to customers' real-time phone location data to a little known company called Securus2 raises public concerns about the risk of personal data leakage and abuse. Such news prompts a debate on whether these IoT devices are our friends or enemies. Trust is not a one-way street in the IoT ecosystem. Data analysts have concerns about the integrity of the data that data owners provide. At the same time, data owners are concerned about whether data analysts only use their data for its declared purposes. Additionally, data owners care about how to protect their own data (sometime captured by manufacturers) when IoT device ownership changes during its life. For example, what happens to the data of a car owner when an autonomous car is sold or the ownership of a car is changed?",10.1109/MCC.2018.043221010,IoTChain: Establishing Trust in the Internet of Things Ecosystem Using Blockchain,14 August 2018,0
"Those three service models are Software as a Service (SaaS), Platform as a Service (PaaS) and Infrastructure as a Service (IaaS). Those four deployment models are private, community, public and hybrid cloud which are the deployment pattern for Cloud Computing. In the architecture of Cloud Computing, there are five major components which are Cloud Consumer, Cloud Auditor, Cloud Provider, Cloud Carrier and Cloud Broker [4] [5]. This paper is mainly focused on architecture components of Service Orchestration and Cloud Service Management in Cloud Provider since those components are relevant to industry solutions, and they are also a part of Common Cloud Management Platform (CCMP) for the cloud management architecture [6]. In addition, Cloud Computing can appeal less capital and operational expenses because the infrastructure can be constructed with a statistical multiplex of hardware and software stacks among workloads and also different customers. The automation technology for the systems management and the shared hardware and software stacks can provide an efficient infrastructure for the enterprise IT operation. Cloud Computing has a challenge IT theme for the IT outsourcing service in enterprises since it is a emerging paradigm shift from a legacy support and business structure to a structure of Cloud Computing [7].",10.1109/CLOUD.2014.105,Industry Cloud - Effective Adoption of Cloud Computing for Industry Solutions,4 December 2014,0
"The drawbacks of tools like browser extensions, commandline tools and applications with a graphical user interface that require a local installation indicate that an online tool is best suited to work with multiple cloud services. This should be delivered as a software service that can be used with all kinds of devices and browsers. The service could be implemented on a scalable platform service such as Google App Engine. It is also quite easy to optimize a software service for mobile devices that lack physical keyboards and have a limited screen size.",10.1109/CLOUD.2011.64,The KOALA Cloud Manager: Cloud Service Management the Easy Way,1 September 2011,0
"In the past 25 years, several other markets have evolved, including data warehousing, text management, the Web, and stream processing. These markets have very different requirements from business data processing. Also in the last 25 years, processors became thousands of times faster and memories grew to be thousands of times larger. Storage volumes have increased enormously. Through the use of scale-out techniques, cloud computing has extended these resources, making them essentially infinite. Finally, systems that use DBMSs rarely run interactive transactions or present users with direct SQL interfaces.",10.1109/MCC.2014.25,Today's Tidbit: VoltDB,10 July 2014,0
"Are there really established and emerging standards in the new world of cloud computing? Yes, definitely. You might not know about such efforts yet, so the magazine aims to collect the most coherent explanations available and expand on them wherever possible. This effort will aim to study, explain, document, and give a forum for describing not only the standards that are seeing use, but also the process through which they're developed to the point that they can see the light of day. As we'll see, standards in the cloud computing world aren't new at all; many of these protocols and specifications have been under continuous development for several years, leading to an increasing state of maturity that makes it possible and practical to take on such an effort.",10.1109/MCC.2014.21,Setting Cloud Standards in a New World,10 July 2014,0
"Progress can take unanticipated turns. Rather than trying to invent the tele-phone, Bell was trying to develop his idea for a multi wavelength version of the simpler telegraph, with each coded signal carried as modulations on its own separate sound frequency. [1] If he had succeeded, this would have provided the logical precursor for modern multiwavelength communications, a technology that is used now in a different but substantially similar way on essentially all long-distance optical fiber connections.",10.1109/MCC.2015.27,"Invention, Innovation, and New APIs",2 June 2015,0
"For a simple workflow such as that in Figure 1, it isn't too difficult to work out a way to partition the software to meet security requirements. Larger, more complex applications might have many more components, and even different security levels for different types of data. Making manual decisions on how to partition the application is error prone and potentially fraught with danger as it could result in sensitive data being stored and processed in the public cloud.",10.1109/MCC.2014.46,Application Security through Federated Clouds,30 September 2014,0
"Legacy, multirooted tree-based network architectures, such as the ThreeTier architecture, cannot accommodate cloud computing's growing demands.[4] Legacy DC architectures face several major challenges: scalability, high oversubscription ratio and low cross-section bandwidth, energy efficiency, and fault tolerance.",10.1109/MCC.2014.26,Trends and challenges in cloud datacenters,10 July 2014,0
"The architecture of MCC refers to the way in which mobile devices connect and interact with the cloud. The existed architectures can be divided into three categories: remote cloud, cloudlet and Ad hoc cloud. We introduce the concepts of the three architectures and analyze the state of art respectively, followed by our vision for future hybrid mobile cloud architecture.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"We propose Osmotic Flow, a new model for holistically programming, mapping and executing IoT data transformation workflow applications on a distributed infrastructure combining both EDC and CDC resources. In the Osmotic Flow model, an IoT workflow application is modelled as a directed (potentially cyclic) graph with data transformation tasks as its nodes, and dataflow dependencies (or control flow dependencies for computational synchronization, if/as needed) between data transformation tasks as its vertices. Osmotic Flow model permits data transformation tasks to be distributed, managed, and executed across any available CDC and EDC provider.",10.1109/MCC.2017.22,Osmotic Flow: Osmotic Computing + IoT Workflow,26 April 2017,0
"The emerging availability and varying complexity and types of IoT devices, along with large data volumes that such devices (can potentially) generate, can have a significant impact on our lives, fueling the development of critical next-generation services and applications in a variety of application domains (healthcare, finance, disaster management, and so on). Understanding how data from such devices can be more efficiently analyzed remains a challenge, with existing reliance on large-scale cloud computing systems becoming a bottleneck over time. Transferring large datastreams to such centralized cloud datacenter environments, in a timely and reliable manner, is a key limitation of current cloud-centric IoT programming models (such as Amazon IoT and Google Cloud Dataflow). These existing IoT programming models are considered inappropriate in the context of emerging IoT applications for the principal reason that they assume that the intelligence and resource capacity necessary for data processing reside predominantly in the cloud datacenter.",10.1109/MCC.2016.124,Osmotic Computing: A New Paradigm for Edge/Cloud Integration,30 December 2016,0
"“A model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources that includes networks, servers, storage, applications, and services that can be rapidly provisioned and released with minimal management effort or service provider interaction”.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"Also known as in-frared camera sensors, thermographic camera sensors function irrespective of ambient light.6,7 In a postdisaster scenario, these sensors periodically capture and transmit frames (generated through thermal imaging) to the onsite sensor cloud storage. These frames are analyzed within the cloud servers in real time to determine the location and number of live victims in the affected regions.",10.1109/MCC.2014.72,Evacuation and Emergency Management Using a Federated Cloud,30 November 2014,0
"The analysis of risk is very important in cloud environment, because of the many challenges of cloud computing. The security and privacy of both provider and consumer can be compromised with the different existing threats of cloud. In the next two section contains the idea and detailed solution of these problems and threats.",https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
Smartphone applications nowadays provide numerous useful ways for users to encompass the proficiencies of their phones [1]. The report articulates that there are more than 1+ million applications and 50+ billion downloads [2] both in PLAY store for Android and APP store for Apple products.,https://doi.org/10.1109/MobileCloud.2017.29,Mobile-Based Location Tracking without Internet Connectivity Using Cloud Computing Environment,12 June 2017,0
"The growing adoption of microservices in the cloud is motivated by the ease of deploying and updating the software, as well as the provisioned loose coupling provided by dynamic service discovery and binding. Moreover, structuring the software to be deployed in the cloud as a collection of microservices allows cloud service providers to offer higher scalability guarantees through more efficient consumption of cloud resources, and to dynamically and quickly restructure software to accommodate growing consumer demand. Structuring software in smaller computation units enables optimized allocation of the application components within proper containers in the virtual machines (VMs) running on top of the host machine provided by the cloud infrastructure, as the example in Figure 1 illustrates. This lets us minimize waste of resources and maximize packing of the components within a single VM. This is possible because, despite having to realize the same application tasks, microservices are typically thinner than conventional software components because they use lightweight software technologies and platforms. This model also allows a simpler and faster migration of software component instances from one VM to another to satisfy cloud applications' changing resource demands.",10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
"We propose a public verification scheme in which we adopt a random masking technique instead of secure channels between cloud servers and auditors to resist external adversaries. In addition, users are able to examine auditors' behaviors to prevent malicious auditors from fabricating verification results. Furthermore, we use Bitcoin to construct an unbiased challenge message, which helps prevent malicious auditors from colluding with cloud servers. Security and performance analyses show that the proposed scheme can achieve security goals with efficiency.",10.1109/MCC.2016.94,Cryptographic Public Verification of Data Integrity for Cloud Storage Systems,11 November 2016,0
"The amalgamation of ICDs with big data processing software frameworks and cloud-based hardware resources leads to the creation of novel big data applications in domains such as healthcare, traffic management, smart energy grids, and smart manufacturing. Managing large, heterogeneous, and rapidly increasing volumes of data, and extracting value out of such data, has long been a challenge. In the past, this was partially mitigated by fast processing technologies that exploited Moore's law. However, with a fundamental shift toward big data applications, data volumes are growing faster than they can be analyzed, regardless of increased CPU speeds or other performance improvements. Although the impetus for the remainder of our article comes from healthcare big data, the problems and solutions discussed are applicable to other application domains.",10.1109/MCC.2015.36,Trustworthy Processing of Healthcare Big Data in Hybrid Clouds,2 June 2015,0
"Microservices act as standalone application subunits or components, implementing specific communication protocols for sending and receiving messages. In microservices, data flows through smart endpoints, which also process incoming information. Using well-defined interfaces and protocols, application developers can deploy different microservices on heterogeneous infrastructures without a specific integration framework. Generally, microservice communication uses a REST approach based on HTTP and TCP protocols, XMPP, or JavaScript Object Notation (JSON). However, currently, there are no widely adopted standardized protocols or data formats for microservice communication.1 Microservices deployment and execution also leads to various networking issues. To this end, application developers currently adopt various software-defined networking (SDN) and network function virtualization (NFV) solutions for networking microservices.",10.1109/MCC.2016.112,Open Issues in Scheduling Microservices in the Cloud,11 November 2016,0
"Data analysis was done by mapping the results from all selected institutions and presenting the result using tables and graphs. Quantitative data was analyzed using excel and observed patterns were compared with other from literatures. Moreover, we calculated the overall results on every investigated metric (e.g. storage, memory, power consumption in PCs and Severs).",https://doi.org/10.1109/SCAT.2014.7055151,Road map towards eco-efficient cloud computing adoption in higher learning institutions in Tanzania,5 March 2015,0
PUE stands for Power Usage Effectiveness. It states that the energy consumed in the data centers would be effective and efficient and no energy should be wasted. It is the statistic to make sure how much energy is consumed. [3] DCiE stands for Data Center infrastructure Efficiency. It is the inverse of PUE. Both of these methods are used to govern electricity.,https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"Taking such an approach also lets us make short work of dispatching useless arguments regarding architectural use patterns and room for creativity in design. Advocates of Representational State Transfer (REST)/HTTP API design methods, for example (practitioners of which include me), sometimes say that such methods don't use standards or are an antistandards alternative, when in fact they simply appropriately use the set of HTTP standards and the REST architectural design pattern to allow creativity to flourish within and between boundaries defined by HTTP interfaces. Far from being antistandards in nature, modern RESTful API design is a vindication of the standards-based approach and a real-world example of using community-designed standards to solve practical problems in creative ways.",10.1109/MCC.2014.6,Defining Our Terms,10 July 2014,0
"An additional fatal issue with private clouds is that enterprise security teams can't stop determined insider attacks. Even in the presence of segregation of duty controls, as with Sarbanes-Oxley relevant systems, the approach is vulnerable to collusion, which is easy to achieve with malware on multiple compromised systems. Thus, by situating a private cloud inside the enterprise and assuming that internal access can be trusted, an organization places its cloud infrastructure at direct risk of compromise.",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"The DC architecture plays a pivotal role in the performance and scalability of the cloud platform. Cloud computing relies on DCs to deliver the expected services.[2] The widespread adoption of the cloud paradigm mandates exponential growth in the DC's computational, network, and storage resources. Increasing the computational capacity of today's DCs is not an issue. However, interconnecting the computational resources to deliver high intercommunication bandwidth and specified QoS are key challenges. Today's DCs are not constrained by computational power but are limited by their interconnection networks.",10.1109/MCC.2014.26,Trends and challenges in cloud datacenters,10 July 2014,0
"This article investigates the technical challenges from the user-to-multiple-cloud interoperability perspective. In this cloud integration model, application owners are responsible for provisioning their application components over resources belonging to multiple providers. In this scenario, owners typically implement or use an application provisioner software program (such as RightScale [www.rightcale.com] or CloudSwitch [https://home.cloudswitch.com]), which distributes application components across multiple resource providers to meet the SLAs in an optimal way.",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"The basic elements of a search engine process are crawling, storage, indexing and ranking algorithms [1]. Many studies has proposes new approach provides a cloud-based platform for low-cost, effective and personalized search models [1]. Cloud computing today has brought a new era in the use of infrastructure more efficient. Currently, cloud computing infrastructure will maximize the use of virtual machine (VM). It means that we can create instance of VM(s) on a single physical computer. The use of VM is expected to increase the efficiency of resource usage because VM can be set, invoked or terminated in accordance with the requirements.",10.1109/ICCCSN.2012.6215751,Building crawler engine on cloud computing infrastructure,14 June 2012,0
"Cultivators can use information such as light, humidity and temperature levels to modify irrigation schedules and avoid the risk of damaging crops.2 For example, soil sensors can be used to collect information on how water flows through the land and can be used to track changes in soil moisture, temperature, and levels of nitrogen and carbon. These sensors can work in conjunction with drip irrigation methods and fertigation to avoid unnecessary waste of water and fertilizer, thus, increasing fruit and leaf quality. Real-time data of weather predictions, soil conditions, crop features, etc. can support farmers in making informed decisions on which crops to plant where and when as well as when to plough, etc. This allows the monitoring, optimization, and precise control of high-yielding (wheat, corn, etc.) and sensitive crops (vineyards, tropical fruits, etc.), whether cultivated outdoors or in greenhouses. This permits farmers to help reach maximum crop production with optimal quality.3",10.1109/MCC.2017.5,Cloud of Things in Smart Agriculture: Intelligent Irrigation Monitoring by Thermal Imaging,,0
"Distributed denial of service (DDoS) attacks have been a nightmare for enterprise operations, availability, and security. After the emergence of modern computing paradigms like cloud computing, these attacks saw major changes in scale, methods, aims, and targets. The advantages provided by cloud computing are available to both victims and the attackers. This has made the DDoS arms race interesting and quite complex.1 In 2004, the peak attack bandwidth was just 8 gigabits per second (Gbps). However, according to the report by Arbor Networks, there were much heavier DDoS attacks with attack bandwidths of more than 500 Gbps in 2015.2 The target services of DDoS attacks lie in each sector influenced by IT infrastructure, whether its government, banking, or media industry.",10.1109/MCC.2017.14,"Combating DDoS Attacks in the Cloud: Requirements, Trends, and Future Directions",15 March 2017,0
"A century ago, factories provided their own power, but with the emergence of large utilities, electricity became a cheap commodity, enabling businesses to simply plug into the grid. Carr argues that a similar phenomenon is occurring with cloud computing. Private computer systems are being supplanted by services provided via the Internet.",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"VCL is evaluated in two perspectives, the architecture model and its deployment explaining its components in detail. The VCL components are compared to other classical cloud computing models. The functionality of VCL services is verified with respect to the cloud management infrastructure of the IaaS VMs.",https://doi.org/10.1109/CCAA.2015.7148478,Virtual computing lab (VCL) open cloud deployment,6 July 2015,0
"This study uses DEMATEL technique to identify the key consideration factors and explore their interrelationship. The DEMATEL, originated from the Geneva Research Centre of the Battelle Memorial Institute [12], uses matrix calculations to obtain all the direct and indirect causal relationships, as well as the influence strength.",https://doi.org/10.1109/CloudCom.2012.6427610,Key consideration factors of adopting cloud computing for science,4 February 2013,0
Calheiros et. al in [10] propose a resource management system for cloud bursting. This system adopts dynamic provisioning and scheduling of cloud resources to minimize cost while respecting job deadlines.,https://doi.org/10.1109/CLOUD.2017.112,Cloud Bursting Scheduler for Cost Efficiency,11 September 2017,0
"It is clear that technology can play a significant role in enhancing the quality of care for patients (e.g. leveraging data analytics to make informed medical decisions) and potentially reduce costs by more efficiently allocating resources in terms of personnel, equipment, etc. For example, data captured in paper form is hard to capture in systems (e.g. costly and data entry errors), costly to archive, and being available when needed.",https://doi.org/10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"The price you pay for these advantages is portability. Applications that are localized for specific cloud platforms are not easily ported to other cloud platforms. Doing so takes a great deal of rewriting or refactoring of the code. For all practical purposes, you are locked into that cloud platform.",10.1109/MCC.2017.4250932,"Cloud-Native Applications and Cloud Migration: The Good, the Bad, and the Points Between",1 December 2017,0
"Enabling marketplaces at the edge and integrating them into existing edge- and cloud-computing infrastructure is nontrivial. Emerging distributed-ledger technologies (DLTs) such as blockchains have promising features that could help in realizing such marketplaces (see Figure 1). However, DLTs will require new extensions before they can be fully leveraged to establish edge marketplaces. Such extensions will require collaboration across multiple disciplines.",10.1109/MCC.2018.064181115,Realizing Edge Marketplaces: Challenges and Opportunities,29 November 2018,0
"Consider a chaos experiment on a microservice architecture that injects latency between calls from service A to service B. This experiment might reveal that a spike in the response time of service B triggers a retry storm that overloads essential service C, a weakness that would not be detected by unit or integration testing (see sidebar: how chaos relates to traditional testing).",10.1109/MCC.2018.032591616,The Business Case for Chaos Engineering,12 June 2018,0
"Artificial intelligence has become more affordable through the use of cloud platforms, making it a shiny new object once again. The affordable cost, coupled with cloud providers that promote artificial intelligence as having wide value, raises valid concerns that the technology will be misapplied. This already seems to be a pattern. Be aware that the value won't be realized if artificial intelligence is applied to systems that can't benefit from making predictions from patterns found in data, which applies to most applications within enterprises.",10.1109/MCC.2018.1081067,Making Sense of AI in Public Clouds,31 December 2017,0
"Volume 1 of National Institute of Standards and Technology (NIST) Special Publication (SP) 500–293, US Government Cloud Computing Roadmap, highlights that boundaries in a cloud ecosystem are more complex and therefore renders traditional risk management mechanisms, such as perimeter-based defense mechanisms, less effective.5 Moreover, in a cloud ecosystem, the complex relationships among cloud actors,6 the actors' individual missions, business processes, and their supporting information systems require an integrated, ecosystem-wide risk management framework (RMF) that addresses all cloud actors' needs. As with any information system, for a cloudbased information system, cloud actors are responsible for evaluating their acceptable risk, which depends on the threshold set by their risk tolerance to the cloud ecosystem-wide residual risk.",10.1109/MCC.2015.122,Managing Risk in a Cloud Ecosystem,2 February 2016,0
"These additional facts bring to light the dichotomy between enterprises' need/desire to migrate high-value data into cloud workloads to realize the promise of increased productivity and operational efficiency, while at the same time fearing the risks associated with operation of the cloud models used to host this data. In addition, a general lack of knowledge and understanding of cloud computing is keeping many organizations from adopting and using cloud platforms and services overall.",10.1109/MCC.2016.21,The Hybrid Cloud Security Professional,26 February 2016,0
"The networked manufacturing framework,3 illustrated in Figure 1, interconnects the strategic centers of an enterprise, enabling it to operate at a worldwide scale. This is different from a logistic network, where products are exchanged to lower production costs. The networked manufacturing framework envisions the exchange of products, associated services, and knowledge to improve productivity, flexibility, and competitiveness. Networked manufacturing is a concrete realization of distributed manufacturing where a network is used to integrate production and shipping facilities, with the headquarters playing the role of centralized manager for the overall network by monitoring and adjusting the day-to-day contingencies and activities.",10.1109/MCC.2016.79,"Cloud Manufacturing: Security, Privacy, and Forensic Concerns",19 September 2016,0
"Recent advancements in container technologies and the capability to overcome limitations in virtualization have, perhaps, encouraged the use of containers in the cloud for software development and deployment. This might also have paved the way for the adoption of a microservice architectural paradigm in cloud-hosted software by lowering infrastructure and maintenance costs.2, 5, 6 For example, microservices support the realization of small (sized) applications that are fine-grained and loosely coupled and communicate through REST protocols. These applications are implemented using APIs provided by the infrastructure-as-a-service (IaaS) layer for provisioning data computing, storage, and delivery capabilities.",10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
"Currently, cloud providers employ access controls to prevent unauthorized access to data and services, and containment mechanisms to prevent data leaking between tenants (those consuming cloud services) using a shared infrastructure. But these tend to be security rather than compliance focused and typically apply only at specific application, system, or user boundaries. Further, cloud services tend to be opaque and black box in nature. Despite some management tools (which depend on the service model/application), there's typically little scope for tenants to visualize, let alone specify, how data should be managed once within the cloud, or the precise circumstances in which data can be transferred.",10.1109/MCC.2015.69,Data Flow Management and Compliance in Cloud Computing,16 September 2015,0
"Just as the shift from first platform (mainframe) to second (client-server) changed everything about the way that software is constructed and managed, so does the shift to third platform. Software practitioners must learn a whole new set of design patterns as well as master new software engineering and management tools and methodologies to remain effective. Ultimately our aim is to provide reliable digital solutions even while the infrastructure they are running on is unstable.",10.1109/MCC.2017.4250927,Realizing Software Reliability in the Face of Infrastructure Instability,1 December 2017,0
"One factor that drives the interest in distributed led-ger-based methods is the ease with which they can be added to existing workflows and data processing life-cycles. This consideration may be more important, in the long run, than the current emphasis on inventing entirely new business models based on such methods.",10.1109/MCC.2017.3791019,Blockchain Standards for Compliance and Trust,12 October 2017,0
"With data also produced at the edge, both data generation and consumption can occur at many different places and times. In this context, different applications can have different requirements, especially in terms of response time. Currently, applications often rely on the cloud to have data and processing support, which may not be suitable for lower latency requirements. Moreover, execution of applications in cloud data centers does not take user mobility into consideration, and data or processing of an application can occur at a geographically distant data center. On the other hand, in a distributed computing scenario at the edges of the network, data distribution and processing can be maintained closer to the user, reducing network traffic to data centers and improving application response times as a result of lower network latency or delay.",10.1109/MCC.2017.27,Mobility-Aware Application Scheduling in Fog Computing,26 April 2017,0
"At present, there are few solutions to address the challenges of secure data sharing and searching in clouds. Typically, to ensure confidentiality of shared data, symmetric key,6 public key,7 and homomorphic8 encryption-based mechanism are currently used. Access control policies based on access control list9 and dynamic attribute10 are used for access control purposes. Searchable encryption based on symmetric11 and public12 keys are used for searching the desired data. In all these schemes, for data security, major security-oriented processing such as encryption, decryption, and access control mechanisms are handled by the user's device itself. In IoT, the resource-limited smart devices cannot handle these computation intensive operations because the security-oriented operations will increase the heavy computational burden.",10.1109/MCC.2017.9,Secure Data Sharing and Searching at the Edge of Cloud-Assisted Internet of Things,15 March 2017,0
"Traditionally, deep learning has successfully been used in many application domains, including computer vision (e.g., facial recognition) and language modeling (e.g., speech recognition), and medical image analysis. However, these complex and well-engineered approaches required substantial effort in selecting handcrafted features.4 The recent advent of technologies such as the Internet of Things (IoT), high-speed communication, and mobile devices with the capability of running machine learning frameworks (e.g., the Apple iPhone Core Machine Learning [Core ML] toolkit) has dramatically increased the availability of different types of medical data. These include electronic health records (EHRs), imaging (e.g., x-ray and ultrasound), sensor data (including that from wearable devices), text data (e.g., doctors' scripts), social media, blogs, online surveys, and traditional repositories. Increased access to such biomedical data underpinned by advances in deep learning technologies (such as the new Inception v3 model based on GoogLeNet) has renewed interest in deep learning in the world of biomedicine by providing solutions and helping researchers analyze medical data to understand, treat, and predict diseases.4, 5",10.1109/MCC.2018.1081070,Deep Osmosis: Holistic Distributed Deep Learning in Osmotic Computing,31 December 2017,0
"In the cloud computing model, users access services according to their requirements, without knowing where the services are hosted or how they’re delivered.1,2 An increasing number of IT vendors (such as Amazon, GoGrid, and Rackspace) promise to offer information and communication technology (ICT) resources such as hardware (CPU, GPUs, storage, and network), software (databases, streamprocessing systems, and data-mining frameworks), and applications (email, video on demand, and social networking). These services are referred to as infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS). Figure 1 shows the layered architecture of the cloud computing model.",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"We have simulated and compared our proposed algorithm TRETA with Min-Max, Min-Min, MCT, and FCFS heuristics using the CloudSim 5.0 [4]. We have used real-world traces of Nasa Ames iPSC/860 which is one of the popular and a De Facto workload trace for carrying out experimenting in domain of task scheduling [5]. The experimentation is done for large task sizes which improve the accuracy of the results due to variations in tasks. The rest of this paper is organized as follows.",https://doi.org/10.1109/SmartCloud49737.2020.00015,An Efficient Task Scheduling Algorithm using Total Resource Execution Time Aware Algorithm in Cloud Computing,27 November 2020,0
"In principle, one might wonder why we need cloud-based cryptography at all. Historically, encrypted data was stored on servers that resided on premises over which the data owner had direct control; using the public cloud as a direct virtualization of such servers might therefore look like an attractive option. In this scenario, data owners would simply have to select one or more untrusted cloud providers and encrypt their data before sending it to the cloud for storage or processing. Unfortunately, despite recent advances in the area of fully homomorphic encryption (FHE), a single untrusted cloud provider that isn't allowed to decrypt customer data will be unable to deliver most commercial processing services.",10.1109/MCC.2016.89,Securing Cryptographic Keys in the Cloud: A Survey,19 September 2016,0
"This article describes and evaluates a proof of concept of the rescue worker interface (RWI), a cloud-based service and mobile application that leverages the SCUBA framework to access BASs and provide real-time monitoring and control capabilities in a clear, holistic, and unified view of the emergency, increasing the contextual and situational awareness of fire wardens. The RWI also provides additional features to assist communications, coordination, decision making, and management of building evacuations.",10.1109/MCC.2014.67,A Cloud-Enabled Building and Fire Emergency Evacuation Application,30 November 2014,0
"In earlier work, we studied some 21 existing attack taxonomies for traditional computing systems published between January 2003 and April 2014.[6] In addition to several key taxonomy characteristics identified in the literature, we believe that a taxonomy should be purposeful because the taxonomy's purpose can significantly impact the level of detail required. For example, in our review, we found that taxonomies without a clearly stated purpose are generally less useful and comprehensible.",10.1109/MCC.2015.2,Cloud Attack and Risk Assessment Taxonomy,22 April 2015,0
"Moreover, even if the cost savings are dramatic, their impact barely moves the needle on overall corporate financials. Since IT costs typically average roughly 4% of revenue, a compelling 25% cost reduction in IT only represents a 1% impact on the company. This is good for a CFO, CIO, or procurement executive's performance review, but not enough to guarantee business success in the world of global hyper-competition and disruption that most companies find themselves in.",10.1109/MCC.2018.043221018,Revenue Growth is the Primary Benefit of the Cloud,14 August 2018,0
"The most common solution for enterprise organizations seeking to mitigate cloud security threats currently involves building a virtual infrastructure inside an existing corporate firewall (see Figure 1). With this approach, enterprise perimeter-protected datacenters host cloud services and/or are used to virtualize applications. These services and applications are accessible only to users who have been properly authenticated and securely admitted to the corporate intranet. This is a mature security approach that's consistent with existing protection strategies for all other enterprise assets.",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"Some consider “private cloud” to be a misnomer. However, many of the key criteria of cloud still apply, such as dynamic allocation of resources from a common pool and pay-per-use pricing through either a commercial transaction or chargeback to an internal customer. A basic question facing most IT shops today is whether to use their own datacenters, a public cloud provider, colocation facilities, or all of the above.",10.1109/MCC.2014.91,The Nuances of Cloud Economics,30 November 2014,0
"A possible solution to augment the scalability of CDCs lies in taking advantage of the ever-increasing computational and storage capabilities available at the network edge.2, 3, 4 We note in the previous instalment of “Blue Skies” sensing and networking devices available at the network edge constitute a new type of computing infrastructure, the Edge Datacentre (EDC).5 An EDC may vary in scope and capability, including gateways (Raspberry Pi 3, UDOO board, esp8266, Meshlium Xtreme, Arduino), software defined network solutions (e.g. Cisco IOx), or smart phones equipped with sensors. To facilitate highly distributed and federated computing environments, we proposed Osmotic Computing paradigm5 that enables the automatic deployment of microservices over inter-connected EDC and CDC. The benefits of integrating EDC and CDC has already been recognised by several companies and open source initiatives, including CISCO, AWS1, and Google3, and the OpenFog Consortium.4 For example, AWS has enriched its CDC offerings with near-edge computing and storage capabilities (i.e., Snowball Edge, Greengrass).",10.1109/MCC.2017.22,Osmotic Flow: Osmotic Computing + IoT Workflow,26 April 2017,0
"The cloud-assisted Internet of Things (IoT) provides a promising solution to data booming problems for the ability constraints of individual objects. However, with the leverage of cloud, IoT faces new security challenges for data mutuality between two parties, which is introduced for the first time in this paper and not currently addressed by traditional approaches. We investigate a secure cloud-assisted IoT data managing method to protect data confidentiality when collecting, storing, and accessing IoT data while limiting to effects of IoT scalability. We further present numerical results to show that the method is practical.",10.1109/MCC.2018.111122026,"Secure Data Collection, Storage and Access in Cloud-Assisted IoT",12 January 2018,0
The physical location is a critical factor that affect an organisation's decision to adopt cloud computing for several reasons. First there are no international policies or regulations for data protection in cloud. Second the fact that some of the cloud providers store the data in another country without disclosing this to the end users [19].,https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"One of the key grand challenges is how we ensure that users trust the IoT ecosystem to make the right decisions and act on them. This involves trusting devices, data and analytics, as previously identified in this column.1 The focus of this article is to analyze different research and technical issues related to managing trust using blockchain in a fully decentralized IoT ecosystem.",10.1109/MCC.2018.043221010,IoTChain: Establishing Trust in the Internet of Things Ecosystem Using Blockchain,14 August 2018,0
"This classification must be taken into account when constructing a self -healing computing process. Depending on the availability of access to physical infrastructure, computing and network resources, development tools, system and applied software, various levels of control of computing processes are possible.",https://doi.org/10.1109/SCM58628.2023.10159053,Model of a Self-Healing Computing Process of a Cloud Computing System under Conditions of Information and Technical Impacts,26 June 2023,0
"In this subsection, Cloud Computing is formalized and defined, and we explain the challenges for Cloud Computing with referenced research studies. Cloud Computing has a wider meaning within the IT industry in general since many organizations in enterprises have a different expectation and perspective for Cloud Computing. It refers to both the applications delivered as services over the Internet and the hardware and systems software in enterprise data centers that provide those services [2]. It has three compelling use cases: (1) Service demand varies with a time and the system has to support its demand. (2) IT resource demand is unknown in advance. For example, the Web site needs to support a spike for the demand. (3) Scale-out workload would like to run on Cloud Computing to be finished with multiple faster processors. National Institute of Standards and Technology (NIST) defines Cloud Computing with five essential characteristics, three service models and four deployment models as an architectural model [3]. Those five essential characteristics are on-demand self-service, broad network access, resource pooling, rapid elasticity and measured service.",10.1109/CLOUD.2014.105,Industry Cloud - Effective Adoption of Cloud Computing for Industry Solutions,4 December 2014,0
"Most IT departments are forced to spend a great deal of time and energy on its implementation, maintenance, and upgrade projects that too often don't add significant value to the company's bottom line[1]. Increasingly, IT teams are turning to cloud computing technology to minimize the time spent on lower-value activities and allow IT to focus on strategic activities with greater impact on the business.",10.1109/ICCASM.2010.5623257,The comparison between cloud computing and grid computing,4 November 2010,0
"Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (for example, networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model promotes availability and is composed of five essential characteristics [on-demand self-service, broad network access, resource pooling, rapid elasticity, and measured service], three service models [cloud software as a service, cloud platform as a service, and cloud infrastructure as a service], and four deployment models [private cloud, community cloud, public cloud, and hybrid cloud].",10.1109/MIC.2010.113,Cloud Computing: The New Frontier of Internet Computing,2 September 2010,0
"Generally, green computing can be defined based on studying and practicing the design, use, and dispose of servers, computers, and associated components including storage, network, and communication devices in an efficient way with least impact on the environment. Lowering energy usage while rising energy efficiency in computing components, applications, and also their executions is considered one of the significant aims that can be achieved using various energy saving techniques [20] [21]. Energy conservation, cost reduction, and environment protection are the main goals that can be gained from reducing the energy consumption. As mobile clouds include mobile devices, networks, and computing server infrastructures, investigators should pay a special attention to MCC energy conservation taking in consider the significant body size of mobile devices and the underlying large-scale network and computing infrastructures. In MCC, energy consumption can be categorized based on various aspects [22]: Mobile devices and computing, Mobile cloud service applications, Cloud computing infrastructures and servers, and Network infrastructures and communications.",10.1109/MobileCloud.2017.26,Energy-Aware Fault Tolerant Task offloading of Mobile Cloud Computing,12 June 2017,0
"There are many authentication techniques such as biometric based, password based, token based, transaction based, image based, special text based etc. are being used in cloud computing environments to achieve data security. These mechanisms guarantee high level of data protection and data security",10.1109/ICCCNT49239.2020.9225396,Detection and Prevention Mechanisms for DDoS Attack in Cloud Computing Environment,15 October 2020,0
"As Weinman [2] had noticed, the utility pricing or Pay-As-Your-Go (PAYG) is not the only possible model for the cloud. Some firms have begun to explore their marketing strategy to support “pay-what-you-like”. He indicated one of the important lessons that CSPs should learn from other industries is that relying on innovative cloud services and technologies is not enough. CSP has to also come up with new pricing models for their services. This means that CSPs should “move beyond competition just on price to competition on pricing.” The question of how to move beyond competition just on price leads to the idea of how to establish innovative pricing models for cloud services. The primary objective of cloud pricing model is to capture cloud service values along with its pricing variation as well as the dynamic nature of cloud technology development.",10.1109/TCC.2018.2858266,Hedonic Pricing of Cloud Computing Services,23 July 2018,0
"While several research efforts have been made regarding the interaction between cloud computing and semantic technologies, it is vital to classify the different interaction types and their implications. This classification provides a basis for a better understanding of the two technologies and enhance further interaction efforts among them. The modes of interaction between cloud computing and semantic technologies can be categorised into three types as follows.",10.1109/DeSE51703.2020.9450748,A Cloud Computing Capability Model for Large-Scale Semantic Annotation,14 June 2021,0
"As cloud offerings proliferate, there will be ongoing challenges with interoperability, portability, and migration. To be sure, interoperability is also an issue for on-premise applications, but this challenge is magnified in the cloud. In an on-premise model, enterprises control their infrastructure and platforms at any time. In the cloud, they're locked in to a provider and no longer control their own IT.",10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"The cornering recommendation algorithms have been implemented but in this paper we do not present the detail. Basically, we use a streaming processing to implement the detection of the curve. Figure 2 presents the topology of operators in the streaming processing, implemented with Apache Apex1. In particular, the operator OSMQueryOperator is used to query points of roads from Open Street Map (OSM - the Maps Provider). This operator can be parallelized -using partitioning techniques - and results from instances of this operator will be unified for the curve determination (CurvesOperator). The curve detection algorithm calculates properties of the curve including start/center-end points, radius and length. From every incoming position (specified in data tuples), it is possible that many curves can be detected and will be emitted to MongoDBOperator which stores them to the MongoDB database using the commons library code. To reduce the number of connections to the database, MongoDBOperator caches curves for a configurable time interval and then stores them in one single batch.",10.1109/CLOUD.2018.00091,Analytics of Performance and Data Quality for Mobile Edge Cloud Applications,11 September 2018,0
"The Cluster of European Research Projects on the Internet of Things considers the Internet of Things as a vital part of Future Internet and they defined it as a dynamic global network infrastructure with self configuring capabilities based on standard and interoperable communication protocols. Things in this network interact and communicate among themselves and with the environment by exchanging data and information sensed, and react autonomously to events and influence them by triggering actions with or without direct human intervention [4]. Gubbi et al. [2] have identified that to support the IoT vision, the current computing paradigm need to go beyond traditional mobile computing scenarios and Cloud Computing has the potential to address these needs, and it is able to hide data generation, processing and visualization tasks. M. D. Assuncao et al. [1] also highlighted that there are many open challenges in applying Clouds for Big Data management. Our work addresses one of their raised issues: how to store information in a way that it can be easily shared between Cloud providers.",10.1109/BDCloud.2014.41,Interoperating Cloud Services for Enhanced Data Management,9 February 2015,0
"Service definition and discovery. dmcc-schema [2] is a semantic proposal based on Linked Data to combine different schemata and vocabularies to define and compose the services. This includes elements such as algorithms, costs/prices, instances, interfaces, authentication or Service License Agreement (SLA). Data Mining services are defined using RDF/Turtle [3] or JSON-LD [4] languages, allowing a high level abstraction in aspects of service deployment or infrastructure. In this way it is possible to create service definitions for algorithms of any type (e.g. Random Forest, SVM or K-means clustering, among others), specifying the details of input and output parameters, data sets, etc.",10.1109/SERVICES.2019.00121,Delivering Data Mining Services in Cloud Computing,29 August 2019,0
"Mobile devices despite their constant hardware advances still lack the battery lifetime or the processing power provided by the bigger stationary devices. Cloud computing came into picture compensating for the hardware limitations and providing a valuable backbone that supports mobility through resource optimization and providing the functionality of accessing remote programs and resources overriding the need for any local installations/processing [1]–​[3]. Aside from computational power, this merger also allows mobile to benefit from enhanced storage capabilities, and memory enabling optimizations to save the limited battery power [4].",10.1109/3ICT.2019.8910294,A Secure Framework for Mobile Cloud Computing,25 November 2019,0
"Implementations of relational databases trace their roots to the original RDBMS designs (IBM System R and follow-ons) of the 1970s. At that time, business data processing was the only DBMS market. The main user interface device then was the dumb terminal, and vendors imagined operators inputting queries through an interactive terminal prompt. Key architectural features of the original DBMSs were disk-oriented storage and indexing structures, multithreading to hide latency, locking-based concurrency control mechanisms, and log-based recovery.",10.1109/MCC.2014.25,Today's Tidbit: VoltDB,10 July 2014,0
"This distinction bears closer scrutiny. Winston Bumpus, chair of the Board of the Distributed Management Task Force (DMTF) and senior director of Architecture and Standards at VMWare, often says (and I don't mind quoting), “you should standardize at the interfaces and innovate between the boundaries”[1] of a system or ecosystem of products. Such an approach is already central to several successful open source and commercial product sets and is a key feature of the overall framework that makes cloud computing possible—that is, the Internet itself. It can be applied to all large-scale applications, cloud stacks, and computing projects.",10.1109/MCC.2014.6,Defining Our Terms,10 July 2014,0
"Cloud Computing magazine welcomes articles covering standards and compliance. Like all the other editorial sections of the magazine, we want to recruit well-written, clear, succinct articles from leading projects and experts that illuminate our readers about the topic at hand. Although other areas might touch on standards from time to time, and many of the introductory editorials already mention such topics, articles in this part of the magazine will focus in detail on the development process used to create cloud computing standards, on their analysis and description, and on their practical use to solve real-world problems.",10.1109/MCC.2014.21,Setting Cloud Standards in a New World,10 July 2014,0
"Interconnecting multiple cloud-based datacenters lets every application owner improve overall quality of service (QoS), reliability, and flexibility of their applications. However, with the almost monthly launching of new cloud services and capabilities by both large (such as Amazon Web Services and Microsoft Azure) and small (such as Rackspace and Ninefold) companies, decision makers (application developers, CIOs, and so on) will likely be overwhelmed by the available choices. Decision making is further complicated by interoperability challenges that exist across multiple cloud providers[3]–​[6]:",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"The challenge associated with private cloud implementations is that, despite the perimeter solutions available to protect the enterprise, the typical organization is still unable to stop attacks such as advanced persistent threats (APTs) from the Internet. In addition, complex policy-based decisions made over long periods of time to allow a multitude of enterprise services and approved exceptions through the corporate firewall, combined with the increasingly common method of bypassing the perimeter using mobile devices, have rendered the enterprise perimeter essentially useless from an advanced threat perspective.",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"IT society authorized the cloud computing with ownership of establishing IT infrastructures, due to its risk free implementation [13] [14]. Henceforth, various stakeholders benefited since they paid only for what they utilized. Seamless IT resources are offered to global users as a support service via internet, helped many major and minor enterprises grow. Cloud computing offers IT solutions with proper access rights in minimal cost with increased flexibility.",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"Some of specific crawler developed for special purposes. Topical or focused web crawlers were developed to create contextual search engine or more focused result [2], [3]. These crawlers automatically navigate the hyperlinked structure of the web while using link contexts to predict the benefit of following the corresponding hyperlinks with respect to some initiating topic or theme. Context of a hyperlink or link context is defined as the terms that appear in the text around a hyperlink within a web page. Link contexts have been applied to a variety of web information retrieval and categorization tasks. Topical or focused web crawlers have a special reliance on link contexts.",10.1109/ICCCSN.2012.6215751,Building crawler engine on cloud computing infrastructure,14 June 2012,0
"Irrigation is crucial for agriculture production to ensure that farmers are able to meet crop water demands even in situations where there is inadequate rainfall. However, poor irrigation scheduling and inefficient utilization of water resources are two of several ubiquitous parameters restricting production in many agricultural regions.1",10.1109/MCC.2017.5,Cloud of Things in Smart Agriculture: Intelligent Irrigation Monitoring by Thermal Imaging,,0
"An overview of DDoS attacks against cloud targets is presented, together with solution requirements, and a guideline for efficient solutions, leading to a novel multilevel alert-flow. To orchestrate future solutions, we give a vision towards novel “Detection Near Impossible” attacks.",10.1109/MCC.2017.14,"Combating DDoS Attacks in the Cloud: Requirements, Trends, and Future Directions",15 March 2017,0
"The microservices-based approach is in contrast to the traditional “monolithic” development of applications, where each application is a single, autonomous unit. For example, in a client-server application, the server is a monolithic entity that handles HTTP requests, executes logic, and retrieves or updates its data. The problem with such monolithic architectures is that even a small modification of the application's logic requires the deployment of a new running version of the entire code base. A microservice architecture is lightweight and easily shipped and updated. Hence, it's ideal for engineering applications where we cannot fully anticipate functionalities in advance (for example, the types of devices that might one day access the application). Microservice architectures are a part of a larger shift in IT departments to-wards a DevOps culture, in which development and operations teams work closely together to support an application over its lifecycle, and go through a rapid or even continuous release cycle.",10.1109/MCC.2016.112,Open Issues in Scheduling Microservices in the Cloud,11 November 2016,0
"Generally, Electronic Medical Records (EMRs) contain medical and clinical data related to a given patient and stored by the responsible healthcare provider.1 This facilitates the retrieval and analysis of healthcare data. To better support the management of EMRs, early generations of Health Information Systems (HIS) are designed with the capability to create new EMR instances, store them, and query and retrieve stored EMRs of interest.2 HIS can be relatively simple solutions, which can be schematically described as a graphical user interface or a web service.",https://doi.org/10.1109/MCC.2018.011791712,"Cloud-Native Applications and Cloud Migration: The Good, the Bad, and the Points Between",28 March 2018,0
"To take proper advantage of a cloud platform, including infrastructure as a service and platform as a service (PaaS), you have to design the applications so that they're decoupled from any specific physical resource. For example, if you access I/O directly from a platform as Linux, you need to access the cloud's abstraction layer, or its native APIs.",10.1109/MCC.2017.4250932,Realizing Edge Marketplaces: Challenges and Opportunities,1 December 2017,0
"Cities are complex systems of systems where human, social, technical, infrastructure, and natural systems interact in complex and ever-changing patterns that generate and drive the inevitable trade-offs, compromises, and debates that accompany such decision making. This new paradigm of decision making is enabled partially through high-velocity data streams from in situ environmental monitors (climate, air quality, and traffic flow) and operational data from real-time monitored infrastructure systems (traffic signals, water flow, electrical demand, etc.). This data is coupled with models that enable predictions that are sector specific, such as a high-resolution hydrological flood model, or integrated models across multiple systems (at different levels of granularity).",10.1109/MCC.2018.064181115,The Business Case for Chaos Engineering,29 November 2018,0
"Chaos Engineering is the discipline of experimenting on a distributed system in order to build confidence in the system's capability to withstand turbulent conditions in production.1 By running chaos experiments directly on a production system in a controlled manner, you can improve your system's availability by identifying and eliminating problems before they manifest as outages.",10.1109/MCC.2018.032591616,Making Sense of AI in Public Clouds,12 June 2018,0
"Artificial intelligence (AI) is best leveraged for specific types of applications that will benefit the most from this technology. Some examples include fraud detection, predictive marketing, machine monitoring (Internet of Things), and inventory management.",10.1109/MCC.2018.1081067,Managing Risk in a Cloud Ecosystem,31 December 2017,0
"Information systems risk management (tier 3) is guided by the risk decisions at tier 1 and tier 2. Information security requirements are satisfied by the selection of appropriate management, operational, and technical security controls from standardized catalogs of security and controls.2–​4",10.1109/MCC.2015.122,The Hybrid Cloud Security Professional,2 February 2016,0
"One way to examine this trend is to think about the role of a cloud security professional in a hybrid cloud environment. The National Institute of Standards and Technology (NIST) defines a hybrid cloud environment as a “composition of two or more distinct cloud infrastructures (private, community, or public) that remain unique entities, but are bound together by standardized or proprietary technology that enables data and application portability.”3 According to the Gartner IT Glossary, hybrid cloud computing “refers to policy-based and coordinated service provisioning, use and management across a mixture of internal and external cloud services”",10.1109/MCC.2016.21,"Cloud Manufacturing: Security, Privacy, and Forensic Concerns",26 February 2016,0
"Models such as networked manufacturing started as intrafirm organizational models to address the globalization needs of enterprises, but later evolved into a collaborative approach between firms. The issues and challenges of the current economic environment are making it more difficult to run small and medium enterprises (SMEs), since they don't have the skills and resources required to compete against larger enterprises. Therefore, SMEs are joining efforts and capabilities to overcome their limitations through collaboration, which can be short term or more stable and durable.",10.1109/MCC.2016.79,Trends and challenges in cloud datacenters,19 September 2016,0
"To overcome these challenges, researchers have proposed various new DC architectures, such as FatTree, DCell, FiConn, Scafida, and JellyFish.[2] However, these proposed DC architectures overcome only a fraction of the challenges faced by legacy DC architectures. For instance, the FatTree architecture delivers high bisection bandwidth and a 1:1 oversubscription ratio, but it lacks scalability. The DCell, FiConn, Scafida, and Jellyfish architectures, on the other hand, deliver high scalability but at the cost of low performance and high packet delays with high network loads.",10.1109/MCC.2014.26,A Cooperative Fog Approach for Effective Workload Balancing,10 July 2014,0
"These works introduce the fog computing paradigm and it's potential. However, fog hosts are not as computationally powerful as the ones offered by massively distributed cloud infrastructures. Load balancing techniques, including resource management methods, messaging architectures and smart task profiling for different scenarios, are still open issues for fog computing. In this article, we focus on these issues, and present a novel architecture of a fog-enabled platform that can be used by IoT networks to perform complex and demanding computational tasks. Smart devices are connected to specific message topics, via the publish-subscribe (Pub/Sub) pattern and the Message Queue Telemetry Transport (MQTT)2 connectivity protocol, which enables them to send and receive MQTT compliant messages asynchronously. These smart devices also have the ability to send a small piece of code that implements the set of collected data. When received by the platform, this small piece of code is forwarded to the most suitable host for execution, whether is a VM on the Cloud or a device on the Edge of the network.",10.1109/MCC.2017.25,A Cooperative Fog Approach for Effective Workload Balancing,26 April 2017,0
"The growing adoption of microservices in the cloud is motivated by the ease of deploying and updating the software, as well as the provisioned loose coupling provided by dynamic service discovery and binding. Moreover, structuring the software to be deployed in the cloud as a collection of microservices allows cloud service providers to offer higher scalability guarantees through more efficient consumption of cloud resources, and to dynamically and quickly restructure software to accommodate growing consumer demand. Structuring software in smaller computation units enables optimized allocation of the application components within proper containers in the virtual machines (VMs) running on top of the host machine provided by the cloud infrastructure, as the example in Figure 1 illustrates. This lets us minimize waste of resources and maximize packing of the components within a single VM. This is possible because, despite having to realize the same application tasks, microservices are typically thinner than conventional software components because they use lightweight software technologies and platforms. This model also allows a simpler and faster migration of software component instances from one VM to another to satisfy cloud applications' changing resource demands.",10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
"Tenants and providers must ensure and demonstrate that they meet their legal and regulatory obligations. However, current technical mechanisms offer limited means for controlling data from afar, and insufficient tools for determining compliance and/or apportioning responsibility. This means that provid-ers-and potentially their whole supply chain-must be trusted to act appropriately. This not only hinders accountability, but also represents a barrier to cloud adoption, particularly for personal data use and for industries such as healthcare and finance, where additional regulatory requirements pertain.",10.1109/MCC.2015.69,Data Flow Management and Compliance in Cloud Computing,16 September 2015,0
"Today we are in the midst of the next radical change as the industry moves from client-server to cloud-native. Sometimes called the third platform, cloud-native is characterized by highly dynamic systems, where every element, from the hardware and operating system, to networks and software deployments, are in constant flux. Whereas for second platform systems (client-server), software was written with an expectation that the systems that it executed on were quite stable, in the new world software must be written, deployed, and managed in a manner that anticipates change. That is, the software that runs on a highly distributed, constantly changing infrastructure must have zero downtime even while the lower layers are shifting about. In fact, applications must have zero downtime even while the application itself is changing, due either to an upgrade being performed, or to the application itself experiencing trouble (there's a bug!).",10.1109/MCC.2017.4250927,Realizing Software Reliability in the Face of Infrastructure Instability,1 December 2017,0
"Distributed methods carry the advantage of being useful in multiple, physically separated settings, but require the existence of methods to determine that a given transaction is complete. Blockchains have become popular precisely because they provide noncentralized, independently verifiable capabilities to ensure the integrity and consistency of distributed ledgers and the associated transactions.",10.1109/MCC.2017.3791019,Blockchain Standards for Compliance and Trust,12 October 2017,0
"With increasing focus on Internet-of-Things (IoT), countless devices scattered and connected to the Internet, producing and consuming data requires scalable resource management at unprecedented levels.1 The data dynamism and heterogeneity resulting from this expected explosive expansion of connected devices, commonly referred in a broad sense as Big Data, also requires new processing models and infrastructures to support its main dimensions: data volume, velocity, and variety. One key aspect of this new era is that both data consumption and production are heavily distributed and at the edges of the network (i.e. closer to or at end-user devices). While the centralized data center model of cloud computing can cope with many types of applications and large amounts of data, its infrastructure and network connection to the edge are not designed to handle this Big Data phenomenon. In this context, computing and data management models that support computing capacity at the edges of the network are now a focus of significant research. Mobile clouds, vehicular networks, and fog computing are examples of new distributed computing models that leverage edge capacity closer to data production.2",10.1109/MCC.2017.27,Mobility-Aware Application Scheduling in Fog Computing,26 April 2017,0
"When the IoT smart devices share data with other devices, potential security issues arise such as data leakage, modification, integrity, and unauthorized access.5 Hence, it is essential that such shared data be ensured confidentiality, integrity, and access control while sharing at the edge. Furthermore, a secure data-searching technique is needed to search and retrieve the shared data by authorized devices.",10.1109/MCC.2017.9,Secure Data Sharing and Searching at the Edge of Cloud-Assisted Internet of Things,15 March 2017,0
"Deep-learning-based applications (applications that have been developed using deep learning technologies) have been highly reliant on the availability of hybrid high-end machines with an array of GPUs. Cloud computing has played an important role by providing the necessary high-end processing capabilities on demand to support the growing array of deep-learning-based applications. Moreover, though deep learning technologies have been proven to produce higher levels of accuracy, especially when analyzing medical imaging datasets, the algorithms generally need to be trained with significantly large amounts of data. For example, well-known Apple Siri and Google Now6 are typical examples of cloud-reliant, deep-learning-based applications. These cloud-only approaches require large amounts of data to be sent to the cloud over wireless networks. This not only places enormous stress on the wireless network but—as we move into more complex applications, such as in the biomedical domain—also raises several security and privacy concerns (e.g., sharing data over public wireless networks). The approach to move data to the cloud to facilitate deep analysis is expensive and proving to be infeasible because of limitations in Internet bandwidth, as well as because of concerns pertaining to data security and privacy.",10.1109/MCC.2018.1081070,Deep Osmosis: Holistic Distributed Deep Learning in Osmotic Computing,31 December 2017,0
"Experimental results for encryption and decryption using our proposed method, HVCCE have been described below. To encrypt a plain text message using the HVCCE Encryption Method, three phases to be followed which are explained in subsection A, B, C. Each phase provides an added extra level of security to the Final Encoded Message. Decryption process of the cipher text into plain text needs three phases of decryption which are produced in subsection D, E, F.",https://doi.org/10.1109/CUBE.2013.20,Designing of Cryptography Based Security System for Cloud Computing,9 January 2014,0
Hamid et al. [8] proposed a new cooperative traffic information system (CTIS) to overcome the drawbacks of existing approaches such as less robust and unstable structure of vehicles. The main objective is to introduce a hybrid approach to calculate the traffic density on the roads and to maintain the traffic information in optimum way. This scheme is limited to particular area or within range of the system. Willke et al. [9] proposed an approach for improving the applications and protocols that related to inter-vehicle communication (IVC) so as to match the best requirements of the users. They proposed a technique for providing a taxonomy of various IVC applications.,https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"Using multiple cloud providers for decryption could be seen as a viable alternative. Much research has been done in scenarios where multiple untrusted cloud providers together with combinations of FHE, secret sharing, and other secure multiparty computation (SMC) techniques are used to process encrypted data without decryption. However, the sheer complexity of these solutions in terms of multiparty cloud service contracts and service-level agreements (SLAs) has until now hindered their practical deployment.",10.1109/MCC.2016.89,Securing Cryptographic Keys in the Cloud: A Survey,19 September 2016,0
"Standardization efforts in this area include the Open Virtualization Forum (www.dmtf.org/standards/ovf). OVF describes an open, secure, portable, efficient, and generic format for packaging and distributing software resources at the PaaS and IaaS layers (see Figure 1). Although many cloud vendors (Microsoft, IBM, Dell, HP, VMware, and Xen, among others) have supported the OVF initiative, its popularity and adoption rate are still uncertain. To overcome this heterogeneity in virtualization format and technology, providers such as Amazon, RightScale, and CloudSwitch offer custom scripts that can be used to manually port a software resource from one virtualization format to another. Some datacenter vendors, such as HP and Rackspace, strongly recommend OpenStack as the virtualization technology for solving public-private cloud interoperability challenges. However, it seems unlikely that other leading vendors, such as Amazon, Microsoft, and VMware, will adopt OpenStack in the near future.",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"Building management is becoming both increasingly sophisticated and more reliant on automation. Structures are regularly fitted with many sensors and controllers that send vast amounts of data to building automation systems (BASs). Traditionally, monitoring and control systems for energy management, security, and safety coexist as separate subsystems with little cooperation between them. However, demand for more robust and interoperable systems is increasing because these systems result in more optimal and effective deployments of equipment, thereby reducing the number of required devices, energy consumption, and cost.",10.1109/MCC.2014.67,A Cloud-Enabled Building and Fire Emergency Evacuation Application,30 November 2014,0
"In this architecture, mobile devices obtain resources and services from a remote cloud data center. As illustrated in Figure 1, mobile devices connect to the backbone network via WiFi access points or 4G cellular networks to access the cloud resources, and then utilize the abundant resources to help deal with a large amount of data. This kind of architecture came into being accompanied by the proposed concept of cloud computing.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"A taxonomy classifies and categorizes the different aspects of a given problem domain, and serves as a basis for a common and consistent language.[2] Because identifying the threat is typically the first step in a proactive risk management strategy, it's of little surprise that there are a number of publications on this topic that vary in scope, purpose, depth, and breadth. For example, Maria Kjaerland's cyberattack taxonomy uses CERT statistics to improve the understanding of attack morivations[3]: Jelena Mirkovic and Peter Reiher's taxonomy lets users examine and classify distributed denial of service (DDoS) attacks and countermeasures[4]; and Venkat Pothamsetty and Bora Akyol's taxonomy for network protocol vulnerabilities and countermeasures is designed primarily for network protocol engineers.[5]",10.1109/MCC.2015.2,Cloud Attack and Risk Assessment Taxonomy,22 April 2015,0
"A typical, but simplistic view says that the economies of scale that large cloud service providers achieve drive down the unit cost of compute.1 This logic does have some truth to it, but is flawed on several levels. First, cloud providers enjoy cost advantages not only through economies of scale, but also through better utilization through aggregation of statistically uncorrelated workloads, as well as selling spare cycles through mechanisms such as “spot instances.” They also can enjoy economies through greenfield siting, where power and land are cheap, and tax benefits may be conferred by local authorities. However, large diversified enterprises with sufficient technical competence, operations capabilities, purchasing power, etc., can enjoy similar cost advantages. Moreover, enterprises doing it themselves don't have to pay the additional cost structure penalty comprising a cloud service provider's profit margin and general, sales, and administrative expenses.2 As a result, real-world experience is mixed, with some saving money by moving to the cloud and others saving money by moving out of public clouds.3 Many others do best with a hybrid strategy that can offer an optimal balance of lower costs through fixed resources for baseline demand and elastic pay-per-use resources for variable demand beyond the baseline.4 Still others use a multicloud approach, either to cobble together digital support for an end-to-end workflow,5 for reliability, or to arbitrage price differentials among cloud service providers.6 Many use a combination of all of the above, leading to a mix of private and public, multiple public clouds, and centralized facilities and dispersed ones—the hybrid multicloud fog.7",10.1109/MCC.2018.043221018,Revenue Growth is the Primary Benefit of the Cloud,14 August 2018,0
"Despite the success of these cloud-based initiatives and services, concerns remain about security protection. The financial services community, for example, is engaged in a vigorous debate about whether public cloud services are secure enough for financial applications.’ The specific cloud threats generally cited include the compromise or unauthorized modification of cloud-resident financial data, as well as the possibility that denial-of-service attacks will cause cloud-resident financial data to become unavailable.",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"The cloud's financial and strategic benefits have been the catalysts for its explosive growth, and pay-per-use pricing, sometimes referred to as measured service,[1] is a core attribute. Some say that cost reduction and business agility are the two most important benefits of the cloud,[2] some argue that economies of scale from large providers are the main drivers of cloud benefits,[3] and others therefore conclude that eventually all IT should and will move to the cloud.[4] However, the theory and practice of cloud economics are considerably more nuanced, and encompass numerous challenges, ranging from the practical to the theoretical, across service architecture, statistics, behavioral economics, computing foundations, game theory, business strategy, and regulatory policy.",10.1109/MCC.2014.91,The Nuances of Cloud Economics,30 November 2014,0
"Sinc virtual machine as a server has been established, we should implement business logic. Amazon cloud computing platform can be called by AMI which is able to acess Web Services. In order to achieve online trading by Web Services, Amazon cloud computing platform denotes each party in transaction making use of cryptographic strings called token. In addition, token contains not only the identity of transaction parties, but also a number of conventions such as who will pay the commission of callers.",https://doi.org/10.1109/APWCS.2010.15,A New Architecture of Online Trading Platform Based on Cloud Computing,7 June 2010,0
"As IoT expands into various application domains such as healthcare, utility grids, cities, agriculture, transportation, industry 4.0, and disaster management, need for investigating on-the-fly computation over the IoT data streams is ever more pressing. Indeed, most IoT applications are modeled as data transformation workflows that consists of: i) multiple interdependent, heterogeneous data analysis computational and programming models that realise various data transformation tasks from data ingestion to analysis, ii) virtualised/non-virtualised computational and network infrastructure, iii) communication media of various kinds (including wireless). Currently, powerful Cloud Datacentres (CDCs, e.g. AWS1) provide computation and data storage resources for IoT workflows, but they suffer from limited bandwidth and network latency, and support neither latency-sensitive applications nor applications that rely heavily on the data streaming from IoT data sources for computing intelligence in real-time (in the form of data ingestion and data analysis).",10.1109/MCC.2017.22,Osmotic Flow: Osmotic Computing + IoT Workflow,26 April 2017,0
"Recently, versatile IoT systems have been widely deployed in daily life, for example, in health care and traffic monitoring, which generate giga-level high-definition images and videos every minute. Massive IoT data require impractically large storage and high-performance computation that a normal user or smart object within IoT hardly supports. Cloud-assisted IoT is popularly applied to leverage the computation and storage capability of a cloud for massive IoT data.1 A cloud is a powerful platform that can provide additional conveniences as a data distribution delegate. When an IoT user has legal requests for certain data being collected, stored, and accessed, he can directly delegate the requests to the cloud at any time with greater convenience.",10.1109/MCC.2018.111122026,"Secure Data Collection, Storage and Access in Cloud-Assisted IoT",12 January 2018,0
"The number of Internet of Things (IoT) devices has already exceeded the world population. With rapid advancement in hardware technologies, these smart devices have been applied in almost every aspect of our daily lives. A large amount of data is generated every second and data science research is actively defining algorithms to process such data to make and enact better decisions for us in our daily activities. For example, wearable smart devices such as smartwatches sense our heartbeat and blood pressure continuously to monitor our health condition; a smart fridge enables us to control the fridge remotely and plan a healthier diet; a smart air conditioner can track our living preferences and adjust the temperature automatically; an autonomous vehicle frees our hands and minds while making our journey safe.",10.1109/MCC.2018.043221010,IoTChain: Establishing Trust in the Internet of Things Ecosystem Using Blockchain,14 August 2018,0
"The paper proposes “Industry Cloud” which can support those industry solutions efficiently since they are required to provide the service business with the solution to customers for enterprises. Figure 1 shows the layer architecture for Ordinary Cloud which is equal to Cloud Computing and Industry Cloud. In Figure 1, Ordinary Cloud has the hardware, cloud infrastructure layer. There is a workload on top of the cloud infrastructure and the hardware layer. On the other hand, Industry Cloud has the Industry Specific Layer between Cloud Infrastructure and Industry Solution. The layer which is described in this paper provides a common service among industry solutions among multiple industries. The paper consists of the “Background” section which describes the background for Cloud Computing and industry solutions, the “Industry Cloud” section which proposes Industry Cloud which can provide the better service for industry solutions, the “Use case scenario” section which describes three use case scenarios in electronics and retail industry for Industry Cloud, the “Discussions” section which discusses the proposed approach, and the “Conclusion” section which has the conclusion for the paper.",10.1109/CLOUD.2014.105,Industry Cloud - Effective Adoption of Cloud Computing for Industry Solutions,4 December 2014,0
"Grid computing is a network that is not in the same place but distributed resources such as computers, peripherals, switches, instruments, and data. Its resources may be owned by diverse organizations. Grid can be viewed as a special type of middleware that enable sharing and manage grid components based on user requirements and resource attributes.",10.1109/ICCASM.2010.5623257,The comparison between cloud computing and grid computing,4 November 2010,0
"Cloud services can be accessed by mobile users in the current MCC architecture in two ways: mobile network or access points. When mobile users utilize mobile network to access cloud services, their devices whether it's cellular or satellite require a satellite link or base station to get Internet connection which is used to get access to various cloud services [11]. The issue with this network is charging users extra cost for data traffic. On the other hand, access points such as Wi-Fi network can be used to get Internet connectivity due to its connection to the Internet service provider [12]. Using this network offers low latency, less energy consumption, and no extra cost compared to mobile network. Thus, it is more preferred by mobile users who want to get Internet connection whenever they are accessible [13].",10.1109/MobileCloud.2017.26,Energy-Aware Fault Tolerant Task offloading of Mobile Cloud Computing,12 June 2017,0
"There also exist service and security risks due to the concept of virtualization technology. Many virtual machines are being created based on the cloud user's requirement and demand. The problem with scale up of virtual machine is that they may be corrupted, accessed, lifted, stolen or manipulated by any means of contact in the cloud network which tops up security and privacy issues",10.1109/ICCCNT49239.2020.9225396,Detection and Prevention Mechanisms for DDoS Attack in Cloud Computing Environment,15 October 2020,0
"Our observation shows that the revenue growth of Amazon Web Services (AWS), one of the leading global CSPs, has a positive correlation with its cloud characteristics (See Fig. 1). This means various cloud service features, such as PAYG, burstable CPU, data center global footprint, GPU, one account for all location, etc. (Notice that the number of characteristics has been increased from just a few in 2006 to more than thousand in 2017 due to AWS’ continuous cloud innovation [24]). The basic question is “Will the cloud characteristics impact its service price or customer willingness to pay (W2P)?” If so, what is the relationship between cloud characteristics and its service prices? Most importantly, how we can calculate or estimate the values of these characteristics. One of the solutions is a so-called hedonic model. The compelling reason to propose the hedonic model is that it can capture non-market values (extrinsic values) for the cloud ecosystem and evolutionary characteristics that either directly or indirectly impact on its service prices.",10.1109/TCC.2018.2858266,Hedonic Pricing of Cloud Computing Services,23 July 2018,0
"There are 2 types of cloud models i.e. service models and the other is deployment models. The deployment models include: Public, Private, Hybrid and Community models. The service models include: IaaS, PaaS and SaaS.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"This defines semantic technologies’ usage in the cloud, with a basic level of interaction, in which semantic-driven software and applications are run from a cloud platform. Semantic driven in this context implies that the software or application has been developed based on one or more technologies from the semantic web stack. In most cases, these will be on the Software-as-a-Service (SaaS) model. This level of interaction is only basic, as the software or application can easily be migrated to another platform, either cloud or non-cloud.",10.1109/DeSE51703.2020.9450748,A Cloud Computing Capability Model for Large-Scale Semantic Annotation,14 June 2021,0
"For some companies, especially smaller organizations with limited resources, data may be safer with a cloud provider than on premises. But for organizations whose existence depends upon safeguarding customer data, trade secrets, classified information, or proprietary information, public cloud providers don't offer sufficient protection. Most providers find it hard, if not impossible, to meet standards for auditablity and comply with legislation such as Sarbanes-Oxley and the Health and Human Services Health Insurance Portability and Accountability Act (HIPAA).",10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"While several applications are obvious from such a private cloud setup, we have used it in solving some of our research problems. Here we address two such problem domains, for which we have developed customized images. We also have images supporting scientific computing and bio-informatics.",https://doi.org/10.1109/CCGRID.2010.56,SciCloud: Scientific Computing on the Cloud,24 June 2010,0
"Cloud computing architecture provides an ideal platform to realize our vision. Even though there is no clear definition of Cloud computing, a good understanding of what Cloud computing can offer is prevalent. According to [2], Cloud computing can be seen as a “pool of easily usable and accessible resources (hardware and software). These resources can be dynamically re-configured. This pool of resources is typically exploited by a pay-per-use model.”",https://doi.org/10.1109/CLOUD.2010.80,Cloud Computing Infrastructure for Biological Echo-Systems,26 August 2010,0
"The idea of a completely stand-alone, autonomous, self-contained, self-validating application that does not depend on either immediate or eventual network communication is becoming nearly unthinkable. In the past, keeping something secure usually depended on providing it with isolated defenses, such as placing it in a physical safe or otherwise isolating it from external access. This approach is still a component of some forms of electronic security, such as offline hardware cryptographic modules for certificate authorities, but blockchain methods depend, in contrast, on the idea of independent open verification rather than isolated operation.",https://doi.org/10.1109/MCC.2017.3791019,Blockchain Standards for Compliance and Trust,12 October 2017,0
"To present our analytics of performance and data quality in mobile edge cloud applications, we select cornering assistance applications. Figure 1 shows the overall architecture of the mobile edge cloud cornering assistance (MECCA) application. Clients hosted in vehicles connect to a service registry to find a Recommendation Service which is responsible for recommending suitable speeds for all upcoming curves around a given location. The recommendation is based on the location data provided by the clients. To calculate a recommended speed, Recommendation Service needs information about upcoming curves and the current weather. An External Database (DB) is used to permanently store curve results and is queried, as a cache, by Recommendation Service. Since the database will be accessed from multiple services running on multiple nodes, it needs to be highly available, scalable and easily maintainable. In case DB has no curves stored yet, a Detection Service is requested to detect and calculate detailed information about upcoming curves, based on (i) the location data, indicating the location of the Clients, given by a Recomm",10.1109/CLOUD.2018.00091,Analytics of Performance and Data Quality for Mobile Edge Cloud Applications,11 September 2018,0
"To that end, we have developed a research with the objective of designing a complete architecture for the deployment of Data Mining services, covering from the definition and description of services, to the implementation of a platform for the support, computation and deployment of those services in Cloud Computing. The result is a platform for the deployment of Data Mining services known as OC2DM: Open Cloud Computing Data Mining.",10.1109/SERVICES.2019.00121,Delivering Data Mining Services in Cloud Computing,29 August 2019,0
"Cloud computing has always faced privacy and security concerns. Because the cloud was extended to the mobile, forming mobile cloud computing, it was only natural that all those concerns get inherited to the mobile cloud computing as well [5]. This paper will present those concerns facing mobile cloud computing in terms of security and privacy and propose a comprehensive security framework that deal with privacy and security issues facing MCC.",10.1109/3ICT.2019.8910294,A Secure Framework for Mobile Cloud Computing,25 November 2019,0
"As Marvin Waschke, Andre Merzky, David Wallom, and I discuss in our article, “Mapping the Current State and Future Directions of Cloud Stan-dards,” which will appear in a subsequent issue of IEEE Cloud Computing, there are several essential ingredients for making progress on this topic in the fast-paced modern world of cloud computing development. These ingredients can occur in a wide variety of combinations, but we find that taken together, they characterize the success patterns of many current projects.",10.1109/MCC.2014.6,Defining Our Terms,10 July 2014,0
"This great range of activity continues to this day. In the first article in the “StandardsNow” series, which appears elsewhere in this issue, I describe some of the practical aspects and nuances of the current cloud standards landscape. For reasons detailed here and in that column, the area of standards for cloud computing is now mature enough to merit coverage in IEEE Cloud Computing on an ongoing basis.",10.1109/MCC.2014.21,Setting Cloud Standards in a New World,10 July 2014,0
"Nowadays, more IT societies and IT technologies supports in storing and processing huge amount of data effectively. Cloud computing enabled IT society to handle large amount of information instantly, with the integration of Big Data. Handling Social application information's such as Facebook, twitter, watsapp, Visa Customer transactions, Credit Card processing in bank applications are some of the real time examples illustrating the usage of Big Data in Cloud Computing",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"According to the National Institute of Standards and Technology, cloud computing is defined as a system which enables efficient and flexible admittance to a vast group of computional resources. These resources can be united, allotted, and released shorn of significant managerial intervention or engagement with service providers. Virtualization enables the creation of numerous Virtual Machines on a single physical computer. Green computing encompasses the strategic processes of planning, creating, consuming, and organizing computer services in a manner that prioritizes environmental friendliness, with the ultimate goal of promoting sustainability [11].",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"Google has a great definition for what Cloud Functions offer that helps us build a model for serverless infrastructure: “Google Cloud Functions is a lightweight, event-based, asynchronous compute solution that allows you to create small, single-purpose functions that respond to cloud events without the need to manage a server or a runtime environment.”",https://doi.org/10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"With patient mobility (both internally and externally to a given country) being increasingly the norm in today's society, it became evident that multiple stand-alone EMR solutions must be made interoperable to facilitate sharing of healthcare data among different providers, even across national borders, as needed. For example, in medical tourism hubs such as Singapore, the need for real-time healthcare data sharing between different providers and across nations becomes more pronounced.",https://doi.org/10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"So, this will be another learning process. Much like we saw when we made applications platform native, such as Win32- and Unix/Linux-native APIs, we had to fail first. In other words, working around the native platform features led to applications that did not live up to the expectations of the business, and IT had to go back to square one to redesign and refactor the applications to meet the needs of the business.",10.1109/MCC.2017.4250932,"Cloud-Native Applications and Cloud Migration: The Good, the Bad, and the Points Between",1 December 2017,0
"Data from observations in the real world analyzed stochastically and empirically provides the mathematical foundations and sets the boundary conditions of these models. It is also the means by which the validity of the model outputs can be judged. More recently, observations have been used to parametrize and tune models in real time, providing better solutions driven by real-time observations in the field.3",10.1109/MCC.2018.064181115,Realizing Edge Marketplaces: Challenges and Opportunities,29 November 2018,0
"Legacy, multirooted tree-based network architectures, such as the ThreeTier architecture, cannot accommodate cloud computing's growing demands.[4] Legacy DC architectures face several major challenges: scalability, high oversubscription ratio and low cross-section bandwidth, energy efficiency, and fault tolerance.",10.1109/MCC.2014.26,Trends and challenges in cloud datacenters,10 July 2014,0
"The explosive rate of the evolution of IoT, creates increasing demands for processing capabilities, which is translated in a need for deploying a large number of devices, in order to serve tasks cognitively for strict computational purposes, improving QoS, latency and efficiency. This new paradigm often referred to as fog computing, enables low-latency computation of tasks in close range networks (edge), which incorporate various types of devices. Consequently, the core concept of fog computing is in complete accordance to the concept of IoT, enabling smart, connected devices not only to operate inside a collective and collaborative ecosystem, but also to be a structural part of it.",10.1109/MCC.2017.25,A Cooperative Fog Approach for Effective Workload Balancing,26 April 2017,0
The key idea underlying the microservice architecture is to distribute application complexity among narrowly focused and independently deployable units of computation. Such small components are loosely coupled by means of an integration middleware that dynamically and seamlessly resolves the implicit dependencies among them.,10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
"Next, EDC can be defined as a “collection of heterogeneous resources including smart IoT devices, IoT gateways (e.g., raspberry pi 3, UDOO board, esp8266, etc.), and Software Defined Networking (SDN) and Network Function Virtualisation (NFV) devices (e.g., Cisco IOx, Hewlett Packard (HP) OpenFlow and Middlebox Technologies) at the network edge that can offer computing and storage capabilities on a pervasive—yet much smaller—scale than CDCs. The scope and role of each resource in an EDC differs. For example, IoT gateways collect, aggregate, and process the data generated by the sensing devices. IoT gateway accepts and routes commands sent from the backend to the respective device. It is also responsible for authenticating and authorizing the devices to participate in IoTDAP. It ensures secure communication between the devices and the centralized command center. The gateway is also capable of dealing with multiple protocols (e.g., Constrained Application Protocol, MQ Telemetry Transport) and data formats. Finally, in-transit SDN and NFV devices offer useful solutions for supporting in-network/in-transit data processing (between edge and CDC) and providing network management abstraction independent of the underlying technology.",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
"Clearly, more is required. We argue that one way forward is the development of flexible data-centric technical mechanisms that enable the visibility and control of data flows within and between cloud services. As an exemplar, we introduce our ongoing work on information flow control OFC) to explore how greater technical controls over data flows can allow parties to better manage their legal obligations, improve accountability, and offer verifiable data trails for audit and compliance. Our focus here is on management and compliance with respect to civil, administrative, and criminal law obligations and responsibilities. Surreptitious actions, such as those by malicious parties and government agencies, are beyond the scope of this discussion, and require robust international policy efforts and domestic legal reforms.",10.1109/MCC.2015.69,Data Flow Management and Compliance in Cloud Computing,16 September 2015,0
"In the 1980s the computer industry experienced a massive transformation when core software system architectures changed from being mainframe-based to client-server. This shift changed virtually everything in software from the hardware, to software designs, to the practices for development and operation of that software.",10.1109/MCC.2017.4250927,Realizing Software Reliability in the Face of Infrastructure Instability,1 December 2017,0
"Cryptocurrency applications of distributed ledger methods such as blockchains are now well established, but their implications for more general topics are just beginning to be appreciated. Beyond applications in finance and banking, new applications are emerging in supply chain management, manufacturing, agricultural product tracking, advertising verification, Internet of Things, healthcare, and the pharmaceutical industry, among others.",10.1109/MCC.2017.3791019,Blockchain Standards for Compliance and Trust,12 October 2017,0
"Computing requirements of mobile users continue to increase, as computing and communication capabilities of smart and wearable devices and in-vehicle systems continue to improve. Many applications rely on remote resources to off-load and complete tasks, primarily through the use of a large-scale computing facility hosted within a data center. Such cloud systems are also able to support applications by storing data and processing tasks offloaded by mobile or fixed devices.",10.1109/MCC.2017.27,Mobility-Aware Application Scheduling in Fog Computing,26 April 2017,0
"With the increasing number and availability of smart devices, data sharing is offered within cloud-assisted IoT applications. The data are of little use if the smart devices do not share data with other devices. Data sharing at the edge allows smart devices to share data with lower latency and have fast data access and higher bandwidth. The next generation wireless communications technology (5G) will greatly depend on such solutions where massive IoT smart devices are interconnected with high data rates at ultralow latency. Yi et al. evaluate a performance comparison of the cloud and edge/fog server in terms of latency and bandwidth.4 The results show that when using fog and cloud server, the latencies are 1.416 and 17.989 ms, respectively, and the uplink/downlink bandwidth for fog and cloud are 83.723/101.918 and 1.785/1.746 Mbps, respectively.",10.1109/MCC.2017.9,Secure Data Sharing and Searching at the Edge of Cloud-Assisted Internet of Things,15 March 2017,0
"To overcome the issue imposed by a cloud-only architecture, distributed deep learning approaches have started to emerge in the literature.7, 8 Some of these approaches take advantage of edge computing, wherein the deep learning model is distributed across edge and end devices. These developments are underpinned by advances in edge and mobile edge device technologies such as federated learning by Google,9 Apple's latest Core ML toolkit that provides capability for Apple's mobile devices to run machine learning algorithms using pretrained models, compressed versions of deep learning frameworks such as tensor flow and caffe (with some of these expected to be available on mobile platforms soon), ARM's improvement to its GPU platform, and Intel's movidius platform.10 In parallel, there have been several advances in the cloud and edge computing area11, 12 with the introduction of several paradigms to orchestrate cloud- and edge-based applications. Osmotic computing is one such paradigm that was discussed in the recent IEEE cloud computing Blue Skies column.13 Though these paradigms provide high-level architectural principles of developing and deploying cloud- and edge-based applications, they fail to provide a detailed account of how technologies such as deep learning can be orchestrated and take advantage of the cloud, edge, and mobile edge environments.",10.1109/MCC.2018.1081070,Deep Osmosis: Holistic Distributed Deep Learning in Osmotic Computing,31 December 2017,0
"A microservices-based cloud application involves the interoperation of multiple microservices, each developed separately, that can be deployed, updated, and redeployed independently without compromising the application's ecosystem's integrity. The ability to independently update and redeploy the code base of one or more microservices increases applications' scalability, portability, updatability, and availability, but at the cost of expensive remote calls (instead of in-process calls) and increased overhead for cross-component synchronization.",10.1109/MCC.2016.112,Open Issues in Scheduling Microservices in the Cloud,11 November 2016,0
"So, concerned data owners who want to keep their data encrypted most of the time (that is, unless plaintext is required to perform a computation) must partner with a cryptographic service that can manage data encryption and decryption as a service in the cloud or on its own premises. Although this solution is contractually simpler, since it only involves three parties, it requires data owners to trust the partner's internal operation and, above all, to understand and approve its precautions against threats to the cryptographic keys.",10.1109/MCC.2016.89,Securing Cryptographic Keys in the Cloud: A Survey,19 September 2016,0
"When comparing infrastructure services in cloud computing, an application owner should read the provider’s documentation to determine which services are most suitable for hosting an application. However, cloud providers’ use of nonstandardized naming terminologies makes it difficult to make accurate comparisons. For example, Amazon refers to its compute services as EC2 Compute Unit, whereas GoGrid refers to its same unit as cloud servers. Furthermore, cloud providers typically publish their service description, pricing policies, and SLA rules on their websites. Because providers might update this information without notifying users, it can be difficult to manually obtain service configurations from cloud providers’ websites and documentation (the only sources of information).",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"On the other hand, many industry solutions have been developed and deployed to provide enterprise core business services to their end customers. The industry solution is defined as a computer system which consists of a set of software stacks that can solve a complex business issue in a specific industry. The concept and approach of the industry solution can be widely accepted for many industries such as electronics, retail, finance, telecommunication and other industries [1]. One of major topics in enterprise IT organizations is to migrate those industry solutions on a legacy infrastructure to the Cloud Computing environment since those industry solutions were originally developed as a legacy system for a long time ago, and aren't flexible for customer's business requirements yet. The IT organization would like to get benefits of Cloud Computing for those industry solutions since Cloud Computing is expected to increase their business capabilities with less expense. In addition, Cloud Computing can also accommodate those workloads of industry solutions efficiently. Despite of higher expectations for those industry solutions on Cloud Computing, there was few research study for an architectural framework of Cloud Computing with an industry oriented approach.",10.1109/CLOUD.2014.105,Industry Cloud - Effective Adoption of Cloud Computing for Industry Solutions,4 December 2014,0
"Cloud computing grew out of our never-ending hunger for everfaster and ever-cheaper computation. The key driving forces behind it are the promise of broadband and wireless networking ubiquity, lower storage and mobile device costs, and progressive improvements in Internet computing software and mobile computing. The perceived advantages for cloud-service clients include the ability to improve use by adding more capacity at peak demand, reducing costs, experimenting with new services, and removing unneeded capacity.",10.1109/MIC.2010.113,Cloud Computing: The New Frontier of Internet Computing,2 September 2010,0
"This integration between mobile devices and cloud technology, which is called mobile cloud computing (MCC), allows mobile devices to outsource heavy computation tasks to remote cloud servers using a process called task offloading. Task offloading process enhances the application performance, lowers battery power consumption, and executes applications that are unable to be processed in mobile devices due to insufficient resources [6]. Despite the advantages of task offloading, some issues related to time management, fault tolerance, and energy consumption are needed to be addressed [7]. Some researchers tried to use different task scheduling techniques to solve previous issues [8]. However, they focused on energy consumption and communication cost without taken the fault tolerance in consideration [9]. As remote servers sometimes are inaccessible due to node failure or unstable link, a fault tolerance issue is appeared [10]. Therfore, it is important to propose a technique that can reduce the energy consumption, minimize the processing time, and above all of these avoid task processing failure which is what we propose in this paper.",10.1109/MobileCloud.2017.26,Energy-Aware Fault Tolerant Task offloading of Mobile Cloud Computing,12 June 2017,0
"Now-a-days due to high speed delivery of services to the cloud users over a network, cloud computing is being used in many organizations. Also due to the ongoing enormous operations huge and huge amounts of data need to be stored in cloud environment. When this data is getting stored with cloud service provider, the cloud user has their own concerns related to the data privacy and security. So proper and suitable security technologies need to be enabled in cloud network to maintain highest possible data security and data privacy",10.1109/ICCCNT49239.2020.9225396,Detection and Prevention Mechanisms for DDoS Attack in Cloud Computing Environment,15 October 2020,0
"Another advantage to consider the hedonic approach is that the cloud price can be modeled by the regression analysis for the cloud service features along with its price variation over a period. In comparison with other methods, such as survey-based or contingent valuation [3] or Delphi [4] method, hedonic regression approach is quick and cost-effective if the chosen dataset is sufficiently large for the regression analysis. Moreover, it can be easily updated. It is a great fit for the cloud environment because of its ever-changing market conditions and rapid technological innovations.",10.1109/TCC.2018.2858266,Hedonic Pricing of Cloud Computing Services,23 July 2018,0
Cloud computing is known for its sharing technology so it is very difficult to obtain a strong isolation property for multitenant architecture. It is the responsibility of the CSP to provide a scalable service to the user without interfering with the other client system.,https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"It stands for ""Infrastructure as Service"". It also known as ""Hardware as Service"" because it provides hardware components virtually like CPU, Operating Systems, RAM, Networking, Storage Drives etc. In this type of Service model, Applications and Data is managed by Client, rest components like Runtime, Middleware, Operating Systems, Virtualization, Servers, Storage and Networking is managed by Cloud Provider.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"The attacker can perform arbitrary malicious code by loading the separated module (dynamic library). For example, in the Windows OS, loading the dynamic library is carried out by calling WinAPI commands, such as «CreateProcess», «LoadLibrary», etc., while after loading the module in memory it is initiated by performing the «DllMain» function or similar.",https://doi.org/10.1109/SCM58628.2023.10159053,Model of a Self-Healing Computing Process of a Cloud Computing System under Conditions of Information and Technical Impacts,26 June 2023,0
"Cloud computing claimed that it provides better efficiency in the use of infrastructure [6]. In addition, cloud computing technology has been developed so rapidly and could change the implementation or operation mode in Information Communication Technology. By using cloud computing, the use of information technology infrastructure is claimed to be more efficient and more effective. Therefore, this study aims to establish a system of search engines by using cloud computing infrastructure.",10.1109/ICCCSN.2012.6215751,Building crawler engine on cloud computing infrastructure,14 June 2012,0
"Security is one of the biggest challenges to the cloud model, and it's often an emotional one as well. Again, the utility analogy isn't very illuminating here because most companies spend little time worrying about whether their electrical wires are being compromised. In contrast, a violation of data security is a paramount concern to an organization.   ",10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"The term “Big Data” originated from Internet with Mining Transactions to manage very large distributed information. Big data offers cloud computing with increased storage capability to handle massive volumes of information, which can be integrations of audio, video, pictures and plain text. In real time, Big Data has three properties, namingly V3 indicating Volume, Variety and Velocity and two more dimensions, namingly Variability and Complexity. Volume indicates the size of Data like storing Socio-Media Data, Live Streaming of Data, etc. variety indicates the type of data or format of data like audio, video, emails, transactions, etc. Velocity It indicates the processing technique of data to meet the user's on demand requirements. Variability indicates the inconsistency of data flows in processing. Complexity indicates the type of processing the data like mapping, linking, cleansing and transformations [18].",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"Behind the firewall, enterprises have control of their data. In the cloud, they must trust the provider. Many organizations are loathe to entrust their sensitive data and their reputation to the public cloud.",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
Storage is linked to the physical location where the data is stored. Whether the data is stored locally or on foreign land. Whether cloud service provider having sufficient data centers or not. Storing data on the different location may lead to the unauthorized access.,https://doi.org/10.1109/CSNT.2015.141,Efficient Framework Approach to Extract Privacy Issues in Cloud Computing,1 October 2015,0
"If the software service is operated on a public cloud platform, the customers have no need to worry about scalability and availability. In scenarios where security or privacy concerns exist, it should be possible to operate the management tool on a private cloud platform, too, avoiding to store the access credentials off-premise. In principle all secret keys should be encrypted due to security concerns as they are stored.",10.1109/CLOUD.2011.64,The KOALA Cloud Manager: Cloud Service Management the Easy Way,1 September 2011,0
"In this paper we propose novel solutions for interoperable personal data management in Clouds to partly contribute to the evolution of Clouds, the Internet of Things and Big Data management. Our approaches enable to manage and process user data produced by mobile devices in different Clouds transparently, and to share this data among Cloud providers in an autonomous way.",10.1109/BDCloud.2014.41,Interoperating Cloud Services for Enhanced Data Management,9 February 2015,0
"These data mining services lack a standardized description and definition in cloud computing. In addition it is not only necessary to have a homogeneous definition of the services, but also it requires a platform and an architecture where to implement this services.",10.1109/SERVICES.2019.00121,Delivering Data Mining Services in Cloud Computing,29 August 2019,0
"In IT standards, we tend to get caught up in particular positioning or viewpoints, becoming captured by a localized “team” argument such as the debate team example. Sometimes the advocacy of a viewpoint can distort and filter our perceptions of progress. There's a premium, however, that we can gain if instead of advocating for one particular viewpoint or camp in an argument, we look at the general point of the standard or standards under discussion from multiple viewpoints. A crucial step in pursuing this approach is defining our terms.",10.1109/MCC.2014.6,Defining Our Terms,10 July 2014,0
"The ongoing process of defining, developing, and recognizing standards in general is intrinsically a community activity. It might be possible to define what constitutes a standard, at its most basic level, as “anything agreed to by more than one party,” and in such a definition, we could sweep up a broad range of human intellectual effort. In the IT field, there is and has always been a wide variety of community time and effort expended to define and codify the framework and details of our work.",10.1109/MCC.2014.21,Setting Cloud Standards in a New World,10 July 2014,0
"SIEM analytics. Integration is usually straightforward between a private cloud and the enterprise security information and event management (SIEM) system, providing data analytics and incident response processes and tools. HP's ArcSite SIEM, for example, is often used in conjunction with a private cloud deployment.",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"The term Cloud Computing has generated a lot of interest and competition in the industry. With an ever-growing list of Cloud Computing service providers, identifying one that best suits the business needs of an enterprise is a challenging and difficult task. Hopefully, a comparison of different Cloud Computing solutions can leverage the Cloud Computing research area providing a good starting point to research groups and interested readers to better choose the most suitable one.",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"An alternative is to exploit the best features of each: public clouds' scalability and agility and private clouds' security. In the case of the healthcare work-flow in Figure 1, a federated cloud (also known as hybrid cloud) approach would store the confidential medical data on a private cloud and send the sensor data (tagged with an anonymized ID) to the public cloud for analysis, with the results returned to the private cloud to be combined with the confidential data.",10.1109/MCC.2014.46,Application Security through Federated Clouds,30 September 2014,0
"The cloud computing paradigm promises reliable services delivered through next-generation DCs built on virtualization technologies. This article highlights some of the major challenges faced by cloud DCs and describes viable solutions. Specifically, we focus on architectural challenges, reliability and robustness, energy efficiency, thermal awareness, and virtualization and software-defined DCs.",10.1109/MCC.2014.26,Trends and challenges in cloud datacenters,10 July 2014,0
"The proliferation of cloud computing has revolutionized hosting and delivery of Internet-based application services. In the standard cloud application deployment approach, an application is architected to be deployed and managed over a single datacenter (for example, Amazon or GoGrid). Such an approach has several shortcomings. Datacenter failure can leave thousands of application users without access to essential (and in some cases paid) services. Moreover, exploiting a single datacenter makes it extremely difficult to exploit location-based placement of data and processing driven by geolocation of application users.",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"For instance, facing many virtual machine monitors (like openvz, xen, kvmetc.); users do not know which is the best one for their applications. Performance evaluation on virtual machine monitors has been extensively studied ([5], [6]). In this paper, we present an evaluation of different open source virtual machine solutions.",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
The motivation for using ontology is to represent the large number of possible combinations of requirement to resource to price mappings by appropriate knowledge representation techniques and to reason against the ontology. The research question is “Can requirements be priced using an ontology mapping approach?”,https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"Evaluation results are presented using three metrics: total cost, waiting time, and resource utilization (Figure 1). In essence, for any scenario, the total cost is explained by average waiting time and resource utilization.",https://doi.org/10.1109/CLOUD.2017.112,Cloud Bursting Scheduler for Cost Efficiency,11 September 2017,0
"Checkpoint is initiated with checkpointing library BLCR library which is available in Open MPI implementation [9], after live migration of the VMs to the redundant nodes. The checkpoint files are saved on the network and neighboring node for easy recovery as well as to eliminate single point of failure. After checkpointing, the resources which were used for migration are free because cloud resource can be relinquished at will.",https://doi.org/10.1109/CCGrid.2012.80,A Fault Tolerance Framework for High Performance Computing in Cloud,14 June 2012,0
"The technological readiness of organisations, meaning the degree of readiness of the IT infrastructure and the human resources in terms of cloud computing.",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"Mobile Cloud Computing is a technology based on two: Cloud computing and mobile computing [2], [6]. Fernando, Loke, and Rahayu [16] even view mobile cloud computing as a solution to the problems facing mobile computing. Marston et al [7] have defined Cloud computing as follows: “It is an information technology service model where computing services (both hardware and software) are delivered on demand to customers over a network in a self-service fashion, independent of device and location”. The Cloud computing infrastructure is a growing appeal, and many organizations are moving on to utilizing it.",10.1109/3ICT.2019.8910294,A Secure Framework for Mobile Cloud Computing,25 November 2019,0
"Globus Nexus provides the high-level security fabric that supports authentication and authorization. Its identity management function lets users create and manage a Globus identity; users can create a profile associated with their identity, which they can then use to make authorization decisions. It also acts as an identity hub, where users can link external identities to their Globus identity. Users can authenticate with Globus through these linked external identities using a single-sign-on model. Supported identities include campus identities using InCommon/ CIlogon via OAuth, Google accounts via OpenID, XSEDE accounts via MyProxy OAuth, an Interoperable Global Trust Federation (IGTF)-certified X.509 certificate authority, and Secure Socket Shell (SSH) key pairs. To support collective authorization decisions (such as when sharing data with collaborators), Globus Nexus also supports the creation and management of user-defined groups.",10.1109/MCC.2014.52,"Efficient and Secure Transfer, Synchronization, and Sharing of Big Data",30 September 2014,0
"A 2015 Gartner report noted that data processing technologies haven't kept pace with the significant increase in the volume of digital healthcare data, and an integrated and trustworthy healthcare analytics solution can facilitate more effective decision making in patient care and risk management, improving quality of life, optimizing performance of services, and so on. [6] Medical professionals have made similar observations. For example, the chief information officer of Boston's Beth Israel Deaconess Medical Center explained that “working with big data in hospital systems is hugely challenging but at the same time holds tremendous promise in providing more meaningful information to help clinicians treat patients across the continuum of care.",10.1109/MCC.2015.36,Trustworthy Processing of Healthcare Big Data in Hybrid Clouds,2 June 2015,0
"Although to some extent, DLPSs can be considered a type of IDS, they're more tailored to data security. However, it's difficult to completely guarantee data security using DLPSs alone. Attackers who gain control of the host machines can modify the DLPS settings, thereby completely disclosing data to those attackers. Moreover, even though firewalls can block unwanted network traffic packets according to a predefined rule set, they can't detect sophisticated intrusive attempts such as flooding and insider attacks. IDSs, DLPSs, and firewalls are therefore not interchangeable security schemes but collaborative ones.",10.1109/MCC.2014.53,Enhancing Big Data Security with Collaborative Intrusion Detection,30 September 2014,0
"Environmental sensors collect rainfall amounts, temperature, pressure, fluid velocity, and other environmental data. Such deployments help the rescue personnel acquire an overall projection of the area's condition following any natural calamity. The information provided also help in determining the disaster spread pattern.",10.1109/MCC.2014.72,Evacuation and Emergency Management Using a Federated Cloud,30 November 2014,0
"This cross-fertilization of industrial engineering standards allowed invention in other fields to spin into being rapidly, with advances in one area feeding quickly into adoption and progress in oth-ers. As a result, audio recording, radio transmission, moving films, television, and, decades later, digital processing, computers, and the Internet came into existence, all the result of this incredible period of concentrated cross-domain multidisciplinary expansion and invention. Standards were at the core of this technological revolution.",10.1109/MCC.2015.27,"Invention, Innovation, and New APIs",2 June 2015,0
"To facilitate data sharing or even patient data portability, there is a need for EMRs to formalize their data structure and the design of HIS. Electronic Health Records (EHRs), for example, are designed to allow patient medical history to move with the patient or be made available to multiple healthcare providers (e.g. from a rural hospital to a hospital in the capital city of the country, before the patient seeks medical attention at another hospital in a different country).3 EHRs have a richer data structure than EMRs. There have also been initiatives to develop HIS and infrastructures that are able to scale and support future needs, as evidenced by the various national and international initiatives such as the Fascicolo Sanitario Elettronico (FSE) project in Italy, the epSOS project in Europe, and an ongoing project to standardize sharing of EHRs.4, 5, 6",https://doi.org/10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"In [1], authors present a Cloud Computing Open Architecture (CCOA). Our Bio-Ecosystem architecture is based on CCOA. Figure 3 illustrates our Bio-Ecosystem architecture. Usually, biological applications involve four types of resources: data sources, tools (software packages), application development platforms, and computing resources.",https://doi.org/10.1109/CLOUD.2010.80,Cloud Computing Infrastructure for Biological Echo-Systems,26 August 2010,0
"Virtual Computing Lab is a free, cloud computing project, open-source, on-demand, remote-access system that dynamically provisions computing resources to end users [5], [6]. North Carolina State University with cooperation with IBM announced the creation of the system in 2006 with the goal of creating a multi-institutional, shared computing services community, which includes universities, colleges, schools and business partners.",https://doi.org/10.1109/CCAA.2015.7148478,Virtual computing lab (VCL) open cloud deployment,6 July 2015,0
"The DC architecture plays a pivotal role in the performance and scalability of the cloud platform. Cloud computing relies on DCs to deliver the expected services.[2] The widespread adoption of the cloud paradigm mandates exponential growth in the DC's computational, network, and storage resources. Increasing the computational capacity of today's DCs is not an issue. However, interconnecting the computational resources to deliver high intercommunication bandwidth and specified QoS are key challenges. Today's DCs are not constrained by computational power but are limited by their interconnection networks.",10.1109/MCC.2014.26,Trends and challenges in cloud datacenters,10 July 2014,0
The major security concern for any organization is increasing attacks to steal confidential data. The apparent loss of control over the organizations data is also an important barrier for wide acceptance of cloud. The survey done by Cloud Security Alliance (CSA) presents following top security issues that IT industries need to tackle while adopting cloud technology [6].,https://doi.org/10.1109/I-SMAC47947.2019.9032545,"A Survey of Cloud Computing Security Challenges, Issues and their Countermeasures",12 March 2020,0
"Smart sensor networks are considered characteristic examples, where the Internet of Things (IoT) can act as an enabling framework, allowing the efficient exchange of information between sensors and controllers. On the other hand, cloud computing platforms and infrastructures provide the ideal virtual environment for analysis of the collected data, giving the ability to provide computational resources. This appoints cloud computing platforms as the perfect environment to support IoT computational needs.",10.1109/MCC.2017.25,A Cooperative Fog Approach for Effective Workload Balancing,26 April 2017,0
"Trustworthiness is also an issue when dealing with microservices. For example, an adversary could compromise or gain control of a component, which isn't uncommon within the public cloud context. However, in a typical microservice architecture, the other components assume a trusted component base; thus, there's a real risk that attacks can be easily propagated due to the microservices' dependencies and (blind) trust of peer components. In data sharding, security threats are related to data provenance, trustworthiness, and protection. Specifically, when data is horizontally segmented into multiple shards, we need to determine if the data source is verifiable (or trustworthy) and how to protect against forging attempts (for example, data modification and tampering) during sharding.",10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
"It is widely accepted that every bit of the data generated by every IoT sensing devices need not make its way back to the CDC. For some data, it might make sense to collect, store, interpret, and respond to locally in the EDC. But IoTDAP stakeholders need a strategy about which data needs to be processed in EDC and which data reaches all the way up to the CDC. For example, rather than sending all IoT sensor data to the CDC, part of the data filtering and aggregation could happen on EDC which may then send a trigger to CDC for initialising large-scale data analytics required for decision making.",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
"Fog computing provides a distributed infrastructure at the edge of the network, resulting in low-latency access and faster response to application requests. With this new level of computing capacity, new forms of resource allocation and management can be developed to take advantage of the fog infrastructure.",10.1109/MCC.2017.27,Mobility-Aware Application Scheduling in Fog Computing,26 April 2017,0
"Cloud Computing is a major trend in the IT industry since it can construct an efficient IT infrastructure and operation for enterprise IT systems. Many enterprises start strategically adopting Cloud Computing for their IT infrastructures since the operational and capital expense can be optimal for their IT infrastructures, and it makes a better business with Cloud Computing. In the result, Cloud Computing becomes a target infrastructure for a transformation for legacy IT infrastructures.",10.1109/CLOUD.2014.105,Industry Cloud - Effective Adoption of Cloud Computing for Industry Solutions,4 December 2014,0
"To make cloud computing work, what you need are three things: thin clients (or clients with a thick-thin switch), grid computing, and utility computing. Grid computing links separate computers to make a large infrastructure, use idle resources[2]. Utility computing is paying for what you use on shared servers like you pay for a public utility (such as electricity, gas, and so on).",10.1109/ICCASM.2010.5623257,The comparison between cloud computing and grid computing,4 November 2010,0
"Historically, the hedonic model has two different objectives. One is to predict the future price of goods or services that customers are willing to pay. This purpose of hedonic prediction is to help decision makers to make an optimized strategic decision. The other is a hedonic index, which is to establish a price ratio by comparing it with a price in a base period. The goal of the hedonic index is to monitor the price of either inflationary or deflationary, which is to verify what has happened in the past.",10.1109/TCC.2018.2858266,Hedonic Pricing of Cloud Computing Services,23 July 2018,0
"It stands for ""Platform as a Service"". In this type of Service model; Applications, Data, Runtime, Middleware, Operating Systems are managed by Client, rest components like, Virtualization, Servers, Storage and Networking are managed by Cloud Provider.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"This defines semantic technologies’ usage for the cloud. A cloud platform can be semantic in nature using semantic technologies to enhance the experience for cloud users. This can be in areas such as the discovery of cloud services, configuration metrics for cloud services, etc. by annotating the different entities with metadata, fostering the efficiency of the cloud platform, with respect to service delivery across the different models; IaaS (Infrastructure-as-a-Service), PaaS (Platform-as-a-Service) and SaaS (Software-as-a-service). Currently, domain-specific ontologies exist for providing metadata for cloud entities’ description [5]. However, rich-content domain ontologies for cloud services are yet to become popular.",10.1109/DeSE51703.2020.9450748,A Cloud Computing Capability Model for Large-Scale Semantic Annotation,14 June 2021,0
The rest of this paper is organized as follows: Section II describes our mobile edge cloud application. Section III explains methods for mobile edge cloud performance and data quality evaluation. Section IV presents experiences for performance and Section V presents experiences for data quality. We discuss the related work in Section VI. We conclude the paper and outline our future work in Section VII.,10.1109/CLOUD.2018.00091,Analytics of Performance and Data Quality for Mobile Edge Cloud Applications,11 September 2018,0
"The first databases used hierarchical data models in which all data was organized in a tree-like structure. This structure is simple but inflexible because it's confined to a one-to-many relationship. The IBM Information Management System (IMS), one of the first production databases, used this model. The hierarchical data model lost traction as the relational model became the de facto standard used by virtually all mainstream DBMSs. The relational database uses a data model much more aligned with real-world business models. In this model, each data item has a row of attributes, so the database displays a fundamentally tabular organization. Tables can be related to other tables using a key mechanism. Relational databases displaced hierarchical databases because the ability to add new relations made it possible to add new, valuable information. SQL offered a way to program relational queries, and the data-base-powered IT marketplace was born.",10.1109/MCC.2014.25,Today's Tidbit: VoltDB,10 July 2014,0
"WHEN I WAS IN COLLEGE, A MEMBER OF THE DEBATE TEAM ONCE TOLD ME THAT THE BEST METHOD HE HAD FOUND SO FAR TO STOP A SUCCESSFUL ARGUMENT BY MEMBERS OF AN OPPOSING TEAM WAS TO ASK THEM TO DEFINE THEIR TERMS. This always struck me as obscure and unproductive advice: after all, isn't the point of a useful debate not just tactics, but arriving at the truth of the matter?",10.1109/MCC.2014.6,Defining Our Terms,10 July 2014,0
"The advent and rapid adoption of the cloud paradigm has brought about numerous challenges to the research community and cloud providers, however. Datacenters (DCs) constitute the structural and operational foundations of cloud computing platforms.[2] Yet, the legacy DC architectures cannot accommodate the cloud's increasing adoption rate and growing resource demands. Scalability, high cross-section bandwidth, quality of service (QoS) concerns, energy efficiency, and service-level agreement (SLA) assurance are some of the major challenges faced by today's cloud DC architectures. Multiple tenants with diverse resource and QoS requirements often share the same physical infrastructure offered by a single cloud provider.[3] The virtualization of server, network, and storage resources adds further challenges to controlling and managing DC infrastructures.[2] Similarly, cloud providers must guarantee reliability and robustness in the event of workload perturbations, hardware failures, and intentional (or malicious) attacks[3] and ultimately deliver the anticipated services and QoS.",10.1109/MCC.2014.26,Trends and challenges in cloud datacenters,10 July 2014,0
"In the cloud computing model, users access services according to their requirements, without knowing where the services are hosted or how they're delivered.[1],[2] An increasing number of IT vendors (such as Amazon, GoGrid, and Rackspace) promise to offer information and communication technology (ICT) resources such as hardware (CPU, GPUs, storage, and network), software (databases, stream processing systems, and data-mining frameworks), and applications (email, video on demand, and social networking). These services are referred to as infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS). Figure 1 shows the layered architecture of the cloud computing model. Cloud resources are hosted in large datacenters, often referred to as data farms, operated by companies such as Amazon, Apple, Google, and Microsoft. Having the flexibility to rent ICT resources on demand to avoid upfront investment has attracted many enterprises that now exploit cloud computing to deliver their application services.",10.1109/MCC.2014.41,The Cloud Interoperability Challenge,15 October 2014,0
"A defect in a cryptographic standard might expose you, me, and everyone working with us to financial ruin, catastrophic security vulnerabilities, or weaknesses. An inconsistent Web browsing experience between products is no longer the most unpleasant thing we might expect from inconsistent HTTP frameworks. Such inconsistencies led to server-side developers spending a great deal of time and effort to deal with them. Although this problem still occurs, an even more important consideration now stems from the manner in which hypermedia and Web APIs are being designed and integrated deeply into business processes for essentially all new software. The corresponding need for consistency and reproducibility in the associated frameworks and standards is very high.",10.1109/MCC.2014.21,Setting Cloud Standards in a New World,10 July 2014,0
"Software-as-a-Service (SaaS): On the top of the overall software stack, there are a variety of web services developed for IVS applications which can be easily accessed through web browsers.",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
"The vehicular cloud provides an efficient way to utilize the vehicles resources. The sensitive data on the vehicles as well as on the cloud can be alter or access by the unauthorized users. Therefore, the data must be encrypted and only available and accessible to authorized users. The vehicles that parked in the airport parking space or shopping malls are used as a data center. The information must be removed from the vehicle when they move from the parking.",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"This part of cloud model consist of a set of software and tools used for product development that allow developers to create applications on the provider's platform, i.e., applications can be built on the internet and executed on provider's infrastructure. This services is divided into two parts, one is Programming Environments and another is Execution Environments.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"This application takes in data about a patient-a mixture of sensitive medical data that identifies the patient and heart-rate sensor data. It analyzes the sensor data and generates a summary that can then be stored with the rest of the patient data. Because there's some sensitive data in the workflow, an organization might feel that it has no choice but to store and analyze the data in a secure private cloud. This is unfortunate, because the analysis is often computationally intensive, which makes it ideal for exploiting the scalability of the public cloud, particularly if, at peak times, data from many patients is arriving for analysis. Not only healthcare applications suffer from this problem. We see equivalent security issues limiting the uptake of the cloud for applications in domains such as financial, human resources, and government.",10.1109/MCC.2014.46,Application Security through Federated Clouds,30 September 2014,0
"Encryption. Private clouds can integrate enterprise encryption capabilities, including key management to further protect cloud-resident content. Encryption solutions from companies such as Checkpoint Software support integration into cloud-resident data storage.",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"OpenStack is a collaborative software project designed to create freely available code and needed standards for the benefit of both Cloud providers and Cloud customers. OpenStack is currently three projects: OpenStack Compute (deploy automatically provisioned virtual compute instances), OpenStack Object Storage (redundant storage of static objects) and OpenStack Image Service (provides discovery, registration, and delivery services for virtual disk images).",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"Existing technology deployments within a medical organization, including its internal, on-premise infrastructure (private clouds) for data storage and the image archiving and communication systems used by radiologists, radically limit efforts to harness the massive amount of medical imaging and other healthcare data. In other words, organizations face several limitations when using private clouds to process health-care application data.",10.1109/MCC.2015.36,Trustworthy Processing of Healthcare Big Data in Hybrid Clouds,2 June 2015,0
"These risks represent a small subset of known cloud-specific vulnerabilities and threats. However, they motivate us to think further about new adversary models, trust relations, and risk factors relative to cloud computing stakeholders. In the examples, the cloud provider isn't trusted because of its resource sharing and VM consolidation practices. Hence, the cloud provider doesn't provide a desirable level of isolation and protection between tenants in the cloud, allowing them to attack each other.",10.1109/MCC.2014.20,Security and Privacy in Cloud Computing,10 July 2014,0
"Commercial and public datacenters such as Amazon Web Services and Microsoft Azure provide computing, storage, and software resources as cloud ser-vices, which are enabled by virtualized software/middleware stacks. Examples include virtual machine management systems such as Eucalyptus and Amazon Elastic Compute Cloud (EC2); image management tools such as the Futuregrid image repository[3]; massive data storage/file systems such as Google File System (GFS), the Hadoop distributed file system (HDFS), and Amazon Simple Storage Service (S3); and data-intensive execution frameworks such as Amazon Elastic MapReduce. In addition, Future-Grid (http://FutureGrid.org) and Open-Stack provide software stack definitions for cloud datacenters.",10.1109/MCC.2015.14,Processing Distributed Internet of Things Data in Clouds,22 April 2015,0
"IDSs are commonly categorized by the type of data source involved in detection. Host-based IDSs (HIDSs) detect malicious events on host machines. They handle insider attacks (which attempt to gain unauthorized privileges) and user-to-root attacks (which attempt to gain root privileges to VMs or the host). Network-based IDSs (NIDSs) monitor and flag traffic carrying malicious contents or presenting malicious patterns. This type of IDS can detect direct and indirect flooding attacks, port-scanning attacks, and so on.",10.1109/MCC.2014.53,Enhancing Big Data Security with Collaborative Intrusion Detection,30 September 2014,0
"This study uses DEMATEL technique to identify the key consideration factors and explore their interrelationship. The DEMATEL, originated from the Geneva Research Centre of the Battelle Memorial Institute [12], uses matrix calculations to obtain all the direct and indirect causal relationships, as well as the influence strength. ",https://doi.org/10.1109/CloudCom.2012.6427610,Key consideration factors of adopting cloud computing for science,4 February 2013,0
"Mobile devices can frequently change locations, which results in the variation and alteration of wireless networks. For service consumers, this variation might impact the quality of service (QoS) of invoked mobile services, while the alteration can lead to failure. For service providers, their services might become temporarily unreachable due to the failure of wireless connections, while network address changes might lead to services being unaddressable. Thus, determining how to handle user mobility is a major challenge for providing reliable mobile services in highly dynamic mobile wireless environments.",10.1109/MCC.2016.92,Toward Mobile Service Computing: Opportunities and Challenges,19 September 2016,0
"Containers are also much more efficient for creating workload bundles that are transportable from cloud to cloud. In many cases, virtualization is too cumbersome for workload migration. Thus, containers provide a real foundation for moving workloads around hybrid clouds and multiclouds without having to alter much, if any, of the application.",10.1109/MCC.2016.122,Moving to Autonomous and Self-Migrating Containers for Cloud Applications,30 December 2016,0
"In this article, we present the challenges of preserving privacy in cloud storage. To address these challenges, we apply oblivious RAM (ORAM), known to be the most effective solution for hiding user access patterns. We provide a tutorial about ORAM and survey recent efforts to increase the practicability of using it in cloud storage by reducing its overhead.",10.1109/MCC.2016.107,Privacy-Preserving Access to Big Data in the Cloud,11 November 2016,0
CSA's basic advice is for organizations to make sure that they have sufficient resources and to perform extensive due diligence before jumping into the cloud. Due diligence refers to the care a reasonable person should take before entering into an agreement or a transaction with another party.,https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"In reality, moving from an internal cyber-physical network to the cloud can lead to various security issues. There are only a few known cyberattack incidents on cyber-physical systems, but a successful attack can have real-world and catastrophic consequences. A recent survey suggested that the role of digital forensics in CPCS incident handling isn't widely understood.3 Although existing digital forensics tools and techniques are unlikely to stop an attack in real time, a forensic-by-design approach can help in several ways. For example, it can help identify an incident by its source and determine its type, preserve and analyze critical evidential data, reconstruct fragments of evidential data and draw conclusions, and accelerate information asset restoration.",10.1109/MCC.2016.5,Forensic-by-Design Framework for Cyber-Physical Cloud Systems,26 February 2016,0
"In our approach, the health authority validates mobile users based on their identity and location attributes. A mobile user consults the domain server, which forwards the request to the health authority on the user's behalf. Based on this validation, the domain server informs the cloud service provider (CSP) to allow the requested information to be transmitted.",10.1109/MCC.2016.76,Hybrid Cryptographic Access Control for Cloud-Based EHR Systems,19 September 2016,0
"Currently, there's an ongoing debate on the utilities and challenges of hosting and sharing of medical data in a cloud platform, despite the potential benefits of outsourcing health-related data to the cloud for storage, processing, and sharing (including cost optimization, ease of data management, flexibility, maintainability, and scalability).",10.1109/MCC.2016.139,Healthcare-Related Data in the Cloud: Challenges and Opportunities,30 December 2016,0
"There are various reasons for these issues. Cloud services and IoT are created separately by cloud providers and IoT providers. In addition, the complexity of the IoT and cloud ecosystems prevents a single stakeholder from offering software that works well in IoT cloud systems. These issues prevent us from developing and operating IoT cloud systems in a co herent manner on top of infrastructures that blend various types of resources. Thus, it's hard to control and manage both IoT and cloud services as a uniform softwares layer (see the “IoT Cloud Systems: Some En-gineering Principles” sidebar for further discussion).",10.1109/MCC.2015.23,Principles for Engineering IoT Cloud Systems,2 June 2015,0
"Contemporary sensor technology aims at complete sensor coverage and control (see www.sensorsmag.corn/about-scnsors). Thus, without loss of generality, we assume predeployment of several heterogeneous sensor nodes across the disaster-affected regions. Heterogeneity of sensors ensures a multiparametric supervision of the regions.",10.1109/MCC.2014.72,Evacuation and Emergency Management Using a Federated Cloud,30 November 2014,0
"Each such innovation created a corresponding need for development of standards in material com-position, tooling, gauges, and associated measurements and metrics. Standardized machinery and component designs, material strengths, and other engineering details were used as the basis for growth in this astonishing period of invention and adoption. New industrial techniques came into use in a wide variety of arenas far beyond those in which they were initially created and applied, partly because industrialized and standardized components could be designed and mass-produced using methods that could easily be adapted for use in other areas.",10.1109/MCC.2015.27,"Invention, Innovation, and New APIs",2 June 2015,0
"Mobile cloud computing was defined by Fan, Cao, and Mao [9] as “cloud computing extended by mobility and a new ad-hoc infrastructure based on mobile devices. It provides mobile users with data storage and processing services on a cloud computing platform”. According to Malik and Chaturvedi [5] Mobile cloud computing consists of the following components: mobile device, wireless communication channel and the cloud. Mobile cloud computing shifts the data storage and processing from burdening the mobile device and onto the cloud via a reliable wireless medium [10].",10.1109/3ICT.2019.8910294,A Secure Framework for Mobile Cloud Computing,25 November 2019,0
"it is cloud provider agnostic, allowing for the development in many of them and even combining their services. This leads to two definitive advantages: a) it allows for migration of tasks from one provider to another, and b) it prevents falling in the vendor-lock problem.",10.1109/SERVICES.2019.00121,Delivering Data Mining Services in Cloud Computing,08-13 July 2019,0
"In cloud computing, many software packages are offers big data as an service, where end user can integrate structured and unstructured data as per his/her requirements from the entirety of its organization's storage capacity, thus the end user with analysis capability to handle the threats [3]. This is a greater advantage of big data for an individual to detect the sensitive data and transform them according to their necessity, also provides the individual to have their control on their data.",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"One of the main problems of search engine service is the requirement of large computing resources to produce a complete and quick search. In practice, the service search engine require big of infrastructures like a lot of servers and big storage to run its services. The issue of search engine infrastructure management becomes important when the number of infrastructure continues to increase. The use of effective and efficient infrastructure is important enough so there isn't resources that having over or under utilities. Several studies have developed faster and more efficient search engines [1], [2], [3].",10.1109/ICCCSN.2012.6215751,Building crawler engine on cloud computing infrastructure,14 June 2012,0
"AWS Lambda comes with ImageMagick 6, an image processing tool, ready to use. Doing image conversions on upload might be a great use of serverless, provided the images are not too large and your usage isn't massive. Keep in mind that Lambda has a 5-minute maximum execution time (and a good thing that is, lest you face unexpected compute cost for a rogue hit). Or what about workflow triggers? AWS Simple Workflow (SWF) is great for some things but at other times, deploying a function is much simpler—or running a serverless function is a step in a larger workflow managed by an orchestrator like AWS SWF. Serverless isn't just for HTTP API endpoints.",https://doi.org/10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",,0
"It stands for ""Software as a Service"". In this type of Service model, all the components like Applications, Data, Runtime, Middleware, Operating Systems, Virtualization, Servers, Storage and Networking is managed by Cloud Provider.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"Amazon cloud computing framework uses its own language GateKeeper to to describe the token, which can satisfy the complex business needs. It is relatively complicated to get buyer token. The whole process is extremely similar to payment via Internet banking when we go shopping online. Because buyers are ultimate users, we must notify an authoritative third-party online payment system which is always an Internet banking mainly about turnovers of transactions to be carried out, and buyers must confirm the transaction in payment system web site rather than seller's web site in order to ensure the security of buyers' transactions.",https://doi.org/10.1109/APWCS.2010.15,A New Architecture of Online Trading Platform Based on Cloud Computing,7 June 2010,0
"The data transmission method, application partition granularity and task migration mechanism of different mobile cloud computing architectures can’t be compatible with each other, so unified open interfaces are needed to achieve the seamless integration and conversion among the heterogeneous cloud platforms.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
Meta heuristics are also used for task scheduling problems as they can be used to find near-optimal solutions for optimization problems with a broader solution space when compared to heuristic approaches. In [10] proposed an improved version of the PSO algorithm called (IPSO) which prevents the algorithm from falling into local optimum. He simulated the algorithm in CloudSim and showed that the improved algorithm is better than the traditional PSO algorithm. To take a better schedule they have considered a minimum time of performing tasks in each resource.,https://doi.org/10.1109/SmartCloud49737.2020.00015,An Efficient Task Scheduling Algorithm using Total Resource Execution Time Aware Algorithm in Cloud Computing,27 November 2020,0
"Recently, the pervasiveness of smart devices (e.g. Android and iOS devices and wearable devices) has also resulted in a paradigm shift within the healthcare industry.7 Such devices can be user-owned or installed by the healthcare provider to measure the well-being of the users (e.g. patients) and inform/facilitate medical treatment and monitoring of patients. For example, there is a wide range of mobile applications (apps) in health, fitness, weight-loss, and other healthcare related categories. These apps mainly function as a tracking tool, such as registering user exercises/workouts, keeping the count of consumed calories, and other statistics (e.g. number of steps taken), and so on.",https://doi.org/10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"Grouping guests into cloudlets makes it easier to schedule jobs and monitor and manage the infrastructure. For example, only hosts within a specific cloudlet need to be taken into account when scheduling a job destined for that cloudlet. Cloudlets can also be managed to determine if a cloudlet's resources should be adjusted based on current computational requirements.",https://doi.org/10.1109/CLOUD.2015.153,Ad Hoc Cloud Computing,20 August 2015,0
"Security is one of the biggest challenges to the cloud model, and it's often an emotional one as well. Again, the utility analogy isn't very illuminating here because most companies spend little time worrying about whether their electrical wires are being compromised. In contrast, a violation of data security is a paramount concern to an organization.",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"The fault predictor module predicts future fault and, send alarm to PLR controller daemon. PLR controller daemon monitors the VMs and MPI applications. It has the visibility of HPC applications running on VMs and the visibility of virtualized environments. The PLR controller daemon ensures that redundant nodes are available for live migration and checkpointing. If the nodes are not available, it makes provision of redundant nodes. PLR controller daemon also initials and carries live migrations of VMs to redundant nodes. It initiates checkpointing of MPI applications after migration.",https://doi.org/10.1109/CCGrid.2012.80,A Fault Tolerance Framework for High Performance Computing in Cloud,14 June 2012,0
"All interviewed institutions preferred a hybrid model to be designed for their institution where all institutions' sensitive data and critical services should be private. The Hybrid deployment model was highly preferred because of policies and regulations which restrict outsourcing of critical institutional data and computing services. Also, doubt on cloud security was the basis for their choice on hybrid model. The preferred model rises concern on technical and operational feasibility of an institution to own and manage a private datacenter. Decision on the type of Hybrid model to be built should be made by taking into account the proposed model and current TC infrastructures.",https://doi.org/10.1109/SCAT.2014.7055151,Road map towards eco-efficient cloud computing adoption in higher learning institutions in Tanzania,5 March 2015,0
"There is a critical piece of software, called the Membership Controller(MC), that resides on each member node that contributes resources to the CU Cloud system. MC monitors the resource usage at a member node and decides the node's membership status: active status indicates there are enough resources to meet the need of a minimum VM, while inactive status indicates unavailability of such resources.",https://doi.org/10.1109/CLOUD.2017.99,"A ""No Data Center"" Solution to Cloud Computing",11 September 2017,0
"Due to deep complex intertwining among different data sources, data analytic activities, EDC, CDC, the design, implementation, and testing of these new IoTDAP face many challenges that arise from the rapid increase of the number and types of sensing devices, type, and scope of resources in EDC and CDC, type and scope of big data programming models, functional complexity, data formats heterogeneity, the increasing deployment of distributed and networked architecture.",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
"The inside-vehicle layer is responsible for recognition of driver behavior, health etc. and information inside the car like temperature through various sensors namely body sensors, vehicles internal sensors, smart phone sensors or apps etc. The data collected must be sent to the cloud for storage and it can also be used as input to various software programs and application related to health and environmental recognition applications. The vehicle is equipped with OBU that contain Radar, GPS etc. to send the location information to the cloud storage.",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"A user can get service from a full computer infrastructure through the Internet. This kind of service is called Infrastructure as a Service (IaaS). Internet-based services such as storage and databases are part of the IaaS. Other types of services on the Internet are Platform as a Service (PaaS) and Software as a Service (SaaS). PaaS offers full or partial application development that users can access, while SaaS provides a complete application, such as Enterprise Resource Management through the Internet[3].",10.1109/ICCASM.2010.5623257,The comparison between cloud computing and grid computing,4 November 2010,0
"Recently, cloud computing has been considered as one of the most rapidly evolving technologies. This rapid growth assists in attracting attention of large IT companies and users [1]. These companies have been increasingly encouraged to adopt cloud environment for hosting different service platforms such as EC2 by Amazon and Google Apps by Google [2]. Coinciding with the growth of cloud computing, end-user mobility has become a significant feature of contemporary wireless network [3]. Lately, many developments have been accomplished in term of storage and computing demands of mobile applications [4]. Despite these developments, mobile devices still consider as resource-constrained devices for the various issues that need to be handled such as performance, security, and environmental issue. A way to handle with these constrained is by employing cloud technology which provide virtually unlimited dynamic resources for storage and computation [5].",10.1109/MobileCloud.2017.26,Energy-Aware Fault Tolerant Task offloading of Mobile Cloud Computing,12 June 2017,0
"Cloud computing ensures large amount of data storage and requested data is provided based on the requirement and demand from the cloud users. There are many fundamental issues, problems and challenges related to this data security. A well-defined infrastructure enabled with strong encryption mechanism can be treated as a solution to handle these data security issues and challenges in cloud computing environment",10.1109/ICCCNT49239.2020.9225396,Detection and Prevention Mechanisms for DDoS Attack in Cloud Computing Environment,15 October 2020,0
"This defines cloud computing usage for semantic technologies. A deep level of interaction is defined here, in which specific, core cloud computing mechanisms are defined and configured to facilitate specific processes within the implementation of annotation for the semantic web. With scalability being one of the major challenges of the semantic web so far [6], the idea is based on the use of these mechanisms to overcome the prevalent challenges with the required processes for the provision of large-scale semantic annotation on the web. This would imply a semantic web that is dependent on a cloud platform for its delivery. Also, with the massive migration of data and applications to the cloud and the convergence of the web and the cloud [7], it is logical to consider a semantic web facilitated (or driven) by a cloud platform. The semantic annotation capability model proposed in this paper is based on the cloud-driven mode of interaction described above and it has been developed based on a specific methodology.",10.1109/DeSE51703.2020.9450748,A Cloud Computing Capability Model for Large-Scale Semantic Annotation,14 June 2021,0
"This utility analogy has taken hold in the public imagination. Although useful, this analogy isn't entirely accurate because it blinds us to the cloud's limitations for enterprises. The reality is that cloud computing simply can't achieve the same plug-and-play simplicity as electricity.",10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"Many edge-cloud applications combine features from edge and cloud so there are various factors that influence the deployment, provisioning and analysis. In this paper, we focus on the impact of performance and data quality for edge cloud applications. Our work experiments performance and data quality for complex mobile edge cloud applications due to the lack of tools and the complexity of such applications. We focus on realistic applications in the connected vehicles domain that are suitable for edge cloud computing, and we study performance and data quality impacts in the design and deployment models. We select a mobile edge cloud cornering assistance (MECCA) application which includes features from IoT, big data services, and streaming data processing that are provisioned in edge and cloud infrastructures. Our contributions are to present steps/techniques for analytics of mobile edge cloud applications and lessons learned through real examples.",10.1109/CLOUD.2018.00091,Analytics of Performance and Data Quality for Mobile Edge Cloud Applications,11 September 2018,0
"Many IT Industries and organizations benefited from the assistance of big data with its Capacity, Scalability and velocity of cloud storage. Furthermore, new business opportunities were created in IT Society as the end users has the possibility of visualizing their data in various dimensions. Big data already provides data analytics, allows end user to personalize their information [17]. Additionally, it also provides predictive analytics, allows end user to predict their data for information processing for their business applications.",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
Top management play an important role and have a significant impact on the adoption rate of IT innovations at the organisational level. Support from top management is essential because they have the ability to make the change and execute acceptance of the cloud. This change in the organisation needs a supportive decision from top management.,https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"Though the computing capacity of mobile devices has rapidly increased recently, there are still numerous applications that cannot be solved with them in reasonable time. Our approach is to utilize cloud infrastructure services to execute such applications on mobile data stored in Personal Clouds. The basic concept of our solution is the following: services for data management are running in one or more IaaS systems that keep tracking the cloud storage of a user, and execute data manipulation processes when new files appear in the storage",10.1109/BDCloud.2014.41,Interoperating Cloud Services for Enhanced Data Management,9 February 2015,0
"To choose where to deploy an application, many system managers therefore ask, “Does my organization consider any part of this application too risky to deploy on a public cloud?” If they answer yes, they must deploy the application on a private cloud, with its inherent restrictions. If not, the public cloud is an option.",10.1109/MCC.2014.46,Application Security through Federated Clouds,30 September 2014,0
"Firewall, IDPS, and DLP. Private clouds mediate external access from untrusted, nonenterprise users via the corporate firewall, an intrusion detection/prevention system (IDPS), and a data loss prevention (DLP) tool. Cisco Systems, for example, offers intrusion detection and prevention signatures that protect private clouds utilizing an enterprise perimeter.",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"Ontologies have been used in a number of applications areas, such as bioinformatics. They provide a mechanism for explicit knowledge definition, for use by stakeholders (users, customers and software system developers). Problems are expressed as terminology (T-Box) and assertions (A-Box). Description logics [5] and associated formalisms allow development of unambiguous expressions of semantic terms within ontology.",https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"AbiCloud is a private Cloud solution developed by Abiquo. It enables users to build Infrastructure as a service Cloud environment. The supported virtualization techniques of AbiCloud are VirtualBox, VMWare, XEN, and KVM.",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"We propose using federated cloud computing to manage and govern the data generated in huge volumes and high velocity from various data sources. Federated cloud computing involves multiple private, public, and/or community clouds collaborating to achieve a common goal. Our proposed disaster relief approach also involves acquiring raw data in situ, and processing and aggregating this sensor data within the federated cloud framework to arrive at a consolidated and dependable analysis of a disaster's affects.",10.1109/MCC.2014.72,Evacuation and Emergency Management Using a Federated Cloud,30 November 2014,0
"The first limitation is scalability. On-premise private cloud deployments might not consider future growth, resulting in limited scalability. This isn't surprising, as building highly scalable private clouds requires a large capital investment for procuring and installing computing and storage resources. However, the changing volume, velocity, and variety of data make it difficult to accurately plan private cloud capacity, and private clouds are often either under-or overprovisioned. To reduce capital investment, private clouds are always built with limited scalability.",10.1109/MCC.2015.36,Trustworthy Processing of Healthcare Big Data in Hybrid Clouds,2 June 2015,0
"IoT elements (sensors, actuators, gateways, lightweight applications, and so on) are developed, de-ployed, and operated separately from cloud services (such as storage and data processing). Because of the complexity of software ecosystems, IoT providers are increasingly different from cloud providers with regard to communication protocols, software layers, and provisioning models, to name just a few. In addition, although cloud services, such as load balancers, message-oriented middleware, NoSQL storage, and streaming data processing frameworks, are designed to accept workloads and data from IoT they lack capabilities to be coordinated with IoT operations. For example, most cloud services reactively monitor the load from IoT and adjust their performance be-havior, but rarely communicate back to the IoT elements to steer the load generated by the IoT.",10.1109/MCC.2015.23,Principles for Engineering IoT Cloud Systems,2 June 2015,0
"Due to security and privacy concerns, however, some users and companies still hesitate to move their data to the cloud. Although encryption can protect data confidentiality, it's insufficient because access patterns can also leak important information. For instance, more than 80 percent of encrypted email queries can be identified by analyzing user access patterns.",10.1109/MCC.2016.107,Privacy-Preserving Access to Big Data in the Cloud,11 November 2016,0
"A follow-up study showed that it's possible to extract private keys via the cross-VM side channel in a lab environment.2 In another study, researchers from the College of William and Mary reported that side-channel attacks aren't just a potential risk, but a realistic threat.3 They created a covert channel via another shared resource (the memory bus) that had a level of reliability and throughput of more than 100 bps in both lab and EC2 environments.",10.1109/MCC.2014.20,Security and Privacy in Cloud Computing,10 July 2014,0
"Companies must combine and analyze this distributed data along with contextual factors such as weather forecasts and pricing positions to establish which factors strongly influence the demand of particular products and then quickly take action to adapt to competitive and evolving environments. Similarly, syndromic surveillance IoT applications require churning through massive amounts of heterogeneous, real-time information available from social media, emergency rooms, health departments, hospitals, and ambulatory care sites to detect outbreaks of deadly diseases such as SARS, avian flu, cholera, and dengue fever.",10.1109/MCC.2015.14,Processing Distributed Internet of Things Data in Clouds,22 April 2015,0
"These vulnerabilities leave loopholes, allowing cyberintruders to exploit cloud computing services and threatening the security and privacy of big data. Various security schemes, such as encryption, authentication, access control, firewalls, intrusion detection system (IDSs), and data leak prevention systems (DLPSs), address these security issues. In this complex computing environment, however, no single scheme fits all cases. These schemes should thus be integrated and cooperate to provide a comprehensive line of defense.",10.1109/MCC.2014.53,Enhancing Big Data Security with Collaborative Intrusion Detection,30 September 2014,0
"Confidentiality is to ensure that messages can only be read by those who are authorized. In VANET, the information exchanged is mostly public except information related to the privacy of users. So, it is important that every user or vehicle must be registered to RSU when comes in the range of it and communication must be encrypted and secured by using public key infrastructure.",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"RightScale's new State of the Cloud Report confirms that containers (exemplified by Docker and CoreOS) are undergoing rapid growth.1 The quick uptake of containers makes a lot of sense given what they offer. At a high level, containers provide lightweight platform abstraction without using virtualization.",10.1109/MCC.2016.122,Moving to Autonomous and Self-Migrating Containers for Cloud Applications,30 December 2016,0
"These additional facts bring to light the dichotomy between enterprises' need/desire to migrate high-value data into cloud workloads to realize the promise of increased productivity and operational efficiency, while at the same time fearing the risks associated with operation of the cloud models used to host this data. In addition, a general lack of knowledge and understanding of cloud computing is keeping many organizations from adopting and using cloud platforms and services overall.",10.1109/MCC.2016.21,The Hybrid Cloud Security Professional,26 February 2016,0
"With an older monolithic architecture, it's difficult or impossible to release systems over a certain size. Capers Jones, writing in 1999 after a study of 1,000 applications, wrote that “MIS applications greater than 10,000 function points are rarely successful.”1 These problems have resulted in failed systems costing hundreds of billions of dollars over the last 50 years. Needless to say, in the more than 15 years since, many more failures have occurred.",10.1109/MCC.2016.109,The Economics of Microservices,11 November 2016,0
"Existing streaming data analysis platforms including (e.g., Spark6, Heron7, Google Dataflow8, AWS, Kinesis1, StreamCloud, Apache Storm), are CDC-centric, hence they do not meet the resource management and scheduling requirements for IoT workflows that require coordinated mapping for data analysis activities to both CDC and EDC. Many workflow application management platforms such as Pegasus, Tri-ana, Taverna, Galaxy, e-Science Central, and Kepler support the development, deployment and execution of scientific workflow applications on CDC without considering newly evolved EDC capabilities. Apache Oozie and Linkedin Azkaban support a Hadoop workflow, but in a rather rigid manner that works well for only batch processing activities. Data analytics platforms such as YARN, Mesos Amazon IoT and Google Cloud Dataflow can support manual provisioning of multiple data transformation tasks on CDC resources, but only in a performance-agnostic way.",10.1109/MCC.2017.22,Osmotic Flow: Osmotic Computing + IoT Workflow,26 April 2017,0
DoS have become very serious threat when the organizations are dependent on the services for 24/7. It temporarily denies the access of data stored in the cloud to the authorized users by make an attack on the server by sending thousands of requests to it become unable to respond to the regular clients.,https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"To manage EHRs efficiently and securely, we propose a design based on steganography, which we use to hide confidential EHR data inside the ECG host data. Steganography offers more efficient and secure information concealment than traditional cryptography.7 Only authorized users can extract data based on their security parameters.8 Our steganography-based approach therefore improves the security of storage and retrieval of EHRs by hiding them inside ECG signals, and enhances performance through flexible feature adoption (such as dynamic policy changes).",10.1109/MCC.2016.76,Hybrid Cryptographic Access Control for Cloud-Based EHR Systems,19 September 2016,0
"Identity and access. A private cloud available for internal enterprise users is easily integrated with existing identity and access management functions, such as corporate directory services. Products such as the IBM Security Identity Manager and Security Access Manager, for example, provide customizable identity and access management support for private cloud deployments.",10.1109/MCC.2014.17,Practical methods for securing the cloud,10 July 2014,0
"Nowadays search engines have influenced people's behavior in using the Internet. Various search engines have been built up and some of them are very dominant, like Google, Yahoo, and Bing. Google, for example, logs 2 billion searches per day and 300 million users use the search facility provided by Google on a daily basis [1]. This number is set to rise in the future so that the facility must be provided by very huge infrastructure and must be coordinated by each other. The infrastructure in this context could consist of a number of machines that runs crawler engine, application servers to accommodate the high demand and storage servers or disk to store the results of all searches.",10.1109/ICCCSN.2012.6215751,Building crawler engine on cloud computing infrastructure,14 June 2012,0
"Parallel computing is a computational paradigm that can be contrasted with the traditional serial computing methodology. In this manner, concurrent execution of many computing operations occurs, contrasting with the typical sequential execution strategy. The process of dividing a task into many sets of instructions, each addressing a specific subtask, in order to enable concurrent resolving, is allocated to several processing elements for implementation.",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"From the review of publications focusing on the interaction between cloud computing and semantic technologies, it can be observed that the implementation of cloud computing solutions is proposed for web applications across different sectors such as electronic learning, biomedicine, forensics, etc. The authors are generally of the opinion that cloud computing provides appropriate solutions for the enhancement of the semantic web as it applies to different industry sectors. There are suggestions that it can play an instrumental role in enhancing the sematic web because of its numerous characteristics that offer cloud resources on demand to clients and thereby support different business models, with a cloud computing architecture that enables developers to efficiently build and deploy distributed systems [8]; [9]; [10]. This implies that semantic web applications can be developed for public distribution through a cloud platform. Also, with cloud computing’s high-performance ability, relatively low cost, and scalability attributes, it is beneficial for driving the semantic web, presenting an effective paradigm for managing, deploying, and offering services using shared infrastructure [11].",10.1109/DeSE51703.2020.9450748,A Cloud Computing Capability Model for Large-Scale Semantic Annotation,14 June 2021,0
"In chemistry, “osmosis” represents the seamless diffusion of molecules from a higher to a lower concentration solution. We believe this process should represent how services can be migrated across data-centers to the network edge. Hence, osmotic computing implies the dynamic management of services and microservices across cloud and edge datacenters, addressing issues related to deployment, networking, and security, thus providing reliable IoT support with specified levels of QoS. Osmotic computing inherits challenges and issues related to elasticity in cloud datacenters, but adds several features due to the heterogeneous nature of edge datacenters and cloud datacenters. Moreover, various stakeholders (cloud providers, edge providers, application providers, and so on) can contribute to the provisioning of IoT service and applications in a federated environment.",10.1109/MCC.2016.124,Osmotic Computing: A New Paradigm for Edge/Cloud Integration,30 December 2016,0
"Recent advancements in container technologies and the capability to overcome limitations in virtualization have, perhaps, encouraged the use of containers in the cloud for software development and deployment. This might also have paved the way for the adoption of a microservice architectural paradigm in cloud-hosted software by lowering infrastructure and maintenance costs.2, 5, 6 For example, microservices support the realization of small (sized) applications that are fine-grained and loosely coupled and communicate through REST protocols. These applications are implemented using APIs provided by the infrastructure-as-a-service (IaaS) layer for provisioning data computing, storage, and delivery capabilities.",10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
"Some public verification schemes don't protect against external adversaries, so an active and online adversary can intrude into the cloud server, modify the outsourced data, tamper with the interaction messages between the cloud server and auditor, and pass the auditor's verification. (See the “Literature Review” sidebar for related work in this area.) A common approach to resisting such adversaries is to have the cloud server interact with the auditor using a secure channel. However, constructing a secure channel for each verification task is cumbersome.",10.1109/MCC.2016.94,Cryptographic Public Verification of Data Integrity for Cloud Storage Systems,11 November 2016,0
"Amazon Web Services was the first cloud provider to introduce serverless with “Lambda functions” in 2014, but similar offerings from Google, Microsoft, IBM, and others have been introduced since then. Many smaller players are also planning offerings, eager to take part in the trend. There are many similarities and some differences between pricing models and actual prices, and cloud pricing is notoriously subject to frequent revision, but let's take a look at one that is very representative—Amazon Web Services Lambda functions (at the time of this writing).",https://doi.org/10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"In cloud computing, the biggest challenge is to detect and prevent malicious hackers and to overcome security threats. Most of the big data techniques helps in detecting threats of fraudulent activities occurs over internet. Another biggest challenge is information privacy issues in IT societies. Due to increase of Big Data Utilization in cloud computing, more IT industries and IT Business suffers from privacy issues. Instead of assuring security policies and privacy techniques on IT industries, it is better to revise the policies and regulations of cloud computing, so that there will be a balance between data security and privacy polices provide to global users",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"The attacker can take advantage of the flaws contained in user software deployed in cloud infrastructure. Flaws can be caused by errors of coding, design, deployment, etc. In this case, the attacker can achieve the execution of an arbitrary code with the rights of the user who launched the process.",https://doi.org/10.1109/SCM58628.2023.10159053,Model of a Self-Healing Computing Process of a Cloud Computing System under Conditions of Information and Technical Impacts,26 June 2023,0
"For instance, some programs have built-in systems such as credit validations, mapping, and address validation services that must be maintained. This can cost upward of hundreds of thousands of dollars per year. The service-based approach lets us reach out and consume remote services that provide this functionality and more, so you can get out of the business of maintaining services that can be found in other places. It also lets us expose services for use within the enterprise by other applications, or even sell services to other enterprises over the open Internet.",10.1109/MCC.2016.114,Practical Use of Microservices in Moving Workloads to the Cloud,11 November 2016,0
"A horizontal representation of IoT driver technologies illustrates the connectivity and common operational platforms (Figure 1).1, 3 The functionalities of the layers presented in Figure 1 are defined with respect to the Open Systems Interconnection (OSI) model layers. The edge network layer, which corresponds to the OSI model's physical layer, is the data perception layer, which is responsible for sensing the physical environment, collecting real-time data, and reconstructing a general perception of the data. These technologies and devices typically have short-range communication, constrained batteries, and low storage and computational power. The access network layer represents the data link layer and has heterogeneous communication technologies that enable the first stage of data transmission in terms of communication path handling and data publishing. This layer's major services include message routing, publishing, and subscribing.",10.1109/MCC.2016.28,The Quest for Privacy in the Internet of Things,25 May 2016,0
"Virtualization increases the utilization of computing servers by allowing them to host multiple virtual machines simultaneously on each of these physical servers; thus, virtualization provides a direct impact on energy efficiency of a single server as well as a datacenter.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"Amazon maintains 38 availability zones within 14 geographic regions around the world, with nine more availability zones and four more regions coming online throughout the next year.7 According to Amazon,8 most data centers house between 50,000 and 80,000 servers, and always less than 100,000 servers. If we consider that each of these zones has one or more data centers, a conservative estimate puts Amazon at over 2–4 million servers globally.",10.1109/MCC.2017.42,The Limits to Cloud Price Reduction,29 June 2017,0
"In the first communication flow, secondary healthcare providers retrieve patient data to provide the appropriate follow-up examination (such as specialist medical services and examinations). In the second communication flow, primary healthcare providers are notified whenever new information (such as medical records) relating to a given patient is available, thus facilitating a smooth handover. Also, at the administration level of a healthcare provider, there's a communication flow in which the administration collects relevant documents for a range of functions (such as billing). This flow is similar to the second communication flow between primary and secondary healthcare providers. Such a communication flow is also of interest to the administration of the secondary healthcare structures and providers.",10.1109/MCC.2016.139,Healthcare-Related Data in the Cloud: Challenges and Opportunities,30 December 2016,0
"There are also devices with embedded sensors for more advanced medical tasks, such as bracelets to measure heartbeat during workouts, or devices for self-testing of glucose. For example, Leu and collaborators proposed a smartphone-based wireless body sensor network to collect user physiological data using body sensors embedded in a smart shirt.8 The data (e.g. user's vital signs) can be continuously gathered and sent in real-time to a smart device, before being sent to a remote healthcare cloud for further analysis. Another example is Ambient Assisted Living solutions for healthcare designed to realize innovative telehealth and telemedicine services, in order to provide remote personal health monitoring.9",https://doi.org/10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"From a technical viewpoint, a cloud's system elements include processing, network, and storage elements. The cloud architecture consists of three abstract layers: infrastructure, platform, and application. Infrastructure is the lowest layer and is a means of providing processing, storage, networks, and other fundamental computing resources as standardized services over the network. Servers, storage systems, switches, routers, and other systems handle specific types of workloads from batch processing to server-storage augmentation during peak loads. Cloud providers' clients can deploy and run operating systems and software for their underlying infrastructures. The middle layer provides higher abstractions and services to develop, test, deploy, host, and maintain applications in the same integrated development environment. This layer provides a runtime environment and middleware to deploy applications using programming languages and tools the cloud provider supports. The application layer is the highest layer and features a complete application offered as a service. Figure 1 shows a cloud infrastructure's general layered architecture, with the additional user interface layer, which enables seamless interaction with all the underlying everything-as-a-service layers.",10.1109/MIC.2010.113,Cloud Computing: The New Frontier of Internet Computing,2 September 2010,0
"There are many challenges that exist in cloud computing such as privacy, security and availability due to its dynamic resource provisioning based on the on demand requests from cloud users. There are many mechanisms available for handling these security and privacy issues in cloud computing. But these approaches cannot be directly applied to fog computing due to a mixture of features that treat it different form cloud [1]. Cloud computing is derived from many paradigms like distributed computing, utility computing, service oriented computing and grid computing. For privacy protection there are many approaches available which are being used in cloud computing environment like attribute based encryption, key policy ABE, cipher text ABE, encryption based on hierarchy, searchable technique using encryption and re-encryption based on proxy etc.",10.1109/ICCCNT49239.2020.9225396,Detection and Prevention Mechanisms for DDoS Attack in Cloud Computing Environment,15 October 2020,0
"A follow-up study showed that it's possible to extract private keys via the cross-VM side channel in a lab environment.2 In another study, researchers from the College of William and Mary reported that side-channel attacks aren't just a potential risk, but a realistic threat.3 They created a covert channel via another shared resource (the memory bus) that had a level of reliability and throughput of more than 100 bps in both lab and EC2 environments.",10.1109/MCC.2014.20,Security and Privacy in Cloud Computing,10 July 2014,0
"The obvious solution is to deploy these security sensitive applications on the organization's internal computer infrastructure, which is often (rightly or wrongly) perceived to be more secure than the public cloud. However, these private clouds have some important limitations. Although scalability in a public cloud is effectively infinite for most applications because of the sheer magnitude of the resources available,[3] private clouds are limited by the size of the organization's internal IT. Further, not all the scalable, platform-level services that are offered on public clouds are available in the private cloud. For example, Amazon offers a range of scalable data storage solutions for structured and unstructured data, not all of which are available for deployment on private clouds.",10.1109/MCC.2014.46,Application Security through Federated Clouds,30 September 2014,0
"A cloud based architecture is particularly suitable for video analysis since it often involves in intensive computations. The heavy loading of complex computations can thus be shifted to cloud servers to alleviate the power consumptions of mobile devices or video sensors. In addition, the centralized service-oriented model of cloud computing relieves service providers from the burden of deploying and upgrading their software.",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
"Wireless connectivity is always unstable, especially in the personnel-intensive areas or under some special circumstances. How to guarantee the normal operation of the mobile application is a difficulty in the case of a sudden loss of connectivity [25]. For example, in a mobile Ad hoc cloud, if a mobile node suddenly disconnects from the network, how is the node’s computing task to be handled? So user mobility and network availability should be taken into account in the process of task division and migration. In addition, mobile caching technology provided by HTML5 can be used as an auxiliary solution.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"These data centers are smaller in size and are huge in number linked geographically along the network edges. These data centers save more energy as compared to normal data centers. [4] So, in order to reduce energy wastage, nano data centers came into picture.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"These facts illustrate the general direction cloud deployment is trending toward in the enterprise, but they do not tell the entire story. What about the security concerns and implications of continued placement of cloud workloads across one or more cloud models? According to Eurostat's Cloud Computing-Statistics on the Use by Enterprises report",10.1109/MCC.2016.21,The Hybrid Cloud Security Professional,26 February 2016,0
"Decently, we've seen a wide adoption and deployment of Internet of Things (IoT) I’) infrastructures and systems for various crucial applications, [1] such as logistics, smart cities[2] and healthcare. This has led to high demands on data storage, processing, and management services in cloud-based datacenters, engendering strong integration needs between IoT and cloud services. Cloud services are mature and provide excellent elastic computation and data management capabilities for IoT. In addition, as IoT systems become complex, cloud management techniques are increasingly employed to manage IoT components. Thus, cloud services now act as computational and data processing platforms as well as management platforms for IoT. From a high-level view, IoT appears to be well-integrated with cloud datacenters to establish a uniform infrastructure for IoT cloud applications. However, the software layers on top of such integrated infrastructures are still fragmented, and therefore far from a uniform software layer to support a coherent execution environment for complex applications.",10.1109/MCC.2015.23,Principles for Engineering IoT Cloud Systems,2 June 2015,0
"In reality, moving from an internal cyber-physical network to the cloud can lead to various security issues. There are only a few known cyberattack incidents on cyber-physical systems, but a successful attack can have real-world and catastrophic consequences. A recent survey suggested that the role of digital forensics in CPCS incident handling isn't widely understood.3 Although existing digital forensics tools and techniques are unlikely to stop an attack in real time, a forensic-by-design approach can help in several ways. For example, it can help identify an incident by its source and determine its type, preserve and analyze critical evidential data, reconstruct fragments of evidential data and draw conclusions, and accelerate information asset restoration.",10.1109/MCC.2016.5,Forensic-by-Design Framework for Cyber-Physical Cloud Systems,26 February 2016,0
"Big data has emerged in domains such as science, engineering, and comO merce. Facebook, for example, currently stores more than 20 petabytes of photos, and this number grows by 60 terabytes each week.1 In the big data era, clouds become a perfect candidate for data storage by providing virtually unlimited storage that can be accessed over the Internet. By outsourcing large volumes of data to cloud storage, such as Google Drive, Dropbox, and Amazon Simple Storage Service, users can simplify their data management and reduce data maintenance costs through the pay-as-you-use model.",10.1109/MCC.2016.107,Privacy-Preserving Access to Big Data in the Cloud,11 November 2016,0
"Enter new approaches based on old approaches, namely containers, and thus Docker and container cluster managers, such as Google's Kubernetes, as well as hundreds of upstarts. The promise is to provide a common abstraction layer that allows applications to be localized within the container, and then ported to other public and private cloud providers that support the container standard.",10.1109/MCC.2016.122,Moving to Autonomous and Self-Migrating Containers for Cloud Applications,30 December 2016,0
"Clearly, contemporary disaster relief infrastructure and methods are inadequate, time-consuming, and certainly not optimally designed-especially given that the first 24 to 72 hours (the “golden 72”)-are critical to the rescue of disaster victims. Thus, we need an efficient and decisive emergency management and evacuation policy. To optimize such policies, it's important to analyze huge volume of data generated from different sources.[",10.1109/MCC.2014.72,Evacuation and Emergency Management Using a Federated Cloud,30 November 2014,0
"The success of each of these innovations required standards to be invented and adopted. Electricity required reproducible components that would fit together, and choices had to be made in terms of voltage, physical sockets, and connection interfaces. Units of usage in terms of billable measurements and metrics had to be standardized and adopted. Standardized streetcar designs and rail widths had to be adopted or migrated from similar technologies and had to be uniform at least within each city or region in which the lines ran.",10.1109/MCC.2015.27,"Invention, Innovation, and New APIs",2 June 2015,0
This is the most familiar and prolific cloud service. All the applications that provide a direct service to the client and run on the Cloud are located in the SaaS layer.,https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"Cloud proponents often compare utility computing to electrical utilities. One of the most prominent voices behind this argument is Nicholas Carr, author of The Big Switch: Rewiring the World, from Edison to Google (Norton, 2008). Carr hails utility computing as a historic shift similar to the advent of electrical utilities. A century ago, factories provided their own power, but with the emergence of large utilities, electricity became a cheap commodity, enabling businesses to simply plug into the grid. Carr argues that a similar phenomenon is occurring with cloud computing. Private computer systems are being supplanted by services provided via the Internet. “It may take decades for companies to abandon their proprietary supply operations and all the investment they represent,” writes Carr. “But in the end the savings offered by utilities become too compelling to resist, even for the largest enterprises. The grid wins.”",10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"So, the users were able to access a computer from anywhere on a network which was mainly used to link the government agencies and universities. As a result of which, Internet was developed. Then, with the advent of operating system, multiple functions could be carried out at the same time on standalone computers for the first time. This paved the way for multiple users to use many systems at the same time.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"Complexity problems often arise in legacy, monolithic systems, such as large enterprise resource planning or core banking systems, making them inflexible and expensive to maintain. In many cases, such systems are linked together so even an apparently trivial change in a single component can create errors in that component or others. This therefore requires regression testing of all components and the system as a whole. We see the same complexity and reliability requirements in new software and digital products. When many changes, ranging from bug fixes to feature enhancements, occur in a monolithic application, it might never become stable and reliable.",10.1109/MCC.2016.109,The Economics of Microservices,11 November 2016,0
"Compared to traditional service computing—which is characterized by powerful service hosts, relatively stable networks, and simple interaction patterns—mobile service computing faces five inherent challenges: constant mobility, limited capability, restricted power, unguaranteed security, and undetermined willingness.",10.1109/MCC.2016.92,Toward Mobile Service Computing: Opportunities and Challenges,19 September 2016,0
"Globus is a hosted provider of high-performance, reliable, and secure data transfer, synchronization, and sharing.[4] In essence, it establishes a huge distributed data cloud through a vast network of Globus-accessible endpoints-storage resources that implement Globus's data access APIs. Through this cloud, users can access, move, and share large amounts of data remotely, without worrying about performance, reliability, or data integrity.",10.1109/MCC.2014.52,"Efficient and Secure Transfer, Synchronization, and Sharing of Big Data",30 September 2014,0
As technology is changing day by day the laws should also be updated so that it can provide full fledge security. The cloud provider should establish transparent policies to customer so that customers can easily understand them.,https://doi.org/10.1109/CSNT.2015.141,Efficient Framework Approach to Extract Privacy Issues in Cloud Computing,1 October 2015,0
"These technical and business advantages, however, don't come without cost. The security vulnerabilities inherited from the underlying technologies (that is, virtualization, IP, APIs, and datacenter) prevent organizations from adopting the cloud in many critical business applications.1 Generally speaking, cloud computing is a service-oriented architecture (SOA). Earlier work gives a comprehensive dependability and security taxonomy framework revealing the complex security cause-implication relations in this architecture.2 We summarize cloud computing vulnerabilities by underlying technology in the sidebar.",10.1109/MCC.2014.53,Enhancing Big Data Security with Collaborative Intrusion Detection,30 September 2014,0
"The IoT vision is to allow things to be connected anytime, anywhere, with anything and anyone, ideally using any path, network, and service. This vision has recently given rise to the notion of IoT big data applications that are capable of producing billions of datastreams and tens of years of historical data to provide the knowledge required to support timely decision making. These applications need to process and manage streaming and multidimensional data from geographically distributed data sources that can be available in different formats, present in different locations, and reliable at different levels of confidence.",10.1109/MCC.2015.14,Processing Distributed Internet of Things Data in Clouds,22 April 2015,0
"A datacenter contains a pool of servers and varying workload. As part of power management, the techniques like Variable power on / off can be adopted, which allows to power on only those servers having a workload.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"An essential task in cloud security and privacy research is to identify new threats and vulnerabilities that are specific to cloud platforms and services. Several recent reports have explored such vulnerabilities. For example, in 2009, researchers from the University of California, San Diego, and the Massachusetts Institute of Technology demonstrated leakage attacks against Amazon's Elastic Compute Cloud (EC2) virtual machines (VMs).1 More specifically, the researchers showed that it's possible to probe and infer the overall placement of VMs in the EC2 infrastructure. Furthermore, an attacker can launch a malicious EC2 instance and then determine whether that instance is physically colocated with a targeted (victim) instance. When the attacker's instance is successfully colocated with the victim, it can launch a side-channel attack by monitoring the status of shared physical resources such as level-1 and level-2 caches, and thus infer the victim's computation and I/O activities.",10.1109/MCC.2014.20,Security and Privacy in Cloud Computing,10 July 2014,0
"Zhang et al. proposed an elastic application model [6], which divided the application into multiple weblets and provided optimal resilience by taking into account factors such as the resource availability of the mobile device and cloud, user preferences, program performance, etc.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"Next, EDC can be defined as a “collection of heterogeneous resources including smart IoT devices, IoT gateways (e.g., raspberry pi 3, UDOO board, esp8266, etc.), and Software Defined Networking (SDN) and Network Function Virtualisation (NFV) devices (e.g., Cisco IOx, Hewlett Packard (HP) OpenFlow and Middlebox Technologies) at the network edge that can offer computing and storage capabilities on a pervasive—yet much smaller—scale than CDCs. The scope and role of each resource in an EDC differs. For example, IoT gateways collect, aggregate, and process the data generated by the sensing devices.",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
"Cloud computing systems include infrastructure and software that can be delivered in the form of remote services on a pay-as-you-go pricing model; these cloud systems have been defined as the next step of the Internet's evolution. Today, another promising technology is edge computing, which pushes clouds away from their logical network, creating fog computing.12 Fog computing expands cloud functionality, allowing business logic and process management to be executed as near as possible to the actual data source (that is, the laptop or smartphone). This alternative view of clouds extends services to user premises and is utilized directly in users' personal devices. Fog computing could offer cloud technology know-how for remote data storage and management, while local data processing facilitates a self-adaptive environment for data extraction and analysis, such as in mobile devices. In such a solution, traditional legacy systems must be imported to the cloud infrastructure and interoperate in both local and remote clouds. To achieve this, users' software and APIs must communicate successfully and understand the new system constraints.",10.1109/MCC.2016.128,Internet of Things Architecture for Enhanced Living Environments,30 December 2016,0
"Thus, the main research questions we address here are how to securely store and manage big EHR data, and how to ensure secure access to this data. Cloud-based utility services (such as storage) offer additional benefits to EHR systems—for example, they're more cost effective, can be easier to manage (for example, access and retrieval), and support collaboration, with mobile technologies and devices to gather data.4, 5 Electrocardiography (ECG) provides an appropriate host signal and a verifiably secure means to store big EHR data in the cloud. To ensure secure access to big EHR data, we propose a cryptographic role-based access control method that's scalable to a large number of users.",10.1109/MCC.2016.76,Hybrid Cryptographic Access Control for Cloud-Based EHR Systems,19 September 2016,0
Providing security-as-a-service by using either by using established information security vendors or by cloud service providers providing security as cloud service with information security companies.,https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"We have identified real world scenarios that require interoperable data management among cloud infrastructures to manage user data produced by mobile devices. In general, services running in IaaS Clouds can download user data files from the cloud storage, execute the necessary application on these files, and upload the modified data to the storage service. Such files can be for example a photo or video made by the user with his/her mobile phone to be processed by an application unsuitable for mobile devices. In our solution currently developed for Android devices, there is a possibility to configure the processes to be performed on the data with a separate configuration file, which is automatically created and managed by a mobile application running on the users device. This application is also responsible for communicating with the cloud storage, which is Dropbox in our case. The file manipulation applications have been created as a virtual appliance, and have been pre-deployed in the participating IaaS Clouds.",10.1109/BDCloud.2014.41,Interoperating Cloud Services for Enhanced Data Management,9 February 2015,0
"Applications store and process data in the cloud, and users access data for diverse purposes, such as simple storage or analytics (see Figure 1). Because the reliability of cloud computing operations depends on the enforcement of security policies (access control, data encryption, and so on), security weaknesses and deficiencies must be addressed.",10.1109/MCC.2015.45,"Security and Privacy in Cloud Computing: Vision, Trends, and Challenges",2 June 2015,0
"This may seem obvious but this is where we get into what serverless really is at its core. In any supposedly “serverless” compute offering, someone (or something) is managing compute servers. But what's on these servers? Serverless isn't specific about how it's implemented so different cloud providers have different components making up the stack—but there are common crucial elements shared between them. You'll need a way to run code in isolation (e.g. Docker), a way to autoscale underlying compute, security monitoring, metrics, some kind of input/output layer for logging and passing data to and from your serverless functions.",10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"The goal of our design of ECaaS and associated apps is to ultimately develop and install ongoing health assessment, making it accessible for a broader group of older adults and physical therapy clinics. Toward this goal, we integrate living lab approaches and user experience principles. This helps us to prepare data-driven reflections for revisiting old and new design decisions and fosters future development of cloud-based services that can be delivered in ELEs for eldercare.",10.1109/MCC.2017.46,Toward an ElderCare Living Lab for Sensor-Based Health Assessment and Physical Therapy,29 June 2017,0
"To process data as they arrive, the paradigm has changed from the conventional “one-shot” data processing approach to elastic and virtualized datacenter cloud-based data processing frameworks that can mine continuous, high-volume, open-ended datastreams. This advancement is broadly supported by two key technologies.",10.1109/MCC.2014.22,Streaming Big Data Processing in Datacenter Clouds,10 July 2014,0
"VMs as the cloud's core virtualization construct have been improved successively by addressing scheduling, packaging, and resource access (security) problems. VM instances acting as guests use large, isolated files on their hosts to store their entire file system and typically run a single, large process on the host. Although security concerns are usually addressed through isolation, several limitations remain. Full guest OS images are required for each VM in addition to the binaries and libraries necessary for the applications. Full images create a space concern that translates into RAM and disk storage requirements and is slow on startup (booting might take from 1 to more than 10 minutes[4]) as in Figure 1, which shows the different architectural settings.",10.1109/MCC.2015.51,Containerization and the PaaS Cloud,15 July 2015,0
"A smooth intellectual transition can take place from observing that some real devices can be connected and automated to the assumption that everything can be treated as part of the same collection. It would not be correct, however, to assume that standards for communication protocols, hardware, device management, data formats, security, or any of the other myriad aspects of the “things” in the IoT will all become uniform and simplified on their own.",10.1109/MCC.2017.23,Standards at the Edge of the Cloud,26 April 2017,0
"Containers have long existed in various forms that differ by the level of isolation they provide. For example, Berkeley Software Distribution (BSD) jails and chroot can be considered an early form of container technology. Recent Linux-based container solutions rely on kernel support—that is, a userspace library to provide an interface to syscalls and frontend applications. There are two main kernel implementations: Linux container (LXC) implementations using cgroups and namespaces, and the OpenVZ patch. Table 1 shows the most popular implementations and their dependences.",10.1109/MCC.2016.100,To Docker or Not to Docker: A Security Perspective,11 November 2016,0
"In today's provider-centric clouds, service specification, security, dependability, pricing, and SLAs are beyond users' influence. To tackle the security and dependability challenges in a multicloud, we need new infrastructure management paradigms that are both user-centric and self-managed. The former means enabling self-service of cloud-of-clouds, where customers define their own protection requirements and can avoid technology and vendor lock-ins. The latter means reducing the administration complexity of cloud-of-clouds through automation techniques.",10.1109/MCC.2016.110,User-Centric Security and Dependability in the Clouds-of-Clouds,11 November 2016,0
"Osmotic computing is a new paradigm that's driven by the significant increase in resource capacity/capability at the network edge, along with support for data transfer protocols that enable such resources to interact more seamlessly with datacenter-based services. It aims at highly distributed and federated environments, and enables the automatic deployment of microservices that are composed and interconnected over both edge and cloud infrastructures.",10.1109/MCC.2016.124,Osmotic Computing: A New Paradigm for Edge/Cloud Integration,30 December 2016,0
"Nevertheless, the usage of an Osmotic Computing infrastructure (CDC+EDC) poses new challenges for IoT workflow application developers and operations managers as they need the awareness of resource/device (CDC server vs. IoT gateway) heterogeneity, virtualisation software heterogeneity (e.g., hypervisor vs. container), data analytic programming model heterogeneity (stream processing vs. batch processing), geographic distribution, and network performance uncertainties.",10.1109/MCC.2017.22,Osmotic Flow: Osmotic Computing + IoT Workflow,26 April 2017,0
"Job Reader Job Reader has function to read job that queuing and ready to be executed. Job Reader has function to start, pause, resume or stop depending on how it would be run. Job Reader also has function to set the speed to execute single job. We can define slow, middle or fast crawling with this module. This speed setting will affect such things as: how much traffic is flowing, how other hardware capabilities in handling high transaction.",10.1109/ICCCSN.2012.6215751,Building crawler engine on cloud computing infrastructure,14 June 2012,0
"PaaS (Platform as a Service)model allows the users for developing and deploying the applications over the cloud environment by taking rent of a platform usage.
",https://doi.org/10.1109/I2CT.2018.8529806,Approaches for Detection of Digital Evidence in Cloud Computing Environment,11 November 2018,0
"Multi-tenancy is the characteristic of cloud environment that can create a serious data risk as the same resources are used among the different users. In order to achieve a secure and reliable multi-tenant model, Isolation amongst the resources are necessary also by the use of segmentation and restricting the user access areas will help to solve the data risk problem.",https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"It is a great way to store energy. They are used in the place of cloud storage as it requires less cooling as compared to other cloud storage drives. [4] Therefore, developers should use energy well planned memory such as solid state storage.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
MapReduce was introduced in 2004 by Dean et al. It is a s/w model for processing and generating large data-sets that is amenable to a large variety of real-world tasks. Clint gives input in form of map and a reduce function and the underlying runtime system automatically parallelizes the computation [16].,https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"Recent integration between mobile computing, edge computing and cloud computing have fostered the development of complex mobile edge cloud applications. While most existing works still focus on edge offloading applications [1], [2], many researchers have also started to address complex interactions between the edge and cloud in an integrated manner [3], [4]. From the development perspective, not only we have to examine suitable deployment models for software components and their dependent third party services in edge and cloud infrastructures but also to carry out several tasks of performance evaluation and testing to detect possible issues and to optimize the design and the deployment.",10.1109/CLOUD.2018.00091,Analytics of Performance and Data Quality for Mobile Edge Cloud Applications,11 September 2018,0
"The use of mobile devices is growing drastically. In 2014, 138 billion mobile applications were downloaded, and the number will continue to grow rapidly. Mobile technology's huge potential brings great opportunities for traditional service computing in the mobile environment. With increased processing power and device capabilities, mobile devices will extend their usage possibilities in various application domains.",10.1109/MCC.2016.92,Toward Mobile Service Computing: Opportunities and Challenges,19 September 2016,0
"Contemporary disaster relief and evacuation strategies still need loads of enhancement and optimization. For example, in August 2005, Hurricane Katrina affected large parts of Louisiana, Mississippi, and Florida. With a death count of more than 1,800 and estimated damages of$108 billion, Katrina proved to be the costliest natural disaster in US history. However, officials lacked a definitive plan of action following the event. Local rescue teams, overwhelmed by the destruction, weren't in a position to evaluate and analyze the storm's effects and severity. Even after a partial damage assessment, constant communication failures led to ongoing pandemonium. Worst was that many of the already insufficient number of deployed military troops remained unutilized because they weren't briefed and exercised in a timely manner.",10.1109/MCC.2014.72,Evacuation and Emergency Management Using a Federated Cloud,30 November 2014,0
"There are, however, a number of challenges associated with PHRs. For example, can we rely on the data collected by the patients themselves? Should the relevant healthcare providers certified data collected by the patients, and if so, how can this be done? Who should be legally liable for a misdiagnosis or delayed diagnosis, due to decisions being made on the data sent from the patient's device that is subsequently determined to be flawed or inaccurate (e.g. due to a malfunction sensor)?",10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"It can easily figure out that Abicloud is built based on Java, which set it irrelevant to the platform and easy to transplant. Actually, Abicloud can support many different virtual machine platforms which include vBox, VMWare, Xen, KVM and so on which make it very flexible.",https://doi.org/10.1109/ISISE.2009.94,Comparison of Several Cloud Computing Platforms,15 April 2010,0
"From an IoT application designer's perspective, IoTDAP are challenging to understand during the early stages of development, due to the dependencies between devices, EDC, and CDC. From an operator's perspective, deploying and testing a system in a real environment is a costly and time-consuming task, which therefore should be carried out parsimoniously, after gaining some confidence that the platform will provide appropriate performance. These challenges raise stringent requirements for developing new holistic simulation and modelling frameworks for aiding design, development, and testing of performance, safety, security, reliability, energy-efficiency, and fault tolerance related to IoTDAP. Compared to traditional modelling and simulation frameworks, we envision that simulation of large-scale IoT-DAP will require answering complex questions concerning, for example, the state of the environment surrounding the sensors and feedback-loop control of a large population of sensors. Moreover, IoTDAP simulation environments should be able to capture the interdependence between sensing, control, actuation, and computational logic in CDC and at the EDC. We identify some key challenges that need to be further investigated within the realm of IoTDAP modelling and simulation research, namely:",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
An organisation normally considers the degree of difficulty involved in using new technology as an important element in their decision before adopting this technology. This factor is also an element of the DOI model [12].,https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"Cloud computing's emergence has added new issues and perspectives to current Internet technologies because many system facets will need to be revised in a new context. 2 For instance, we should invest in new service-level agreements between cloud service consumers and providers. In terms of content delivery, integrating cloud computing in this process has changed the architecture, design, and implementation of existing content-delivery networks. Using a network of edge locations around the world, cloud providers provide mechanisms that distribute not only content but also services to end users with low latency and high data-transfer speeds. Also, we should introduce new standards to improve cloud interoperability. The problem is that, although a wide range of vendors provide cloud services, clients remain stuck. Considering that a plethora of cloud providers are flooding the market, this is a real obstacle on the road to the future Internet of services' cloud marketplace due to vendor lockin. Currently, a trend in improving cloud interoperability exists. The recently formed Cloud Computing Interoperability Forum moves in this direction, enabling cloud infrastructures to evolve into a transparent platform. Regarding security and privacy issues, the move to cloud services results in developing new data-protection mechanisms to secure data privacy, resource security, and content copyrights.",10.1109/ICCASM.2010.5623257,The comparison between cloud computing and grid computing,4 November 2010,0
"As more aspects of our work and life move online and the Web expands beyond a communication medium to become a platform for business and society, a new paradigm of large-scale distributed computing has emerged in our lives. Cloud computing has very quickly become one of the hottest topics – if not the hottest one – for practicing engineers and academics in domains related to engineering, science, and art for building large-scale networks and Internet applications. Nowadays, everyone's talking about clouds. In academia, numerous research papers, tutorials, workshops, and panels on this emerging topic have been presented at major conferences and published in the top-level computer science journals and magazines. Also, several universities have added courses that are dedicated to cloud computing principles. A plethora of blogs, forums, and discussion groups on the subject are available on the Web. In industry, companies are devoting great resources to investing in cloud computing, either by building their own infrastructures or developing innovative cloud services.",10.1109/MIC.2010.113,Cloud Computing: The New Frontier of Internet Computing,2 September 2010,0
"Certainly, cloud computing offers many attractive benefits to enterprises. The cloud model moves IT infrastructure from an upfront capital expense to an operational one. Companies can use the cloud for large batch-oriented tasks – those involving large spikes in requirements for processing power – that otherwise would be out of reach or require huge investment. Many enterprises provision computing resources for peak loads, which often exceed average use by a factor of 2 to 10. Consequently, server utilization in datacenters is often as low as 5 to 20 percent. One key benefit of cloud computing is that it spares companies from having to pay for these underutilized resources. Cloud computing shifts the IT burden and associated risks to the vendor, who can spread variations over many customers. Organizations can use the cloud to rapidly scale up or down; they can also buy or release IT resources as needed on a pay-as-you-go model. As one group of researchers from the University of California, Berkeley noted, “This elasticity of resources, without paying a premium for large scale, is unprecedented in the history of IT”",10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"All at once, in a great inventive surge came the light bulb, the refrigerator, electric street cars, barbed wire, the typewriter, the elevator, skyscrapers, the horseless car-riage-all in about thirty-five years, plus one other extremely important contribution that would change our whole way of talking to each other-the telephone. [1]",10.1109/MCC.2015.27,"Invention, Innovation, and New APIs",2 June 2015,0
"IT Vendors offers storage, computation, application hosting services with backed performance and charge on pay-per-use techniques via cloud service providers (CSP).",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"The confidentiality and integrity comprise due to repudiation. In this, the attacker alters the data and information by using the identity of other users. The attacker not only manipulates but also denies that the particular action takes place.",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"In this paper, by considering the aforementioned limitations of current solutions for resource-limited smart devices, we propose a lightweight cryptographic scheme so that IoT smart devices can share data with others at the edge of cloud-assisted IoT wherein all security-oriented operations are offloaded to nearby edge servers. Furthermore, although initially we focus on data-sharing security, we also propose a data-searching scheme to search desired data/shared data by authorized users on storage where all data are in encrypted form. Finally, security and performance analysis shows that our proposed scheme is efficient and reduces the computation and communication overhead of all entities that are used in our scheme.",10.1109/MCC.2017.9,Secure Data Sharing and Searching at the Edge of Cloud-Assisted Internet of Things,15 March 2017,0
"Hypervisor-based resource virtualization (such as that used by Citrix and VMware) is a key concept in cloud computing. Hypervisor-based virtualization enables cloud providers to create unique virtual machines (VMs) that share a set of physical hardware resources (CPU, memory, network, and disk). Each VM executes distinct operating system instances (ranging from proprietary to open source), which supports fault-tolerant and isolated security context behavior.",10.1109/MCC.2016.112,Open Issues in Scheduling Microservices in the Cloud,11 November 2016,0
Automation and self-management of cloud computing infrastructure aim techniques for less operational costs and more profit to CSP. Development of elastic software services improves the degree of cloud elasticity in turn cloud energy efficiency.,https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"A horizontal representation of IoT driver technologies illustrates the connectivity and common operational platforms (Figure 1).1, 3 The functionalities of the layers presented in Figure 1 are defined with respect to the Open Systems Interconnection (OSI) model layers. The edge network layer, which corresponds to the OSI model's physical layer, is the data perception layer, which is responsible for sensing the physical environment, collecting real-time data, and reconstructing a general perception of the data. These technologies and devices typically have short-range communication, constrained batteries, and low storage and computational power. The access network layer represents the data link layer and has heterogeneous communication technologies that enable the first stage of data transmission in terms of communication path handling and data publishing. This layer's major services include message routing, publishing, and subscribing.",10.1109/MCC.2016.28,The Quest for Privacy in the Internet of Things,25 May 2016,0
"The first popular attack occurred around Christmas 2014 on Sony and Microsoft gaming servers using cloud-based services related to PlayStation and Xbox, respectively. Similarly, there was an attack on cloud service provider Rackspace that was a DNS DDoS attack and lasted more than 11 h. Another attack in the third quarter of 2014 involved a combination of hacking and DDoS attack on Amazon EC2 cloud services.4 A more recent attack transpired in late 2015 on cloud-hosting provider Linode and lasted for more than a week. These attacks made the entire cyber security research community consider the scale and strength of these attacks. This introspection and reevaluation of the mitigation methods substantiates the attackers' target shift toward cloud services.",10.1109/MCC.2017.14,"Combating DDoS Attacks in the Cloud: Requirements, Trends, and Future Directions",15 March 2017,0
"In a cloud forensic investigation, it is necessary to analyze the data flow, commonly at three main stages, data-at-rest on the client device(s), data-intransit, and data-at-rest on the server(s). Therefore, it is important to conduct static analysis and dynamic (binary code) analysis of apps installed on the client device, analysis of data communication and exfiltration channels and techniques, and investigation and validation of techniques to locate and recover public and private keys, authentication tokens, encrypted blocks, and other data of interest in the network traffic and on the client device and server (e.g. memory dumps).",10.1109/MCC.2017.39,Evidence and Forensics in the Cloud: Challenges and Future Research Directions,29 June 2017,0
"The attacker can execute a malicious code by intercepting the execution of the program code by the operating system. Such an interception can be performed, for example, by replacing the dynamic library with harmful with its subsequent loading or modifying environmental variables read by the operating system during the launch of software, such as «LD_PRELOAD».",https://doi.org/10.1109/SCM58628.2023.10159053,Model of a Self-Healing Computing Process of a Cloud Computing System under Conditions of Information and Technical Impacts,26 June 2023,0
"The definition of a transparent and trustworthy cloud is fundamental to widen its adoption in critical scenarios managing sensitive data and applications. Recently, security solutions have been considered as the key enablers towards increasing trust in the cloud. However, their roles fall far short of expectation due to the fact that involvement of customers and service providers in security management is reduced by lack of trustworthy evidence on their behavior. It has then become a mantra to consider the cloud as an “environment where magic happens”, while at the same time an “untrusted environment”.",10.1109/MCC.2017.51,Towards Transparent and Trustworthy Cloud,29 June 2017,0
"Free cooling should be used in order to minimize the energy emissions in the form of heat. So, we need to lower the CPU power consumption, so that it emits very less amount of heat.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"Distributed cloud computing is an emerging approach that facilitates the integration of data and applications sourced from multiple locations. The capacity to perform several tasks concurrently is a fundamental attribute of cloud computing, which also endeavors to diminish CPU utilization, minimize switching durations, decrease data processing delays, amplify server throughput, and augment the speed of data processing and transmission. One further characteristic facilitates the seamless utilization of cloud-based applications for user communication across diverse geographical locations.",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"In order to evaluate performance, we compared the times of executing a cloud job on our ad hoc cloud and Amazon EC2 [1]) instance with similar resources. We showed that our ad hoc cloud can offer similar performance for a variety of workloads, even in the event of one or multiple ad hoc guest failures, when taking into account the various overheads of both models.",https://doi.org/10.1109/CLOUD.2015.153,Ad Hoc Cloud Computing,20 August 2015,0
"While federating clouds can provide increased storage and computing capabilities; one recent trend is fog computing4 In fog computing, a set of devices is placed in between the sensing devices and the cloud5 As illustrated in Figure 2, the edge of the IoT and cloud computing is interleaved by an intermediary level, with devices that aggregate data acquired and sent to the cloud. It has been suggested that architectures based on fog computing can improve the performance of IoT deployment (e.g. in terms of reduced response time, and reduced energy consumption).6",10.1109/MCC.2017.30,Challenges of Connecting Edge and Cloud Computing: A Security and Forensic Perspective,26 April 2017,0
"The Interdependencies between elasticity types, virtualization, and energy efficiency techniques in cloud computing is depicted in Fig.-1. Reducing the number of active servers by migrating Virtual Machines is known as server consolidation, a horizontal elasticity.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"We propose a scheme based on attribute-based encryption (ABE) to deduplicate encrypted data stored in the cloud and support secure data access control at the same time. Analysis and implementation demonstrate that our scheme is secure, effective, and efficient.",10.1109/MCC.2016.29,Encrypted Data Management with Deduplication in Cloud Computing,25 May 2016,0
"Given the distribution and diversity of storage as well as increasingly huge data sizes, we need standardized, secure, and efficient methods to access data, move it to other systems for analysis, synchronize changing datasets across systems without copying the entire dataset, and share data with collaborators and others for extension and verification. Although high-performance methods are clearly required as data sizes grow, secure methods are equally important, given that these datasets might include medical, personal, financial, government, and intellectual property data. Thus, we need models that provide a standard interface through which users can perform these actions and methods that leverage proven security models to provide a common interface and single-sign-on. These approaches must also be easy to use, scalable, efficient, and independent of storage type.",10.1109/MCC.2014.52,"Efficient and Secure Transfer, Synchronization, and Sharing of Big Data",30 September 2014,0
"The main design challenge of City Eyes is to provide a general framework to handle the diverse needs in smart video surveillance applications. To this end, the proposed PaaS has been designed to include the following main functionalities to meet some basic requirements, such as the simplicity of integrating various video analysis engines and supporting configurable workflow to accomplish different tasks.",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
"Recent studies by Cisco and IBM show that we generate 2.5 quintillion bytes of data per day, and this is set to explode to 40 yottabytes by 2020-that's 5,200 gigabytes for every person on earth.[1], [2] Much of this data is and will be generated from Internet of Things (IoT) devices and sensors. IoT comprises billions of Internet-connected devices (ICDs) or “things,” each of which can sense, communicate, compute, and potentially actuate, and can have intelligence, multimodal interfaces, physical/virtual identities, and attributes. ICDs can be sensors, RFIDs, social media, clickstreams, business transactions, actuators (such as machines/equipment fitted with sensors and deployed for mining, oil exploration, or manufacturing operations), lab instruments (such as a high energy physics synchrotron), and smart consumer appliances (TV, phone, and so on).",10.1109/MCC.2015.14,Processing Distributed Internet of Things Data in Clouds,22 April 2015,0
"A couple of things are behind the shift to SDN. First, as enterprises relocate their workloads, including data and applications, to public clouds, the center of the workload universe is shifting, and the network must follow. Second, as net-new applications appear on public clouds, networks need to be on clouds as well.",10.1109/MCC.2016.62,Software-Defined Networks Meet Cloud Computing,4 July 2016,0
"Not all agree that a hypervisor or container is required to call a given system a cloud; several specialized service providers offer what is generally called a bare metal cloud, where they apply the referenced elasticity and automation to the rapid provisioning and assignment of physical servers, eliminating the overhead of a hypervisor or container altogether. Although interesting for the most demanding applications, the somewhat oxymoron term “bare metal cloud” is something perhaps Tidbits will look at in more detail in a later column.",10.1109/MCC.2014.51,Containers and Cloud: From LXC to Docker to Kubernetes,30 September 2014,0
"Cloud computing brings natural economies of scale4 like structural cost advantages, scale of operation, learning curve effects, and enhanced productivity. Moreover, many customers sharing (that is, being statistically multiplexed into a common pool of resources) the same infrastructure means higher utilization and smoothing of the inevitable peaks and troughs in workloads. This results in a reduction in the coefficient of variation for independent, uncorrelated workloads,5 allowing cloud providers to optimize the hardware needs of their data centers.",10.1109/MCC.2017.42,The Limits to Cloud Price Reduction,29 June 2017,0
"Microservices is an architecture as well as a mechanism, and is often confused with traditional SOA-type services. Indeed, there's a great deal of overlap. It's an architectural pattern in which complex applications are composed of small, independent processes that communicate with each other using language-agnostic APIs.",10.1109/MCC.2016.114,Practical Use of Microservices in Moving Workloads to the Cloud,11 November 2016,0
"In Account Hijacking a malicious intruder can use the stolen credentials to hijack cloud computing services and they can enter on other's transactions, insert false information, and divert users to abusive web sites which resulted in legal issues for cloud service providers.",https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"However, the integration of IoT with cloud services introduces some significant challenges—security and privacy being the foremost. Within the IoT paradigm, everything, including final dependability, relies on the integrity of the data, which drives the decision-making processes that enable smart functionality. The data should be secure and private as it's generated, communicated, stored, and analyzed within the complete integrated environment of public cloud facilities and IoT application domains. Most of the key IoT applications, which range from personal-level systems like e-health and assisted living to industrial-level systems like smart grid and machine/process monitoring, require the generated data to be both private and secure",10.1109/MCC.2016.30,Secure Data Analytics for Cloud-Integrated Internet of Things Applications,25 May 2016,0
"Apply some strategies to the code. By reducing the space and time complexity of the code, the energy can be best consumed and will not be wasted. Efficient algorithms should be made by the developers for creating a quality code.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"As CBS only activates (new) resources when neither private cloud resources nor public cloud resources can complete jobs within their deadlines. For this reason, the average resource utilization is significantly improved with CBS (89%) compared with the private (medium) cloud only solution.",https://doi.org/10.1109/CLOUD.2017.112,Cloud Bursting Scheduler for Cost Efficiency,11 September 2017,0
Cloud computing is a way to get direct cost savings from a capital-intensive method in an unpredictably changing environment. Individuals and corporations can use cloud services to develop software and hardware and distribute it to other parties in remote locations,https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"This evolution is mainly required for the adaptation of the cloud paradigm to the IoT phenomenon. The increasing need for supporting interaction between IoT and cloud computing systems has also led to the creation of the edge computing model, which aims to provide processing and storage capacity as an extension of available IoT devices, without needing to move data/processing to a central cloud data-center (such as Amazon Web Services). This reduces communication delays and the overall size of the data that needs to be migrated across the Internet and public and private datacenters.",10.1109/MCC.2016.124,Osmotic Computing: A New Paradigm for Edge/Cloud Integration,30 December 2016,0
"A possible solution to augment the scalability of CDCs lies in taking advantage of the ever-increasing computational and storage capabilities available at the network edge.2, 3, 4 We note in the previous instalment of “Blue Skies” sensing and networking devices available at the network edge constitute a new type of computing infrastructure, the Edge Datacentre (EDC).5 An EDC may vary in scope and capability, including gateways (Raspberry Pi 3, UDOO board, esp8266, Meshlium Xtreme, Arduino), software defined network solutions (e.g. Cisco IOx), or smart phones equipped with sensors. To facilitate highly distributed and federated computing environments, we proposed Osmotic Computing paradigm5 that enables the automatic deployment of microservices over inter-connected EDC and CDC. The benefits of integrating EDC and CDC has already been recognised by several companies and open source initiatives, including CISCO, AWS1, and Google3, and the OpenFog Consortium.4 For example, AWS has enriched its CDC offerings with near-edge computing and storage capabilities (i.e., Snowball Edge, Greengrass).",10.1109/MCC.2017.22,Osmotic Flow: Osmotic Computing + IoT Workflow,26 April 2017,0
"Complexity problems often arise in legacy, monolithic systems, such as large enterprise resource planning or core banking systems, making them inflexible and expensive to maintain. In many cases, such systems are linked together so even an apparently trivial change in a single component can create errors in that component or others. This therefore requires regression testing of all components and the system as a whole. We see the same complexity and reliability requirements in new software and digital products. When many changes, ranging from bug fixes to feature enhancements, occur in a monolithic application, it might never become stable and reliable.",10.1109/MCC.2016.109,The Economics of Microservices,11 November 2016,0
"Workload placement overall shows that 68 percent of enterprises currently run less than a fifth of their application portfolios in the cloud, while at the same time, 55 percent report that a significant portion of their application portfolios are being built with cloud-friendly architectures.",10.1109/MCC.2016.21,The Hybrid Cloud Security Professional,26 February 2016,0
XCP is an open source enterprise server virtualization and Cloud Computing platform. It was originally derived from Citrix XenServer and it is licensed under the GNU General Public License (GPL2).,https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"Decently, we've seen a wide adoption and deployment of Internet of Things (IoT) I’) infrastructures and systems for various crucial applications, [1] such as logistics, smart cities[2] and healthcare. This has led to high demands on data storage, processing, and management services in cloud-based datacenters, engendering strong integration needs between IoT and cloud services. Cloud services are mature and provide excellent elastic computation and data management capabilities for IoT. In addition, as IoT systems become complex, cloud management techniques are increasingly employed to manage IoT components. Thus, cloud services now act as computational and data processing platforms as well as management platforms for IoT. From a high-level view, IoT appears to be well-integrated with cloud datacenters to establish a uniform infrastructure for IoT cloud applications. However, the software layers on top of such integrated infrastructures are still fragmented, and therefore far from a uniform software layer to support a coherent execution environment for complex applications.",10.1109/MCC.2015.23,Principles for Engineering IoT Cloud Systems,2 June 2015,0
"These databases started to develop in 1980s [17]. Parallel DBMS support standard relational tables and SQL and also implements many of the performance enhancing techniques including indexing, compression, materialized views, result caching and I/O sharing and so on.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"We can broadly categorize healthcare as primary or secondary. Secondary healthcare providers, such as hospitals and other medical institutions, provide additional health services to complement those offered by general practitioners. Secondary healthcare can also be provided by pathologists working at laboratories and performing specific tests on patients. Both public and privately run healthcare providers generally have an administration and several other departments.",10.1109/MCC.2016.139,Healthcare-Related Data in the Cloud: Challenges and Opportunities,30 December 2016,0
"Poorly implemented EHR-based systems pose significant risk for patient safety and data misuse.2 The main security concerns in big data systems include secure storage, secure access, and secure retrieval.3 In addition to strong access control mechanisms, location of data access is an important aspect of secure data usage. Recently reported incidents of illegal trade and stealing of patient data over mobile devices remotely2 motivate research on secure data usage based on location. Healthcare service facilities increasingly use mobile devices to improve workflow dynamics and efficiency. However, this mobility and the use of multiple mobile devices increase the gravity of security concerns and demands robust privacy-preserving measures.",10.1109/MCC.2016.76,Hybrid Cryptographic Access Control for Cloud-Based EHR Systems,19 September 2016,0
"The continued amalgamation of cloud technology into all aspects of our daily lives creates business opportunities, operational risks, and investigative challenges. But as businesses continue to offer customers and employees increased access, improved software functionality, and new supply chain management opportunities, the risk of cyber-physical attacks on cyber-physical cloud systems (CPCSs) grows. Increasing digital interconnectivity between devices at the physical (such as sensors and actuators) and cyber (such as intelligent decision systems) levels has transformed cyber-physical systems (such as the electric power grid) into large ecosystems requiring a scalable and flexible infrastructure.",10.1109/MCC.2016.5,Forensic-by-Design Framework for Cyber-Physical Cloud Systems,26 February 2016,0
"Big data has emerged in domains such as science, engineering, and comO merce. Facebook, for example, currently stores more than 20 petabytes of photos, and this number grows by 60 terabytes each week.1 In the big data era, clouds become a perfect candidate for data storage by providing virtually unlimited storage that can be accessed over the Internet. By outsourcing large volumes of data to cloud storage, such as Google Drive, Dropbox, and Amazon Simple Storage Service, users can simplify their data management and reduce data maintenance costs through the pay-as-you-use model.",10.1109/MCC.2016.107,Privacy-Preserving Access to Big Data in the Cloud,11 November 2016,0
"The cloud has fundamentally changed the landscape of computing, storage, and communication infrastructures and services. With strong interest and investment from industry and government, the cloud is being increasingly patronized by both organizations and individuals. From the cloud provider's perspective, cloud computing's main benefits include resource consolidation, uniform management, and cost-effective operation; for the cloud user, benefits include on-demand capacity, low cost of ownership, and flexible pricing. However, the features that bring such benefits, such as sharing and consolidation, also introduce potential security and privacy problems. Security and privacy issues resulting from the illegal and unethical use of information, and causing disclosure of confidential information, can significantly hinder user acceptance of cloud-based services. Recent surveys support this observation, indicating that security and privacy concerns prevent many customers from adopting cloud computing services and platforms.",10.1109/MCC.2014.20,Security and Privacy in Cloud Computing,10 July 2014,0
"The trouble with existing approaches to cloud computing, including leveraging infrastructure as a service (IAAS) and platform as a service (PAAS), is that they tend to come with platform lock-in. Once you've ported an application to a cloud-based platform, including Google, Amazon Web Services (AWS), IBM, and Microsoft, it's tough, risky, and expensive to move that application from one cloud to another.",10.1109/MCC.2016.122,Moving to Autonomous and Self-Migrating Containers for Cloud Applications,30 December 2016,0
"Although service computing and mobile computing have been studied for many years, their combination-that is, mobile service computing—hasn't been widely researched. Thanks to the development and utilization of mobile computing technologies, services are no longer limited to traditional contexts and platforms. They can be deployed on mobile devices or cloud servers and delivered over wireless networks. Mobile devices can play the roles of consumer, broker, and provider simultaneously. Mobile services delivered through mobile techniques are now emerging as a promising technology to extend traditional service computing.",10.1109/MCC.2016.92,Toward Mobile Service Computing: Opportunities and Challenges,19 September 2016,0
"Despite such challenges and potentially thorny legal issues, having a HIS based on an ecosystem of solutions that is able to seamlessly exchange data among themselves and provide the abstraction of a single health data storage for any given patient (e.g. physically distributed among multiple concrete software instances at multiple healthcare providers and mobile apps) will benefit all users, ranging from patients to healthcare providers to governments.",10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"The increasing popularity of microservices, despite the effort required to implement them, is probably due to the benefits associated with their agility, resilience, scalability, and maintainability.4 Specifically, we could enforce separation of concerns by applying the single responsibility principle.",10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
"Existing public verification schemes assume the auditor is honest and can't be corrupted. But this is a strong assumption, since auditors can be corrupted in practice. A malicious auditor can always claim that the outsourced data is (not) retained well in the cloud, regardless of the verification result, so even the malicious auditor wouldn't perform the verification. In addition, the vulnerability of existing schemes is further exacerbated by the fact that the malicious auditor colludes with the cloud server and generates a biased challenging message to check the data blocks that aren't corrupted, and thus deceiving the user. Constructing an efficient public verification of data integrity for cloud storage against malicious auditors is of paramount importance.",10.1109/MCC.2016.94,Cryptographic Public Verification of Data Integrity for Cloud Storage Systems,11 November 2016,0
Cloud data centres with providers on physical level and customers on virtual level both monitor their hard-and software infrastructure to understand load patterns and to detect malfunctions and bottlenecks.,https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
IT applications and physical businesses often face similar challenges. Customers have to be served quickly; throughput and availability should increase. Concepts such as redundancy and parallelism are inherent in the architectural design of both worlds.,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
Dynamic Voltage or Frequency Scaling (DVFS) is to scale the microprocessor voltage and frequency at run time as per the cloud service resource requirements deployed on a physical machine.,https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
A primary challenge of the cyberinfrastructure research community is the need to define the Platforms for Science beyond 2020. We analyze major current trends and propose that in order to deliver the Platform for Science in 2020 the dominant research challenge is to manage the convergence of capabilities of traditional HPC systems with richness of Apache Big Data systems.,https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"For cloud customers, transparency in resource consumption is an important part of trust between customers and service providers. The customer pays for virtual resources, which are expected to be guaranteed whenever the deployed application requires it. On the other hand, the service provider deals with unutilised virtual resources from customers, who usually buy more resources than they use in average.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Large scientific datasets are increasingly hosted on both public and private clouds. For example, public datasets hosted by Amazon Web Services (AWS) include 20 Tbytes of NASA Earth science data, 500 Tbytes of Web-crawled data, and 200 Tbytes of genomic data from the 1000 Genomes project. Open clouds such as the Open Science Data Cloud (OSDC)[3] host many of the same research datasets in their collection of more than 1 Pbyte of open data. Thus, it's frequently convenient, efficient, and cost-effective to work with these datasets on the cloud. In addition to these high-profile public datasets, many researchers store and work with large datasets distributed across a plethora of cloud and local storage systems. For example, researchers might use datasets stored in object stores such as Amazon Simple Storage Service (S3), large mountable block stores such as Amazon Elastic Block Store (EBS), instance storage attached to running cloud virtual machine (VM) instances, and other data stored on their institutional clusters, personal computers, and in super-computing centers.",10.1109/MCC.2014.52,"Efficient and Secure Transfer, Synchronization, and Sharing of Big Data",30 September 2014,0
"IT organizations started constructing cloud computing integrated with Big Data [10]. The problem still persists with big data environments, which need networking servers to support their large volumes, high velocity and numerous Big data formats. Nowadays, clouds are designed with large networking servers, increased storage capacity and reduced infrastructure enabling modifications as needed by customers. As a results, it was proved that cloud computing is a big solution to integrated big data technologies with advanced analytic tools, which enhances business significance",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"Cloudlet, like a “data center in a box”, can be selfmanaging and require less time, energy and access control. Moreover, Internet connectivity is not necessary. The application model of cloudlet is similar with remote cloud, except that cloudlet supports real-time application better and provides fewer resources than remote cloud.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"The concept of Mobile Sensor Cloud Computing (MSCC) is to extend Sensor cloud-computing ecosystem to the world of future sensor enabled mobile applications and Internet clouds. Also it introduces new technologies, hardware, software, communication protocols, etc., which together forms ecosystem of mobile cloud.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"In cloud computing, data confidentiality and user authentication are correlated. Protecting a user's account from misuse is an important part of the larger problem of controlling access to cloud-based resources (such as objects, memory, devices, and software). Cryptographic authentication solutions can help facilitate secure resource utilization. However, depending on the cloud deployment model, key management (assignment, distribution, and revocation) must be efficient and manageable at a large scale.",10.1109/MCC.2015.45,"Security and Privacy in Cloud Computing: Vision, Trends, and Challenges",2 June 2015,0
Apache Software Foundation develops a java based open source s/w platform called Hadoop. Hadoop implements Google's MapReduce programming model on top of a distributed file system called the Hadoop Distributed File System (HDFS)[22].,https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
Sensor Configuration Each sensor support package will implement an interface to view and change the individual sensor's configuration. This interface will handle all communication with the sensor and will provide an interface specific to the individual sensor.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Smart world environment that is richly and invisibly interwoven with sensors, actuators, displays, and computational elements, embedded seamlessly in the everyday objects of our lives, and connected through a continuous network. Wireless Sensor Networks (WSN) solutions, a growing green movement, demand for public safety solutions.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"In some cases, due to small onboard storage vehicles may need additional storage to run the applications while moving on the road. Hence, the vehicles that have large on-board storage capability can provide storage pool to other vehicles so that other vehicles use their storage space to run their application or services. It refers to Storage as a Service (STaaS)",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"A severe earthquake disaster occurred in a certain area, leading to communication and traffic disruption. Since the terrain, roads, and buildings in the area are seriously damaged, the mismatch between the actual scene of the disaster area and its original environment information affects the progress of rescue. There is a pressing need to reconstruct relevant information to assist the rescue work. Rescuers build cloudlet infrastructure in the field, then local residents take photos with their smartphones, cameras and other mobile devices and deliver those photos to the cloudlet center through the temporary wireless link.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"Two important current major trends in computing systems are: (i) A growth in high performance computing (HPC) with an international exascale initiative, and (ii) Software systems to support data-intensive applications with an accompanying cloud infrastructure of well publicized dramatic and increasing size and sophistication.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
Do ‘n’ number of tasks in very less time. It will help in time saving and energy consumption. Multitasking is one of the important phenomena to save time and energy.,https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"Genetic algorithm (GA) is a bio-inspired method, which produces new solutions using best among the pool of solutions and discarding the worst. GA is a tool for multi-objective optimization. Xu et al. developed a genetic algorithm with objectives of minimizing power consumption, heat and resource wastage",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"For highly sensitive data, honeypot system can be implemented in order to trap the attackers activity. A honeypot is a deception trap, designed to entice an attacker into attempting to compromise the information systems in an organization. If deployed correctly, a honeypot can serve as an early-warning and advanced security surveillance tool, minimizing the risks from attacks on IT systems and networks.",https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"Here, we offer a holistic overview of privacy issues and challenges related to IoT technologies and applications. Compared with previous literature, we provide a broader synopsis of current research on various aspects of IoT privacy and PbD solutions from the viewpoints of academics, industries, and the general public. In addition to describing existing solutions and promising emerging approaches, we discuss open research issues and design guidelines for preserving privacy in the IoT.",10.1109/MCC.2016.28,The Quest for Privacy in the Internet of Things,25 May 2016,0
Sensor Support Packages Individual sensor support packages provide the features necessary to interface with a specific sensor or set of sensors.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"WSN offer a powerful combination of distributed sensing, computing and communication. WSN have very high resource constraints in terms of memory, processing, and transmission power. They lend themselves to countless applications and, at the same time, offer numerous challenges due to their peculiarities.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"For example, if we measure an API by transactions per minute and expect an average of 60K hits per minute, we might be lulled into thinking that this averages to a maximum concurrent throughput of 1000 TPS.",https://doi.org/10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
Relative advantage is an element of the DOI model [12]. This factor refers to the level of benefit to an organisation if they decide to move into cloud computing.,https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"IT experts have a long-established relationship with coffee and related products - you could even call it love. Coffee shops making our favorite products are places to relax and work, but they can also inspire IT architectures.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Multicloud infrastructures also raise several security and dependability challenges. First, infrastructure layers, which include customer virtual machines (VMs), provider hypervisors, and services, are extremely vulnerable to attacks, in part due to new virtualization technologies,5 so the infrastructures can't be trusted. Second, interoperability and unified control of security across providers is mostly absent. Policy heterogeneity among providers facilitates the introduction of more vulnerabilities because of mismatching APIs and workflows. Finally, security administration challenges for such complex infrastructures clearly prohibit a manual approach. Automation of security management is required, but still lacking, in the multicloud.",10.1109/MCC.2016.110,User-Centric Security and Dependability in the Clouds-of-Clouds,11 November 2016,0
"Cloud applications have typically leveraged virtualization. However, several factors—including acceleration of the development cycle (such as agile methods and DevOps), an increasingly complex application stack (mostly Web services and their frameworks), and market pressure to densify applications on servers—have triggered the need for a fast, easy-to-use way of pushing code into production.",10.1109/MCC.2016.100,To Docker or Not to Docker: A Security Perspective,11 November 2016,0
"In cloud computing, data confidentiality and user authentication are correlated. Protecting a user's account from misuse is an important part of the larger problem of controlling access to cloud-based resources (such as objects, memory, devices, and software). Cryptographic authentication solutions can help facilitate secure resource utilization. However, depending on the cloud deployment model, key management (assignment, distribution, and revocation) must be efficient and manageable at a large scale.",10.1109/MCC.2015.45,"Security and Privacy in Cloud Computing: Vision, Trends, and Challenges",2 June 2015,0
"To implement the service, we use the RESTFul architecture deployed on the open source OpenStack cloud system. Our system's advantages include services' reusability, improved fault tolerance, easy distribution of newer versions, and decoupling of services (and thus easy management). Our expectation is that decoupling the system components from the application logic will offer more flexibility; for example, integrating a new system will not require changes to the service's internal procedures.",10.1109/MCC.2016.128,Internet of Things Architecture for Enhanced Living Environments,30 December 2016,0
"The cloud environment still fails to build trust worthy belief for a cloud clients or forensic investigator. Now, listing of major contributions made by some researchers in the field of digital data forensic at the cloud computing environment.",https://doi.org/10.1109/I2CT.2018.8529806,Approaches for Detection of Digital Evidence in Cloud Computing Environment,11 November 2018,0
"Serverless computing is sometimes conflated with “NoOps,” the extreme evolution of the DevOps movement. However, even though serverless options potentially abstract away load balancing, autoscaling, high availability, and the security maintenance of compute infrastructure, it's worth pointing out that all of these underlying operational concerns are simply distractions from operational responsibility. Sure, you don't need to manually spin up and manage compute, but you do need to ensure your services are tunable, testable, secure, performant, resilient, monitored, and KPI-instrumented. You also will need a deployment and versioning strategy that allows serverless tasks to play nicely with other services. The true operational concerns of your application are not generic enough to be a commodity—if they were, your service wouldn't be unique and probably wouldn't exist.",10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"In order to deliver such cloud-based apps within ELEs for eldercare, the challenges that arise include 1) ensuring stable network performance and performance-tuned cloud platforms for large-scale sensor information analysis, 2) interactive interface and intuitive displays suitable for effective interactions between older adults and PTs, and 3) the integration of apps in their social context of use as secure, privacy-preserving, and socially embedded technologies.",10.1109/MCC.2017.46,Toward an ElderCare Living Lab for Sensor-Based Health Assessment and Physical Therapy,29 June 2017,0
"In contrast, all state-of-the-art implementations of data mining algorithms operate by loading the whole training dataset into the main (RAM) memory of a single machine or simple machine clusters that have static processing and storage capacity configurations. This approach has two key problems.3–6 First, the data can simply grow too big over time to fit into the available RAM. Second, most of big data applications produce data spread across multiple distributed data sources (including streaming sources). Moving all the datasets to a centralized machine is thus expensive (due, for example, to network communication and other I/O costs), even if we assume that the machine has a super-large RAM to hold all the data for processing. Further, when the data mining algorithms' computational complexity exceeds the available RAM, the algorithms don't scale well and they never finish or are unable to process the whole training dataset.",10.1109/MCC.2014.22,Streaming Big Data Processing in Datacenter Clouds,10 July 2014,0
"As cloud offerings proliferate, there will be ongoing challenges with interoperability, portability, and migration. To be sure, interoperability is also an issue for on-premise applications, but this challenge is magnified in the cloud. In an on-premise model, enterprises control their infrastructure and platforms at any time. In the cloud, they're locked in to a provider and no longer control their own IT.",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"David Bernstein discusses the importance of container-based application deployment and cluster management for the cloud computing infra-structure.[3] This article reviews the virtualization principles behind containers, particularly in comparison with VMs. Specifically, I investigate the relevance of the new container technology for PaaS clouds, although containers also relate to the IaaS level through their sharing and isolation aspects. Because today's applications are distributed, I also discuss the resulting requirements for application packaging and interoperable orchestration over clusters of containers. I aim to clarify how containers can change the PaaS cloud as a virtualization technique, specifically PaaS as a platform tech-nology. I go beyond Bernstein,[3] addressing what's needed to evolve PaaS significantly further as a distributed cloud software platform, resulting in a discussion of achievements and limitations of the state of the art. To illustrate concepts, I'll discuss some example technologies that exemplify technology trends.",10.1109/MCC.2015.51,Containerization and the PaaS Cloud,15 July 2015,0
"In the light of this historical failure, and for other reasons that I'll cover in this column, we should be modest in our expectations for a single unifying paradigm and a single simple set of standards to cover the concepts mentioned above.",10.1109/MCC.2017.23,Standards at the Edge of the Cloud,26 April 2017,0
"the cloud customer and the cloud service provider have a great interest in monitoring their physical and virtual infrastructures for several different reasons. The cloud service provider obviously needs to detect malfunctions in the physical hard-and software, as well as needs to optimise the overall data centre utilisation by placing the virtual resources ideally on the physical ones.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"We need to promote Green Cloud Computing because it is a critical situation since lots of carbon residues emit out of data centers. So there are various data mining methods that need to be done in order to filter the data as processing lots of data needs time and therefore data centers heat up, so there is a need of cooling of these data centers and it consumes a lot of energy.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
Pricing can be broken into a number of general problem solving ontology concepts. The concepts of general problem ontology are shown in Figure 1. An example task could be ‘find the lowest cost for a set of high level requirements'. Problem Solving Methods (PSM) could be pricing algorithms or heuristic strategies for pricing. Domain models could be ‘databases' for pricing.,https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"While the time frame of the described approach to define the dynamic part of the statistical model is defined by the buffer size, its value defines the granularity with respect to short or long term modelling of the resource utilisation.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
Virtualization allows movement of both live / suspended virtual machines from one to another physical machine without loss of data. This movement can be utilized to the server or physical machine consolidation to reduce the number of physical machines powered on dynamically.,https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"Most agree that the definition implies some kind of technology that provides an isolation and multitenancy layer, and where computing resources are split up and dynamically shared using an operating technique that implements the specified multitenant model. Two technologies are commonly used here: the hypervisor and the container. You might be familiar with how a hypervisor provides for virtual machines (VMs). You might be less familiar with containers, the most common of which rely on Linux kernel containment features, more commonly known as LXC (https://linuxcontainers.org). Both technologies support isolation and multitenancy.",10.1109/MCC.2014.51,Containers and Cloud: From LXC to Docker to Kubernetes,30 September 2014,0
"Although the cloud computing paradigm holds great promise that appeals to performance-hungry scientific computing communities: clouds can be a cheap alternative to supercomputers and specialized clusters, a much more reliable platform than grids, and a much more scalable platform than the largest of commodity clusters, there are nonetheless a range of uncertainties and challenges that concern scientists to widely adopt the innovative service models.",https://doi.org/10.1109/CloudCom.2012.6427610,Key consideration factors of adopting cloud computing for science,4 February 2013,0
"The cloud data may expose private data or improper requested data to additional users apart from sending to the requested users. The increase of inconvenient data handling in cloud is because of bugs, collisions, operator errors, or improper arrangements.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
The Nimbus project is considered as a science Cloud Computing solution providing Infrastructure as a service. Nimbus is attached to the Culumbus project and it supports different virtualization implementations: Xen and KVM.,https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"SDN is the software enablement of infrastructures. It's part of the software-defined datacenter concept that, in essence, detaches the hardware from the software, and replaces complex hardware devices with changeable layers of software. Specifically, SDN decouples the software control panel from a node's forwarding hardware (such as routers and switches), and executes the control software in either a local server or the cloud.",10.1109/MCC.2016.62,Software-Defined Networks Meet Cloud Computing,4 July 2016,0
"However, current industrial deduplication solutions can't handle encrypted data. Existing solutions for deduplication are vulnerable to brute-force attacks' and can't flexibly support data access control and revocation (see the “Related Work in Data Deduplication” sidebar for a discussion of some other work in this area).3 Few existing schemes for cloud data access control support data deduplication simultaneously,4 and few can ensure flexibility and security with sound performance for cloud data deduplication that data owners control directly",10.1109/MCC.2016.29,Encrypted Data Management with Deduplication in Cloud Computing,25 May 2016,0
"Cloud computing is a potential solution, due to the capability to support real-time data sharing regardless of geographical locations, to provide resource elasticity as needed, and to handle big data (e.g. hosting of big data analytical tools) to obtain useful insights from the analysis of big healthcare data for research and policy decision making.12, 13",https://doi.org/10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"VCL aims to develop and promote virtualization concepts and open-source solutions for the benefit of the academia and its stakeholders by creating shared virtual computing resources and supporting related research. VCL has been deployed, from an academic perspective, to provide services to students and academic staff as well.",https://doi.org/10.1109/CCAA.2015.7148478,Virtual computing lab (VCL) open cloud deployment,6 July 2015,0
"A key benefit of connecting edge and cloud computing is the capability to achieve high-throughput under high concurrent accesses, mobility support, real-time processing guarantees, and data persistency. For example, the elastic provisioning and storage capabilities provided by cloud computing allow us to cope with scalability, persistency and reliability requirements and to adapt the infrastructure capacity to the exacting needs based on the amount of generated data.",10.1109/MCC.2017.30,Challenges of Connecting Edge and Cloud Computing: A Security and Forensic Perspective,26 April 2017,0
"It clearly emerges the need of increasing the cloud transparency by providing reliable evidence on the behavior of the cloud and its services. Traditional security verification techniques composed of static analysis approaches are not enough and must be extended to support continuous evidence collection from in-production cloud services at runtime. A proper evidence collection process provides the basis of a trustworthy cloud. On the contrary, the absence of nontransparent evidence hinders users' trust on the real cloud behavior and prevents users from taking full advantage of the cloud functionalities.",10.1109/MCC.2017.51,Towards Transparent and Trustworthy Cloud,29 June 2017,0
"Recovery of distorted computations is possible when a violation of semantic correctness is detected at one of the control points located on the linear section of the control flow graph by applying an inverse transformation of the invariant matrix, generating a recovery plan, and performing point modifications in memory.",https://doi.org/10.1109/SCM58628.2023.10159053,Model of a Self-Healing Computing Process of a Cloud Computing System under Conditions of Information and Technical Impacts,26 June 2023,0
"A number of other security solutions have been proposed for the cloud in the literature, ranging from access control to crypto primitives to intrusion detection to privacy-preserving, and so forth. Despite the existence and deployment of various security solutions, there will be times where digital investigation is needed. As noted in a previous column,2 to successfully prosecute individuals who commit crimes involving digital evidence, one must be able to gather evidence of an incident or crime that has involved cloud servers as well as the client devices that have been used to access the cloud services, a process known as digital forensics (or cloud forensics).",10.1109/MCC.2017.39,Evidence and Forensics in the Cloud: Challenges and Future Research Directions,29 June 2017,0
"Generally, in a datacenter, almost power is consumed by cooling units and computing servers. So converting the setup to be an energy efficient one, there is a possibility of reducing power consumption by minimizing the number of computing servers and cooling units to be powered on at a point of time with respect to the workload on the cloud at that time.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"Microservices act as standalone application subunits or components, implementing specific communication protocols for sending and receiving messages. In microservices, data flows through smart endpoints, which also process incoming information. Using well-defined interfaces and protocols, application developers can deploy different microservices on heterogeneous infrastructures without a specific integration framework. Generally, microservice communication uses a REST approach based on HTTP and TCP protocols, XMPP, or JavaScript Object Notation (JSON). However, currently, there are no widely adopted standardized protocols or data formats for microservice communication.1 Microservices deployment and execution also leads to various networking issues. To this end, application developers currently adopt various software-defined networking (SDN) and network function virtualization (NFV) solutions for networking microservices.",10.1109/MCC.2016.112,Open Issues in Scheduling Microservices in the Cloud,11 November 2016,0
"CDBMS as database-as-a-service makes various geographically distributed databases available and share them with various users and database logically function in such a way like all the databases are available local to the user. Database-as-a-service provider includes SimpleDB from Amazon, and Azure from Microsoft [21],",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"At present, there are few solutions to address the challenges of secure data sharing and searching in clouds. Typically, to ensure confidentiality of shared data, symmetric key,6 public key,7 and homomorphic8 encryption-based mechanism are currently used. Access control policies based on access control list9 and dynamic attribute10 are used for access control purposes. Searchable encryption based on symmetric11 and public12 keys are used for searching the desired data. In all these schemes, for data security, major security-oriented processing such as encryption, decryption, and access control mechanisms are handled by the user's device itself. In IoT, the resource-limited smart devices cannot handle these computation intensive operations because the security-oriented operations will increase the heavy computational burden.",10.1109/MCC.2017.9,Secure Data Sharing and Searching at the Edge of Cloud-Assisted Internet of Things,15 March 2017,0
"As noted in the previous installment of “Blue Skies” and shown in Figure 1, IoT devices can be sensors, mobile phones, radio frequency identification, actuators (such as machines/equipment fitted with sensors and deployed for mining, oil exploration, or manufacturing operations), lab instruments, and smart consumer appliances (TV, phone, and so on).5, 6 Social media, clickstreams, and business transactions are also workloads in IoT.",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
"In order to decrease free time, auto scaling aspect is the most wonderful thing in the field of cloud computing as the usage of the services areas per the requirements and this helps in minimizing power usage and therefore it also reduce costs. Dr Bindu and Mr Joe in their paper used MDE technique to make sure that maximum response time restriction is met. [",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"In particular, the attack duration has enormous impact on the services running on the cloud due to the on-demand utility computing model of the cloud. Financial losses due to DDoS attacks have multiple components or symptoms, few of which are visible during the attack. However, the remaining part of the losses are visible only after the attack disappears. Most of these losses are difficult to measure, including the long-term reputation and ensuing business losses. There are recent and much talked about massive DDoS attacks on cloud services and cloud service providers that have shaped the socalled battlefields of the cyberattacks.",10.1109/MCC.2017.14,"Combating DDoS Attacks in the Cloud: Requirements, Trends, and Future Directions",15 March 2017,0
"We show in this article that, since cloud computing became widely available, in spite of well-publicized price reductions from a variety of providers, Amazon public cloud prices have only fallen at 10.5 percent annually. Google, although it promised to follow Moore's Law principles for cloud pricing, has only dropped 20.8 percent annually in the last 3 years. We explain why Moore's law does not apply to cloud data centers, and how a repeated cutting of prices to follow Moore's law would considerably reduce cloud provider profit margins. Public clouds, despite their economies of scale, are unlikely to be able to drop prices more than 15 percent annually over the long haul without impacting their margins and/or bottom line. Similar structural limits to unit cost reduction apply to private clouds for similar reasons, although there are notable real-world differences, such as SG&A (Sales, General and Administrative expenses, such as funding enterprise sales teams and holding marketing events) allocations for profit-seeking enterprises versus cost centers.",10.1109/MCC.2017.42,The Limits to Cloud Price Reduction,29 June 2017,0
"Another major privacy challenge in cloud computing is the nature of information source. In Big data, data are generated from various sources in various formats leading to data to be secured and managed in caution [10]. At the same time, data should be protected from unauthorized users from changing the originality of it. And also, client's privacy should be sustained, while collecting, managing and communicating data's. These challenges are very crucial to the privacy of cloud and are mentioned as assurance of availability, confidentiality, and integrity.",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"For large companies, the private cloud represents an option to have your cake and eat it, too. When compared to the standard components of the public cloud, the custom-made private cloud stands out as a radically different construct. Unfortunately, many people continue to loosely throw around the term “cloud” without realizing that it may refer to very different models and without realizing its limitations. After a careful analysis of the cloud, many companies might want to keep their CIOs for the foreseeable future.",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"The attacker or unauthorized person pretends to be an authorized user to obtain the information or to access the data. The attacker steals the identity of intended users to communicate with the other users, to access the relevant information and also to provide wrong information in the network. So that the confidentiality and integrity of data and authentication compromised. The one of the example of this type of threat is man-in-the-middle-attack.",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
The concept of data breach is that any malicious person or unauthorized person enters into a corporate network and stolen the sensitive or confidential data.,https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"All the dispatched jobs will be retrieved and performed by various video analysis engines running on worker instances (i.e. virtual machines). For each engine, before it can be called as a service of PaaS, it must be uploaded to an image of VM first and registered to obtain an unique engineID. To maximize simplicity and compatibility, it is only required for each engine to be able to be launched and accept optional parameters through command line interface. To coordinate job execution and report results, a bridge between PaaS controller and worker instance is required.",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
"The cloud in which resources are offered as services to the general public by service providers are known as public cloud. Several key benefits of using public clouds are no initial money investment on infrastructure and shifting of risks to infrastructure providers. But these clouds are deficient in fine-grained control over data, network and security settings, which hamper their usefulness in many business cases.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"We can broadly categorize healthcare as primary or secondary. Secondary healthcare providers, such as hospitals and other medical institutions, provide additional health services to complement those offered by general practitioners. Secondary healthcare can also be provided by pathologists working at laboratories and performing specific tests on patients. Both public and privately run healthcare providers generally have an administration and several other departments.",10.1109/MCC.2016.139,Healthcare-Related Data in the Cloud: Challenges and Opportunities,30 December 2016,0
"The DOI theory was developed by Rogers [12]. DOI is a widely used model to explain why and how adoption of new ideas and technologies occurs at individual and organisational levels. The DOI theory posits that there are five technological attributes that have a direct impact on the adoption rate. These attributes are relative advantage, complexity, compatibility, trialability and observability",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"Finally, reverse Caesar cipher using the known Cipher Key is applied on the result achieved from phase 2 decryption to obtain final plain text in the receiving end. Results from phase 2 decryption is considered as input, “yxkhfkdaxqxfpqlybpbkqcoljyxeoxfkqlhrtxfq”, decryption key is considered as “4”. Result after phase 3 decryption has been achieved as “bankingdataisto besentfrombahraintokuwait”. Character wise input, Caesar cypher key and phase 3 decrypted result is shown in Table VI. Phase 3 decryption is shown in Figure 7.",https://doi.org/10.1109/CUBE.2013.20,Designing of Cryptography Based Security System for Cloud Computing,9 January 2014,0
"With the popularity of mobile devices, mobile cloud computing applications are becoming more and more widely used. The application scenarios include daily life, battlefield environment, emergency treatment, etc. The application types include image processing, speech recognition, augmented reality, social networks, etc. [24]",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"As IoT expands into various application domains such as healthcare, utility grids, cities, agriculture, transportation, industry 4.0, and disaster management, need for investigating on-the-fly computation over the IoT data streams is ever more pressing. Indeed, most IoT applications are modeled as data transformation workflows that consists of: i) multiple interdependent, heterogeneous data analysis computational and programming models that realise various data transformation tasks from data ingestion to analysis, ii) virtualised/non-virtualised computational and network infrastructure, iii) communication media of various kinds (including wireless). Currently, powerful Cloud Datacentres (CDCs, e.g. AWS1) provide computation and data storage resources for IoT workflows, but they suffer from limited bandwidth and network latency, and support neither latency-sensitive applications nor applications that rely heavily on the data streaming from IoT data sources for computing intelligence in real-time (in the form of data ingestion and data analysis).",10.1109/MCC.2017.22,Osmotic Flow: Osmotic Computing + IoT Workflow,26 April 2017,0
"Microservices are a Solution—Perhaps the Only Solution—to the Problem of Efficiently Building and Managing Complex Software Systems. For medium-sized systems, they can deliver cost reduction, quality improvement, agility, and decreased time to market. For large cloud systems, they fundamentally change the rules of the game. Microservices are the software equivalent of Lego bricks: they are proven to work, fit together nicely, and can be used to rapidly construct complex solutions.",10.1109/MCC.2016.109,The Economics of Microservices,11 November 2016,0
"Cloud computing is a product of both inherited and learned characteristics. It blends conventional definitions of resources with innovative usage patterns and solutions to facilitate user access to ever more powerful hybrid systems and introspective data. Cloud computing characteristics, service models, and deployment models are well documented, and hopefully well understood. Less apparent are the key trends shaping hybrid cloud computing: where they come from, what they're driven by, how they interact, whom they impact, and why they're important to understand.",10.1109/MCC.2016.21,The Hybrid Cloud Security Professional,26 February 2016,0
"The trading platform provides us with a set of simple and practical solution for online transactions. The online trading platform based on cloud computing framework sheilds a number of complex implementation details, and has an sandbox extremely easy to be used for debugging. Thus, we can not ignore these advantages.",https://doi.org/10.1109/APWCS.2010.15,A New Architecture of Online Trading Platform Based on Cloud Computing,7 June 2010,0
“ISO/IEC29100”- This privacy framework includes International Standard to protecting the personal identifiable information (PII) within information and communication technology (ICT) systems.,https://doi.org/10.1109/CSNT.2015.141,Efficient Framework Approach to Extract Privacy Issues in Cloud Computing,1 October 2015,0
"This evolution is mainly required for the adaptation of the cloud paradigm to the IoT phenomenon. The increasing need for supporting interaction between IoT and cloud computing systems has also led to the creation of the edge computing model, which aims to provide processing and storage capacity as an extension of available IoT devices, without needing to move data/processing to a central cloud data-center (such as Amazon Web Services). This reduces communication delays and the overall size of the data that needs to be migrated across the Internet and public and private datacenters.",10.1109/MCC.2016.124,Osmotic Computing: A New Paradigm for Edge/Cloud Integration,30 December 2016,0
"However, the integration of IoT with cloud services introduces some significant challenges—security and privacy being the foremost. Within the IoT paradigm, everything, including final dependability, relies on the integrity of the data, which drives the decision-making processes that enable smart functionality. The data should be secure and private as it's generated, communicated, stored, and analyzed within the complete integrated environment of public cloud facilities and IoT application domains. Most of the key IoT applications, which range from personal-level systems like e-health and assisted living to industrial-level systems like smart grid and machine/process monitoring, require the generated data to be both private and secure",10.1109/MCC.2016.30,Secure Data Analytics for Cloud-Integrated Internet of Things Applications,25 May 2016,0
"Typical cloud monitoring solutions consist of distributed components. Close to each resource under observation, an adaptor or collector is responsible to query statistics from hard-and software.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Using patterns, IT architects can compare cloud providers in terms of those patterns they support, and can design applications without considering the specific offering's idiosyncrasies too early in the design process.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"The basic notion of service-oriented architecture (SOA), and SOA using cloud computing, is to leverage these remote services using some controlled infrastructure that allows applications to invoke remote application services as if they were local to the application. The result (or goal) is a composite application made up of many local and remote application services. Since they're location and platform independent, they can reside on premises or within one of many cloud computing providers.",10.1109/MCC.2016.114,Practical Use of Microservices in Moving Workloads to the Cloud,11 November 2016,0
"Fault tolerance is the ability of a system to recover/restart from the nearest possible stable state after failure. Whenever a failure occurs, we have to recover from the failure (by choosing some mechanism like checkpointing etc.). Every time a node fails if we have to restart our query from the beginning then it becomes very hard for the long queries to complete. The only solution is fault tolerance, hence a system must be fault tolerant.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"Through which CSP can reduce the operational costs. Also reducing power consumption will make positive effects in greenhouse gas emission. Since cloud data centers were using 2% of worldwide global energy consumption and the rapid increase of cloud data centers may hold beyond 10% of global energy utilization, which is a big peril[29].",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"Some schemes rely on users to perform the verification—that is, a user must actively and repeatedly engage in a process that has expensive communication and computation overhead, which assumes that the user always has a device with sufficient computation capability and Internet bandwidth to perform integrity verification. To reduce the verification burden on users, we propose a public verification paradigm in which an external and independent auditor periodically verifies data integrity on users' behalf.",10.1109/MCC.2016.94,Cryptographic Public Verification of Data Integrity for Cloud Storage Systems,11 November 2016,0
"The small applications have a high degree of internal cohesion around a single task and can cope with a simple responsibility. Here, we consider “responsibility” as doing (or being responsible for) one activity only. The activity can include serving or representing a particular resource. Practical examples include logging incoming messages within a database or a file, or managing a message queue by taking, processing, and discarding queued messages. Such a concept started within the industrial practice of splitting large monolithic applications into small cooperating pieces to improve their maintainability, scalability, and testability. Microservice architectures are receiving increasing focus, as evidenced by search statistics on Google Trends.2 Academia's interest in microservices is also evidenced by the publication of the first mature academic book in 2015.",10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
To overcome the problems and challenges of cloud the some rigorous steps must be taken by the cloud vendors to protect their data and resources in order to provide a secure and reliable services to the consumers. The cloud providers must implement the concept of isolation and segmentation in their cloud infrastructure in order to solve the problems related to multi-tenant architecture. The implementation of honey pot system into the cloud infrastructure will solve the problem of Distributed Denial of Service Attack (DDoS) attack and abuse of cloud services up to a remarkable point.,https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"The key agreement protocol can support and provide secure data sharing for multiple data owners within a group, where the data sharing follows a many-to-many pattern.",https://doi.org/10.1109/TDSC.2017.2725953,Block Design-Based Key Agreement for Group Data Sharing in Cloud Computing,12 July 2017,0
"Tools, data sources, and network and computing resource providers make their resources available to the bio-ecosystem through this interface possibly in a plus and play manner.",https://doi.org/10.1109/CLOUD.2010.80,Cloud Computing Infrastructure for Biological Echo-Systems,26 August 2010,0
"Overall, we have seen that real-world businesses employ many concepts that make cloud applications scalable and resilient toward resource failures. These concepts should thus be common knowledge. However, IT application designers often neglect these concepts, creating holistic applications that are hard to manage during runtime.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
Traditional exascale simulations involve applications of differential equation based models that need very fine space and time steps and this leads to numerical formulations that need the memory and compute power of an exascale machine to solve individual problems (capability computing).,https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Trustworthy cloud computing relies on two parties performing certain tasks in a dependable man-ner. Traditional distributed architectures uphold trust by enforcing security policies. However, in cloud deployment models, data and application control is delegated, hence traditional policy-based enforcement presents a number of challenges. Reliable enforcement is a critical aspect of cloud service de-pendability. A trusted third party within a cloud environment is often used together with cryptographic methods to ensure the integrity, authenticity, and confidentiality of both data and communication.",10.1109/MCC.2015.45,"Security and Privacy in Cloud Computing: Vision, Trends, and Challenges",2 June 2015,0
"To implement the service, we use the RESTFul architecture deployed on the open source OpenStack cloud system. Our system's advantages include services' reusability, improved fault tolerance, easy distribution of newer versions, and decoupling of services (and thus easy management). Our expectation is that decoupling the system components from the application logic will offer more flexibility; for example, integrating a new system will not require changes to the service's internal procedures.",10.1109/MCC.2016.128,Internet of Things Architecture for Enhanced Living Environments,30 December 2016,0
"In the cloud, workload varies time to time and accordingly resources have to be provided. Hence all the resources may not be used all the time. Powering on and off of the servers, switching workload in servers leads to research problems of minimizing the number of powered on systems, which is a major part of cloud energy efficiency.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"Patterns avoid provider- or implementation-language-specific terminology, thus documenting design knowledge gained from practice in a provider-independent form.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"On the other hand, monitoring the physical infrastructure from the virtual infrastructure is due to isolation technically impossible. The physical infrastructure the other way round sees only the load produced by the virtual infrastructure on the physical resources but lacks details about application specific metrics and, due to e.g. overbooking, the actually experienced resource utilisation from inside the virtual infrastructure.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"In this article, I'll review the advantages of SDN, describe how to exploit it, and explain related business and technology opportunities that might not readily be clear. Moreover, I'll look at the potential for SDN solutions to live in the cloud, providing an on-demand networking capability that could offer better and cheaper approaches to networking, and the ability to place network volatility into its own domain.",10.1109/MCC.2016.62,Software-Defined Networks Meet Cloud Computing,4 July 2016,0
"However, current industrial deduplication solutions can't handle encrypted data. Existing solutions for deduplication are vulnerable to brute-force attacks' and can't flexibly support data access control and revocation (see the “Related Work in Data Deduplication” sidebar for a discussion of some other work in this area).3 Few existing schemes for cloud data access control support data deduplication simultaneously,4 and few can ensure flexibility and security with sound performance for cloud data deduplication that data owners control directly",10.1109/MCC.2016.29,Encrypted Data Management with Deduplication in Cloud Computing,25 May 2016,0
"Healthcare data contain personal and sensitive information that may be attractive to cybercriminals. For example, cybercriminals seeking to benefit financially from the theft of such data may sell the data to a third-party provider, who may perform data analysis to identify individuals who may be uninsurable due to their medical history or genetic disorder. Such data would be of interest to certain organizations or industries.",10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"Trust refers to the reliance on another entity and the belief that this entity will function as expected. Trust in the cloud environment heavily depends on trusting the service itself and the provider to provide a trusted level of authenticity, integrity and confidentiality in regard to the service and the stored data.",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"Data security is a major issue in cloud because data is managed by a third party and confidentiality of data becomes a major conern over here. The chances that host company may violate the privacy of its customers and access data without permission, makes some potential customers worried [7]. So, data security also becomes an important issue in cloud data management",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"Public cloud: A public cloud is a cloud that is available to the general public on a pay-as-you-go basis. A third-party provider offers services such as computing, storage space, networks, virtualization, and applications to a large number of clients in the public cloud.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"Big data always deals with data collection from various sources and is one of the major challenged faced in cloud computing, since it leaks client's sensitive information. This type of data migration may lead to violation of user's privacy policy. Another challenge lies in cloud computing is user's identification and authentications and need to be resolved in networking [6].",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"Virtual machine monitor is a software that allows a single physical machine to support multiple virtual machines. It is based on three virtualization technologies which are full-virtualization, para-virtualization and OS-level virtualization (Isolation), etc.",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"Fog computing demonstrates superior advancements and exhibits enhanced performance compared to cloud computing in terms of managing user demands and adhering to evolving norms. Cloud computing is a form of infrastructure that relies on hardware and software to facilitate job management and handling. In contrast, Fog computing leverages the resources of edge devices. However, it is important to note that Fog computing does not currently possess the capability to supplant cloud computing, which remains the dominant force in the commercial world and a significant source of employment globally.",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"Most agree that the definition implies some kind of technology that provides an isolation and multitenancy layer, and where computing resources are split up and dynamically shared using an operating technique that implements the specified multitenant model. Two technologies are commonly used here: the hypervisor and the container. You might be familiar with how a hypervisor provides for virtual machines (VMs). You might be less familiar with containers, the most common of which rely on Linux kernel containment features, more commonly known as LXC (https://linuxcontainers.org). Both technologies support isolation and multitenancy.",10.1109/MCC.2014.51,Containers and Cloud: From LXC to Docker to Kubernetes,30 September 2014,0
The presented approach is being developed at present and consists of the two development tasks for collecting the resource statistics and converting the statistics into statistical models,https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Consider Apple. Its shift from a perpetual license model to the iTunes store's pay-per-use option allowed it to quadruple revenues in four years. The Apple model depends on tight integration between Apple's ERP system and the billing engine, which handles 10 million sales per day. It would be difficult, if not impossible, to set up such a tight integration between the cloud's ERP and Apple's highly proprietary billing software.",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"Cisco estimates that by 2020 there will be more than 50 billion Web-enabled devices, including refrigerators, televisions, and scales.3 Internet and cloud service providers (ISPs and CSPs) and consumers have already encountered many global privacy threats due to the use of pervasive products and services. Recent press reports highlight several privacy violations in IoT applications.4, 5 For example, in June 2013, the press revealed privacy risks related to the Planning Tool for Resource Integration, Synchronization, and Management (PRISM) program, which the US National Security Agency uses to collect private electronic data belonging to users of major Internet services including Microsoft Outlook, Google, and Facebook. Further, an annual Internet security threat report claims that mobile malware attacks increased by 58 percent from 2011 to 2012, and 32 percent of those attacks attempted to steal information from the device's contact information.5 According to a US Federal Trade Commission (FTC) report on consumer privacy, privacy by design (PbD) is the most prominent approach to overcoming IoT privacy issues.",10.1109/MCC.2016.28,The Quest for Privacy in the Internet of Things,25 May 2016,0
"Cloud applications should respect a provider's availability assurances. With low node-based availability or environment-based availability, a watchdog can help identify and handle failures. The coffee shop manager commonly fulfills this role in the real world.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
Big data problems do not clearly need a full exascale system to address a single job. Typically any platform will be running lots of jobs that are sometimes pleasingly parallel/MapReduce (Cloud) and sometimes small to medium size HPC jobs which in aggregate are exascale (HPC Cloud) (capacity computing).,https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"For fundamental cloud computing patterns, we show that coffee shops similarly handle the five design phases of cloud applications: decomposition, workload, data (state), component refinement, and elasticity and resiliency.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"In contrast, all state-of-the-art implementations of data mining algorithms operate by loading the whole training dataset into the main (RAM) memory of a single machine or simple machine clusters that have static processing and storage capacity configurations. This approach has two key problems.3–6 First, the data can simply grow too big over time to fit into the available RAM. Second, most of big data applications produce data spread across multiple distributed data sources (including streaming sources). Moving all the datasets to a centralized machine is thus expensive (due, for example, to network communication and other I/O costs), even if we assume that the machine has a super-large RAM to hold all the data for processing. Further, when the data mining algorithms' computational complexity exceeds the available RAM, the algorithms don't scale well and they never finish or are unable to process the whole training dataset.",10.1109/MCC.2014.22,Streaming Big Data Processing in Datacenter Clouds,10 July 2014,0
Sensor Management The sensor management package is a standard application that provides sensor management services to other applications on the device. This provides the BlacBerry 10 device user and client applications with an interface to list installed support packages and invoke them in limited ways,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Experimentation was done with the Max-Min, Min-Min, RSA, Improved Max-Min and Enhanced Max-Min algorithms. They showed that it performs better in terms of makespan and the proposed algorithm can be further improved to get better results. In [13] Pengcheng Han, Chenglie Du and Jinchao Chen have proposed a meta-heuristic based algorithm HDEA. The algorithm is based on Differential evolution algorithm (DEA) and several optimization policies. The algorithm was compared with two other representative evolutionary algorithms DEA and SOS algorithm",https://doi.org/10.1109/SmartCloud49737.2020.00015,An Efficient Task Scheduling Algorithm using Total Resource Execution Time Aware Algorithm in Cloud Computing,27 November 2020,0
"Trustworthy cloud computing relies on two parties performing certain tasks in a dependable man-ner. Traditional distributed architectures uphold trust by enforcing security policies. However, in cloud deployment models, data and application control is delegated, hence traditional policy-based enforcement presents a number of challenges. Reliable enforcement is a critical aspect of cloud service de-pendability. A trusted third party within a cloud environment is often used together with cryptographic methods to ensure the integrity, authenticity, and confidentiality of both data and communication.",10.1109/MCC.2015.45,"Security and Privacy in Cloud Computing: Vision, Trends, and Challenges",2 June 2015,0
"Sensor networks are keys to the creation of smart environments, which embed information technology in everyday home, cities and work environments. The increasing interest in wireless sensor networks can be promptly understood simply by thinking about what they essentially are: a large number of small sensing self-powered nodes which gather information or detect special events and communicate in a wireless fashion, with the end goal of handing their processed data to a base station.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"OpenNebula is an open source toolkit used to build private, public and hybrid Clouds. It works with Xen, KVM and VMware virtualization solution and it is currently working on supporting VirtualBox",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"Note that the parameter lists are optional and may be of variable lengths. The orchestrator will then launch the engines specified in the given workflow and automatically append the corresponding parameters as input. In practice, an engine on PaaS is not necessarily limited to perform only video analysis tasks. For example, it could also be a video crawler which sends HTTP requests or CGI commands to remote DVR/NVR to retrieve video clips for the subsequent processing.",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
"In cloud data centres the two stakeholders provider and customer, with physical servers versus limited view on virtual resources usually have their own monitoring systems. Both the virtual and physical level are isolated and don't have access to each other, yet the physical level experiences the load from the virtual level on the physical resources.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"In practice, distributed cloud computing has remained highly provider-centric, and multicloud integration remains a challenge. Adoption also suffers from vendor lock-in, with services tightly coupled to providers. Lack of interoperability stems mainly from the heterogeneity of technologies (for example, different hypervisors), and from service-resources mappings that are incompatible across providers, hampering, for instance, uniformity in service-level agreements (SLAs). User control is also limited by monolithic infrastructures, preventing fine-grained cloud customization by the customer (for example, hypervisors hide specific hardware capabilities).",10.1109/MCC.2016.110,User-Centric Security and Dependability in the Clouds-of-Clouds,11 November 2016,0
"To the best of our knowledge, container ecosystem security has yet to be fully investigated, despite being fundamental to container adoption. Here, we address that gap and focus our investigation on the Docker ecosystem for three reasons. First, Docker successfully became the reference on both the market of containers and the associated DevOps ecosystem. In particular, 92 percent of people surveyed by ClusterHQ and DevOps.com are using or planning to use Docker in a container solution.7 Second, security is the first barrier to container adoption in the production environment,7 Docker being no exception in this. Finally, Docker is already running in some environments, making it possible to run experiments and explore the practicality of some attacks.",10.1109/MCC.2016.100,To Docker or Not to Docker: A Security Perspective,11 November 2016,0
"Even among humans, communication is not a simple endeavor. Despite many attempts, some political, some altruistic, and most at their core economic, there has never been nor will there ever most likely be a single standard spoken or written language that spans all of humanity and crowds all other languages to non-existence. The closest we have come so far as a species may be HTML, and even this nearly-universal method shows the rapid evolution, fragmentation, and specialization that are characteristic of human endeavors.",10.1109/MCC.2017.23,Standards at the Edge of the Cloud,26 April 2017,0
"To better understand the potential of this revolution, recognize that most of IoT data collected today is not used, and data that is used is not yet fully exploited. For instance, less than one percent of data is utilized today. This means that 99 percent of IoT data is lost, either because it is not captured or it is captured but not analyzed or used for business ana-lyrics.” Most data that is used on factory floors, finds application in real-time control or anomaly detection, to send alarms when the sensor detects something out of tolerance. A great deal of additional value remains to be captured by using the data for predictive maintenance or to optimize operational processes.",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
"Work is underway to develop ontology for a constrained domain of problems that utilize Hybrid Meta-Heuristics (HMH). These problem solving methods are well suited to the execution on cloud computing platforms as they require large amounts of computing power, previously seen in grid computing applications.",https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"The statistical model to represent the resource statistics consists of two parts: a state change probability matrix as the dynamic part, while a static part contains fixed information like CPU cores, and reference values of the underlying hardware for hardware independent comparisons.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Eucalyptus (Elastic Utility Computing Architecture for LinkingYour Programs To Useful Systems) project began from California University Santa Barbara, and mainly was used to build open-source private cloud platform [8]. Now it has been run by Eucalyptus system company. Eucalyptus is an open-source implementation of Amazon EC2 and compatible with business interfaces. It also implement virtualization depending on Linux and Xen as EC2 does.",https://doi.org/10.1109/ISISE.2009.94,Comparison of Several Cloud Computing Platforms,15 April 2010,0
"However, as with many things, the devil is in the details and the economic benefits of serverless computing heavily depend on the execution behavior and volumes of the application workloads. In the same way that pennies per day can add up to thousands of dollars eventually, low “per hit” prices can not only add up as transaction volumes increase, but can make serverless economics unattractive relative to what have now become more traditional approaches, such as virtual machines or even dedicated hardware.",10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"While older adults stay in the home of their choice, in-home sensors can be used to monitor older adults' activity patterns; smart algorithms recognize changes in the patterns and send health alerts to care coordinators to flag potential health changes and administer targeted coaching. Our previous study has shown that in-home sensor data from bed, motion, and gait sensors, gathered using web services in an app form, can automatically provide ongoing health assessments without being obtrusive.1 Although they can even alert caregivers when the system detects health changes, alert notifications capability as provided in our App-1 are not enough. In App-2,2 we have shown how care coordinators can provide active corrective health coaching by real-time analysis of a large amount of data from patient's homes using a cloud platform. An example of the use of App-2 is illustrated in Figure 1, where an interface is shown that we developed for a physical therapist (PT) at a clinic. The app helps the PT interact with an older adult in a home to assess his/her mental and physical health status through guided physical exercises designed to overcome the risk of falling.",10.1109/MCC.2017.46,Toward an ElderCare Living Lab for Sensor-Based Health Assessment and Physical Therapy,29 June 2017,0
"The above examples demonstrate the rise of big data applications, in which data has grown unre-strainedly. Conventional data processing technologies are now unable to process this data within a tolerable elapsed time. Such applications generate datasets that don't fit the data processing model frameworks of traditional relational databases (such as Oracle, MySQL, and DB2) and data mining (such as Microsoft Excel, Matlab, and R). Relational databases operate on archived data in response to queries such as “commit a credit card transaction” (as in e-commerce). That is, the data processing technologies are designed to maintain an efficient and fault-tolerant collection of data that's accessed and aggregated only when users issue a query or transaction request (and thus the data must be archived prior to processing).",10.1109/MCC.2014.22,Streaming Big Data Processing in Datacenter Clouds,10 July 2014,0
"Although VMs and containers are both virtu-alization techniques, they solve different problems. Containers are tools for delivering software-that is, they have a platform-as-a-service (PaaS) focus-in a portable way aiming at greater interoperability while still utilizing OS virtualization principles.[1] VMs, on the other hand, are about hardware allocation and management (machines that can be turned on/off and be provisioned)-that is, there's an infrastructure-as-a-service (IaaS) focus on hardware virtualization. Containers can be used as a replacement for VMs where the allocation of hard-ware resources is done through containers by componentizing workloads in between clouds.",10.1109/MCC.2015.51,Containerization and the PaaS Cloud,15 July 2015,0
"Cloud computing technology has also been steadily growing, becoming a mature service platform with worldwide spending upward of US$170 billion in 2014.3 Cloud resources provide a pervasive, convenient, and reliable platform for high-performance computing and storage that's scalable and accessible on demand anywhere. The integration of cloud computing services over large-scale IoT implementations will help achieve the required computational and storage needs for effectively analyzing large amounts of generated data. This will enable smart functionality over a wide variety of applications that are set to be revolutionized by the adoption of this emerging paradigm of cloud-assisted IoT implementations.",10.1109/MCC.2016.30,Secure Data Analytics for Cloud-Integrated Internet of Things Applications,25 May 2016,0
"By nature, clouds are large distributed systems providing resources for computation, communication, and storage.4 Monolithic applications that comprise one component and use a single server for hosting do not benefit from this distributed environment.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
With overbooking and resource sharing it is important to understand the difference between i) VM doesn't need more resources at the moment versus ii) VM cannot consume more resources due to resource bottlenecks. This contains a necessity to identify resource bottlenecks for VMs on the physical level.,https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"User interface and processing components should interact asynchronously. The tiers that are scaled, such as virtual servers, should be configured to possibly fulfill the functionality of multiple application components. This lets the application reassign resources more flexibly",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"SciCloud is also relevant and used in solving other enterprise problems; Web services [7] are going mobile. A Mobile Enterprise can be established in a cellular network by participating Mobile Hosts [9], which act as web service providers, and their clients.",https://doi.org/10.1109/CCGRID.2010.56,SciCloud: Scientific Computing on the Cloud,24 June 2010,0
"Understanding the trends has a practical consideration, as engineering the merger for HPC and data-intensive problems will allow: (i) More efficient sharing of large scale resources running simulations and data analytics; (ii) The need for higher performance Big Data algorithms; (iii) Richer software environment for research community building on many “big data” tools, and (iv) Facilitate a sustainability model for HPC, as it does not have resources to build and maintain a full software stack.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"In order to save energy, devices are provided with a feature named as ""sleep mode"" and the system rests when there is no activity on the device for a long time. This is an important feature as it helps in saving electricity. This is an automatic managed feature by the operating system. About the power saver mode, it lowers the computer’s performance and speed of the brain of the computer and also the screen light to the very low level where only it is visible and not clearly visible.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"Whenever possible, the application components should not handle session and application states. Instead, such states should be kept in requests or in communication and storage offerings. In a coffee shop, employees do not memorize the order status or communicate it directly; the coffee cups act as an asynchronous form of communication to manage state.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"To enable application specific metrics, the cloud provider specifies a channel which can then be used by customers to pipe their specific monitoring data through the execution middleware like hypervisor or container engine towards Clomon. The required channel can be considered as a virtual device or a virtual network adaptor, which is securely isolated and unidirectional.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"By the development of cloud technology it creates a new security challenges that leads to various research work in field of cloud security. The analysis of security problem [1] shows the dependency between the layers, it shows that the security of any upper layer depends upon the subsequent lower layer of the cloud architecture. The CSA (Cloud Security Alliance) published The Notorious Nine [2] in 2013 and shows the top nine threats of the cloud and their possible solutions. Cloud Standard Customer Council published in 2012 Practical Guide to Cloud Service Level Agreements [3] that deals with the all aspects of a standard service level agreement.",https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"The virtual computing layer is cable of image creation, maintenance and downloading on behalf of the cloud terminals. Using such virtual computing layer will considerably reduce the load maintained between the virtual computing client and the server.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"Sensing, processing and communication are three key elements whose combination in one tiny device (mobile and tablet) gives rise to a vast number of applications. Sensor networks provide endless opportunities, but at the same time pose formidable challenges, such as the fact that energy is a scarce and usually non-renewable resource.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"For comparable resource utilisation values, the hardware has to be considered as well. The first step towards hardware independence for resource statistics obviously is a lookup of the hardware specifications for each physical hardware.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"One could also leverage cloud computing to achieve faster and energy-efficient communications between sensing devices and the base stations, with a longer range. For example, processing, storage, and analysis of the sensing data can be securely outsourced to the cloud. In addition, the increasing miniaturization of hardware has allowed these tiny devices to perform more than just sensing, such as presenting themselves as a service (i.e. device as a service). Such an evolution (see Figure 1) where the cloud has a central role in the overall infrastructure for data processing, storage, and analysis, as well as visualization is also known as Internet of Things (IoT).2 Building a content gathering and processing network from distributed devices based on clouds presents a series of challenges, such as those relating to reliable content gathering, unreliable and heterogeneous sources, fast data delivery, real-time scheduling, cross-domain security, and cost efficiency.",10.1109/MCC.2017.30,Challenges of Connecting Edge and Cloud Computing: A Security and Forensic Perspective,26 April 2017,0
"Ten years ago1 Amazon started a revolution that is completely transforming the IT market. Since the release of its Elastic Compute Cloud (EC2) in August 2006, Amazon has reduced prices more than 50 times.2 These cost reductions are due to a variety of factors: economies of scale, learning curve effects, price promotions, signaling to rivals in an increasingly competitive market, less expensive hardware due to no-frills hardware designs (thanks to initiatives such as Open Compute), and Moore's Law effects. Sometimes these reductions can be fairly dramatic. It was in March of 2014 that EC2 prices were slashed by as much as 45 percent. This was one day after Google announced price reductions for virtual machines of by up to 32 percent and its commitment to a Moore's Law pricing model.3 However, the average annual price reduction since Google released its cloud computing services has been far from 30 percent.",10.1109/MCC.2017.42,The Limits to Cloud Price Reduction,29 June 2017,0
"Gordon et al. proposed an application model called COMET [13], offloading multi-threaded applications to cloudlet servers transparently. COMET combined the workload of mobile device with the decision making process of thread migration, and utilized the distributed shared memory techniques, thereby, supporting the migration of several threads.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"Provisioning cloud resources as elastic service units boost up elastic software development, there is a need to establish the real elasticity metrics, cloud test cases has to be generated, since the cloud services are automatically deployed in same time of development, instead of test and deploy we can shift to a model deploy and test",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"Therefore, ensuring the security of the EMR/EHR/PHR ecosystem and the underlying systems and components that form the ecosystem is crucial, yet challenging due to the interplay and complexity between the systems and components. Moreover, the privacy and integrity of healthcare data must be protected not only from external attackers, but also from unauthorized access attempts from inside the network or ecosystem (e.g. employee of the healthcare provider, or cloud service provider). The attacks (e.g. leakage or modification of data) can be intentional and unintentional, and organizations may be penalized or held criminally liable for such incidents, for example under the Health Insurance Portability and Accountability Act.",https://doi.org/10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"The approach presented in this paper PINaaS, provides a brokerage mechanism for executing Task requirements by selected PSM using resources offered by cloud providers. An example could be a pharmaceutical company looking to run 1 million drugs discovery tasks a month using a processor intensive PSM with a Domain Model that requires 1 TB of storage. The advantage of the PINaaS approach is that users and suppliers have a clear specification of Tasks, PSM and Domain models.",https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"The characterization of workloads is a complex research problem given the frequency of workloads that include diverse, nontrivial, and inadequately understood characteristics. Open research topics encompass a range of workloads, including those pertaining to fog clouds, large data, mysterious societal systems, and sensor complexes, among others.",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"In this article, I'll review the advantages of SDN, describe how to exploit it, and explain related business and technology opportunities that might not readily be clear. Moreover, I'll look at the potential for SDN solutions to live in the cloud, providing an on-demand networking capability that could offer better and cheaper approaches to networking, and the ability to place network volatility into its own domain.",10.1109/MCC.2016.62,Software-Defined Networks Meet Cloud Computing,4 July 2016,0
The best practice for decomposing application functionality is captured by the distributed application pattern: a cloud application divides provided functionality among multiple application components that can be scaled out independently,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
These resource shortcomings combined with the resource utilisation together are the actual resource experience for a customer inside virtual resources.,https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"It is still a big challenge to create a database appliance that can be easily deployed in a cloud [13]. These issues may be related to localization, routing, authentication, placement of virtual machines on physical machines, how to handle varying workloads.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"The cloud entities are majorly targeted in their functionality of data migration, data storage and their maintenance. The cloud privacy is imposed on the cloud entities by considering the mentioned challenges to address the user's objectives and authorizations.",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"It is an open source Cloud Computing framework commonly available to academic research groups. It provides a modular and open to experimental instrumentation and study platform [7]. The architecture of Eucalyptus is simple, flexible and modular with a hierarchical design. Currently, it supports VMs that run with Xen, KVM and VMware.",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
The challenging task for the Clomon tool is in collecting resource statistics with resource sharing and overbooking in mind. Clomon hence invests additional effort to enrich the traditionally reported resource statistics with the previously listed metrics.,https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"The microservices-based approach is in contrast to the traditional “monolithic” development of applications, where each application is a single, autonomous unit. For example, in a client-server application, the server is a monolithic entity that handles HTTP requests, executes logic, and retrieves or updates its data. The problem with such monolithic architectures is that even a small modification of the application's logic requires the deployment of a new running version of the entire code base. A microservice architecture is lightweight and easily shipped and updated. Hence, it's ideal for engineering applications where we cannot fully anticipate functionalities in advance (for example, the types of devices that might one day access the application). Microservice architectures are a part of a larger shift in IT departments to-wards a DevOps culture, in which development and operations teams work closely together to support an application over its lifecycle, and go through a rapid or even continuous release cycle.",10.1109/MCC.2016.112,Open Issues in Scheduling Microservices in the Cloud,11 November 2016,0
"At present, there are few solutions to address the challenges of secure data sharing and searching in clouds. Typically, to ensure confidentiality of shared data, symmetric key,6 public key,7 and homomorphic8 encryption-based mechanism are currently used. Access control policies based on access control list9 and dynamic attribute10 are used for access control purposes. Searchable encryption based on symmetric11 and public12 keys are used for searching the desired data. In all these schemes, for data security, major security-oriented processing such as encryption, decryption, and access control mechanisms are handled by the user's device itself. In IoT, the resource-limited smart devices cannot handle these computation intensive operations because the security-oriented operations will increase the heavy computational burden.",10.1109/MCC.2017.9,Secure Data Sharing and Searching at the Edge of Cloud-Assisted Internet of Things,15 March 2017,0
"A particularly promising approach to improving security in cloud computing is the use of cryptographic methods. Because of limitations in computational efficiencies and associated con-straints, traditional cryptographic techniques aren't yet widely used in cloud-based environrnents.[2] Proposed homomorphic encryption schemes have proven to offer a high level of security, but they require lengthy computations; more efficient and scalable security solutions are thus needed.",10.1109/MCC.2015.45,"Security and Privacy in Cloud Computing: Vision, Trends, and Challenges",2 June 2015,0
"Here, we propose a generic IoT architecture and present a motion-sensing cloud service to monitor patients' movement. The fundamental idea is that, by placing such sensors in enhanced living environments (ELEs), we can offer patients protection from accidents (such as falls) and let caregivers monitor patients remotely. In particular, the caregivers can monitor patients as well as create and monitor predefined movements for patients in rehabilitation. Our work was motivated by an existing motion sensor data collection system,10, 11 which collects data according to an event-based architecture that includes constant updates for patients who might need help.",10.1109/MCC.2016.128,Internet of Things Architecture for Enhanced Living Environments,30 December 2016,0
"It is beneficial for drivers to know about the some important road and traffic situations such as heavy rain, fog etc. before starting journey. The drivers can use this service to get the information about the road conditions and alert from the possible accidents on road or intersections.",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
Businesses that use public cloud services save money and time by exploiting the cloud's elastic scalability and market-oriented estimate capabilities.,https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"In ""standby mode"" all the parts of the computer system are switched off except memory. Memory restarts when the user left and resumes the system whenever any key on the keyboard is clicked or mouse is dragged as memory is not standby in this mode. In ""HB mode"" all the parts of the computer system are switched off involving memory as well.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"The capability provided to the consumer is to rent processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can include operating systems and applications.",https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"As reported by Arbor Networks, the percentage of attacks targeting cloud-based services is growing each year. Over 33 percent of reported DDoS attacks in 2015 targeted cloud services, which makes the cloud a major attack target. Motivation for the DDoS attacks range from extortion, demonstration of attack capabilities, and hacktivism to business rivalry. It is interesting to note the rise of DDoS-attack-for-hire payment-based services, also known as booters or stressers, that attack a target via the planting of attack guns (botnets).3 With the arrival of these methods, the attack frequencies to victim organizations have increased considerably in recent few years. DDoS attacks may last between a few seconds to even weeks in a few cases, which multiplies the economic and business losses multifold.",10.1109/MCC.2017.14,"Combating DDoS Attacks in the Cloud: Requirements, Trends, and Future Directions",15 March 2017,0
"Another commonly seen criminal exploitation of the cloud is to support the execution of large-scale and distributed attacks, for example by compromising some instances of virtual machines within a cloud infrastructure to launch Distributed Denial-of-Service (DDoS) attacks against third-party websites, portals or platforms. In 2012, a group of cyber-criminals exploited the CVE-2014-3120 Elasticsearch 1.1.x vulnerability, in order to compromise virtual machines within Amazon EC2, and launched a UDP based DDoS attack. Predictably, most cloud service providers have platform-wide DDoS protection systems that monitor incoming and outgoing traffic in order to prevent DDoS attack against their platform or to avoid being used to launch such attacks.",10.1109/MCC.2017.39,Evidence and Forensics in the Cloud: Challenges and Future Research Directions,29 June 2017,0
"In the last few years, as the cloud has reached functional maturity, the research community has focused on protecting security and privacy of its users from different angles.3 Several techniques have been proposed, including solutions to protect confidentiality and integrity of data and applications, maintain isolation among cloud tenants, and identify malicious and fraudulent activities. Despite the good intention behind such efforts, they have led to the proliferation of heterogeneous approaches and have increased user confusion. Indeed, the perception that the operation of different security and privacy controls may be affected in a different way by virtualization and cloud-specific factors is a main obstacle to cloud adoption in emerging domains, such as big data domains.",10.1109/MCC.2017.51,Towards Transparent and Trustworthy Cloud,29 June 2017,0
"At the same time, data owners want CSPs to protect their personal data from unauthorized access. CSPs should therefore perform access control based on the data owner's expectations. In addition, data owners want to control not only data access but also its storage and usage. From a flexibility viewpoint, data deduplication should cooperate with data access control mechanisms. That is, the same data, although in an encrypted form, is only saved once at the cloud but can be accessed by different users based on the data owners' policies",10.1109/MCC.2016.29,Encrypted Data Management with Deduplication in Cloud Computing,25 May 2016,0
It takes advantage of clustering techniques to spot the behavior of elastic cloud. ADVISE recommends appropriate cloud service in runtime by evaluating deployed infrastructure dynamics and external environment variables.,https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"Many formal definitions of cloud computing exist. The National Institute of Standards and Technology's internationally accepted definition calls for “resource pooling,” where the “provider's computing resources are pooled to serve multiple consumers using a multitenant model, with different physical and virtual resources dynamically assigned and reassigned according to consumer demand.“[1] It also calls for “rapid elasticity,” where “capabilities can be elastically provisioned and released, in some cases automatically, to scale rapidly outward and inward commensurate with demand.”",10.1109/MCC.2014.51,Containers and Cloud: From LXC to Docker to Kubernetes,30 September 2014,0
"Even though application components might experience the same workload type, the actual processing complexity can differ significantly, Scaling an application as a holistic unit - for example, by hosting all application components on a single server - can, therefore, be very inefficient.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
Resource statistics depend on the hardware it currently runs on. The cpu utilisation on a low CPU frequency might be much longer than on a CPU with higher frequency.,https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Layer-based decomposition divides the application into layers based on the provided functionality - for example, user interface, processing, and data handling layers. Components are assigned to these layers and may interact only with components on the same layer or one layer below to ensure that interfaces between components are well-defined and dependencies are reduced.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"A good example of a service is a risk analysis process, which runs within an enterprise to calculate the risk of a financial transaction. This remote application service is of little use by itself, but when abstracted into a larger application—for example, a trading system—that remote application service has additional value.",10.1109/MCC.2016.114,Practical Use of Microservices in Moving Workloads to the Cloud,11 November 2016,0
"In order to secure the communication over network, the Transport Layer Security (TLS) protocol can be used. IDS and advanced firewalls will be helpful while detecting the port scan. The Domain Name System Security Extension (DNSSE) is installed to handle DNS threats.",https://doi.org/10.1109/I-SMAC47947.2019.9032545,"A Survey of Cloud Computing Security Challenges, Issues and their Countermeasures",12 March 2020,0
"Because cloud environments are large distributed systems by nature, IT architects must decompose a cloud application's functionality into components. These components can then be hosted on multiple cloud resources. This decomposition into separate components forming a processing pipeline is also visible in the coffee shop.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"We use term cloud broadly without choosing particular implementations: public/private clouds, OpenStack/Docker virtualization. In fact many public clouds now offer features characteristic of HPC including GPU's, high performance networks and FPGA accelerators. This is clear for deep learning in the cloud where the value of GPU's Is well understood.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Private clouds are designed for restricted use by a single association. It is also called internal cloud. It offers the uppermost degree of control over performance, reliability and security but may be criticized for being similar to traditional proprietary server farms and for not providing reimbursement such as no up-front capital costs.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"A particularly promising approach to improving security in cloud computing is the use of cryptographic methods. Because of limitations in computational efficiencies and associated con-straints, traditional cryptographic techniques aren't yet widely used in cloud-based environrnents.[2] Proposed homomorphic encryption schemes have proven to offer a high level of security, but they require lengthy computations; more efficient and scalable security solutions are thus needed.",10.1109/MCC.2015.45,"Security and Privacy in Cloud Computing: Vision, Trends, and Challenges",2 June 2015,0
"recent advances in low power VLSI, embedded computing, communication hardware, and in general, the convergence of computing and communications, are making this emerging technology a reality. Likewise, advances in nanotechnology and Micro Electro-Mechanical Systems (MEMS) are pushing toward networks of tiny distributed sensors and actuators",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"The industry has moved beyond the simplistic, black or white debate of whether to use public cloud services in consolidated hyperscale facilities. Instead, real-world environments typically use a mix of strategies, including legacy environments, private clouds, and public cloud providers at the infrastructure, platform, or software level, and increasingly are utilizing not just centralized facilities, but highly dispersed compute and storage elements: the “fog”.1",10.1109/MCC.2017.13,The Economics of the Hybrid Multicloud Fog,15 March 2017,0
"STREAM is designed mainly to measure the memory bandwidth using four operations, Add, Copy, Scale and Triad, and was set up with an array size of 2,000,000.",https://doi.org/10.1109/CLOUD.2017.99,"A ""No Data Center"" Solution to Cloud Computing",11 September 2017,0
Process-based decomposition considers the business process the application supports using modeling languages such as the Business Process Execution Language (BPEL)6 or Business Process Model and Notation (BPMN),https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Concluding the resource statistics collection, it is important to combine several metrics beyond the typically measured ones, in order to understand the virtual resource experiences from the physical level point of view.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"It is the technique to use multiple imaginary servers on one machine. Cloud Computing is based on virtualization and user can use the imaginary servers whenever required and when they are not in use, he/she can dispose of that imaginary server. This concept is already in use and it provides optimal solution in saving energy because servers when not in use are disposed of.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"Isolation is considered as the most performant solution. However, its disadvantages lies in the fact that it exists only for Linux systems and guests OSs must have the same OS type as the host;",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"As the size of data grows, most database system does not easily scale beyond a certain limit. As with the passes of time the size of data is growing very fast and hence scalability is a major challenge [12].",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"Cisco estimates that by 2020 there will be more than 50 billion Web-enabled devices, including refrigerators, televisions, and scales.3 Internet and cloud service providers (ISPs and CSPs) and consumers have already encountered many global privacy threats due to the use of pervasive products and services. Recent press reports highlight several privacy violations in IoT applications.4, 5 For example, in June 2013, the press revealed privacy risks related to the Planning Tool for Resource Integration, Synchronization, and Management (PRISM) program, which the US National Security Agency uses to collect private electronic data belonging to users of major Internet services including Microsoft Outlook, Google, and Facebook. Further, an annual Internet security threat report claims that mobile malware attacks increased by 58 percent from 2011 to 2012, and 32 percent of those attacks attempted to steal information from the device's contact information.5 According to a US Federal Trade Commission (FTC) report on consumer privacy, privacy by design (PbD) is the most prominent approach to overcoming IoT privacy issues.",10.1109/MCC.2016.28,The Quest for Privacy in the Internet of Things,25 May 2016,0
"For network overbooking, errors and losses are an important metric for measuring overbooking. The queue sizes of buffers at least within the physical server reveals further information about if a virtual resource requires more resources than physically available",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"The coffee shop uses the third decomposition strategy: pipes-and-filters-based decomposition. Functionality is divided based on the processing function (Figure 2) - user interface, coffee processing, and special processing for frozen coffee.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"The Internet of Things (IoT) represents a paradigm for a smart world in which ubiquitous and pervasive computing and communication occur over a global network of heterogeneous and interconnected entities. The key enabling technologies for IoT are wireless sensor networks (WSN), machine-to-machine interfaces (M2M), RFID, and embedded sensor and actuator designs that enable sensing, command/control interaction, data communication/transfer, and limited analytical services.’ The main application areas that are being disrupted through the enabling of IoT include power systems and smart grid, e-health and assisted living systems, and large-scale industrial and environmental monitoring applications.1, 2 With the advent of constant Internet connectivity coupled with ubiquitous sensing, these applications are now producing vast amounts of data that have to be communicated, stored, processed, and analyzed in a secure and efficient manner to reach the targeted levels of smart functionality envisioned through the IoT.",10.1109/MCC.2016.30,Secure Data Analytics for Cloud-Integrated Internet of Things Applications,25 May 2016,0
"IoT devices are not only engaged in sensing, but they also perform some actions based on the sensed data and/or external queries. Because of this new vision, these devices are already the backbone of emerging applications, such as smart buildings, smart cities, smart vehicles, environmental sensing and forecasting, and disaster management, among others.",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
"As a development in the technology of the Internet and cryptography, group data sharing in cloud computing has opened up a new area of usefulness to computer networks. With the help of the conference key agreement protocol, the security and efficiency of group data sharing in cloud computing can be greatly improved.",https://doi.org/10.1109/TDSC.2017.2725953,Block Design-Based Key Agreement for Group Data Sharing in Cloud Computing,12 July 2017,0
"This research concludes that, among all the consideration factors, Cost, Networking, and Elasticity are the ones with strong influence power. We also find that once “dispatchers” factors like Cost and Network change the “receiver” factors like Adoptability and Performance will be impacted.",https://doi.org/10.1109/CloudCom.2012.6427610,Key consideration factors of adopting cloud computing for science,4 February 2013,0
"To maintain a reliable service, we want to ensure that 95% of the time a cloud job will complete successfully. To satisfy this requirement, we must always have at least one current snapshot present on another host as its presence is directly related to the future success of an application if it is interrupted in any way.",https://doi.org/10.1109/CLOUD.2015.153,Ad Hoc Cloud Computing,20 August 2015,0
"Nimbus is an open tool set, and also a cloud computing solution providing IaaS. Put forward based on scientific research in the early stage, Nimbus have supported many nonscientific research domain applications [7]. It permit users lease remote resources and build the required computing environment through the deployment of virtual machines. Figure 3 demonstrates the Nimbus cloud computing platform.",https://doi.org/10.1109/ISISE.2009.94,Comparison of Several Cloud Computing Platforms,15 April 2010,0
"How to secure EMR/EHR/PHR ecosystem and ensure privacy and integrity of the data is an active research area. Approaches include using cryptographic primitives, such as those based on public key infrastructure and public clouds to ensure data confidentiality and privacy.14 For example, data is encrypted prior to outsourcing to the cloud. However, this limits the searchability of the data, in the sense that healthcare providers have to decrypt the (potentially big) data prior to searching on the decrypted data, resulting in increases in time and costs for the data retrieval and diagnosis (e.g. download, decrypt, and search).15",https://doi.org/10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"End users can reserve different virtual environments through the VCL portal, with different privileges. For example, the admin privilege has more capability than normal users. When a user is authenticated, a status summary about his virtual images reservation is shown. By choosing New Reservation Tab from the menu, a user can select the suitable image for his need from a drop-down menu. After that, the Create Reservation button will reserve the image from the images chosen, where the user can arrange a reservation for a future time. The waiting time is less than one minute if a hardware server is already preloaded with the requested virtual image or up to 25 minutes if the virtual image has to be transferred to the least utilized server from the image library.",https://doi.org/10.1109/CCAA.2015.7148478,Virtual computing lab (VCL) open cloud deployment,6 July 2015,0
"The algorithm is experimented using real workload traces workload trace from NASA Ames iPSC/860 which is a popular real-world trace used for scheduling problems. The experimental results show that the proposed algorithm outperforms existing state-of-art heuristics Min-Max, Min-Min, MCT and FCFS with respect to Makespan, System Throughput and Degree of Imbalance. We can also observe a significant amount of improvements in the Makespan, Degree of Imbalance and System Throughput in each workload size of the traces used for the experimentation",https://doi.org/10.1109/SmartCloud49737.2020.00015,An Efficient Task Scheduling Algorithm using Total Resource Execution Time Aware Algorithm in Cloud Computing,27 November 2020,0
"Microservices, one of the Latest Architectural Trends in Software Engineering,1 can be Broadly Defined as the Design of Service-Oriented Software Using a Set of Small Services. These services are small applications that can be deployed independently, with a precise and hardened interface, and easily integrated. Microservices are supported by middleware for communication and a platform for flexible and low-cost deployment.",10.1109/MCC.2016.105,Challenges in Delivering Software in the Cloud as Microservices,11 November 2016,0
"However, despite the benefits brought by cloud storage services, critical security concerns in data outsourcing exist. One of the most important security concerns for users is data integrity—that is, whether their data remains intact on cloud servers.7 A cloud service provider might hide data loss incidents to maintain its reputation8 or discard data that's rarely accessed to save storage space, while claiming that no data loss has occurred. Moreover, an external adversary might distort users' data on cloud servers for financial or political reasons. Consequently, users require an efficient and secure verification method to ensure their data's integrity.",10.1109/MCC.2016.94,Cryptographic Public Verification of Data Integrity for Cloud Storage Systems,11 November 2016,0
"One could also leverage cloud computing to achieve faster and energy-efficient communications between sensing devices and the base stations, with a longer range. For example, processing, storage, and analysis of the sensing data can be securely outsourced to the cloud. In addition, the increasing miniaturization of hardware has allowed these tiny devices to perform more than just sensing, such as presenting themselves as a service (i.e. device as a service). Such an evolution (see Figure 1) where the cloud has a central role in the overall infrastructure for data processing, storage, and analysis, as well as visualization is also known as Internet of Things (IoT).2 Building a content gathering and processing network from distributed devices based on clouds presents a series of challenges, such as those relating to reliable content gathering, unreliable and heterogeneous sources, fast data delivery, real-time scheduling, cross-domain security, and cost efficiency.",10.1109/MCC.2017.30,Challenges of Connecting Edge and Cloud Computing: A Security and Forensic Perspective,26 April 2017,0
"Cloud databases provide MapReduce like frameworks for example Hadoop and Dryad that are designed for distributed processing of data-intensive tasks. They lack various features of modern DBMSs like bulk loading, indexing, updating, integrity and referential constraints etc.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"However, the use of SDN within public and private clouds as well as on the edge of clouds goes beyond its typical application. Indeed, this shift has the potential to turn the hardware-driven concept of networking into one that's more software-defined and on-demand.",10.1109/MCC.2016.62,Software-Defined Networks Meet Cloud Computing,4 July 2016,0
"The elasticity requirements can be related to cost, quality or both. The language does not support to deal with multi-tenancy. Copil et al. presented a framework called ADVISE, which advises elasticity controllers about the behavior of parts in cloud service to control overall service.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"Many formal definitions of cloud computing exist. The National Institute of Standards and Technology's internationally accepted definition calls for “resource pooling,” where the “provider's computing resources are pooled to serve multiple consumers using a multitenant model, with different physical and virtual resources dynamically assigned and reassigned according to consumer demand.“[1] It also calls for “rapid elasticity,” where “capabilities can be elastically provisioned and released, in some cases automatically, to scale rapidly outward and inward commensurate with demand.”",10.1109/MCC.2014.51,Containers and Cloud: From LXC to Docker to Kubernetes,30 September 2014,0
"Based on the proposed computational framework, it has been made very easy to develop various smart video surveillance applications on the top of it. In the following, we briefly describe several applications developed under such a programming paradigm.",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
"Probably public clouds either offering IaaS or those running today's Internet are the lowest cost (but not necessarily lowest price) solution and in aggregate are far more powerful than the systems used in science research. Of course all systems require a significant ecosystem with many people developing, testing and running software.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Scalability and resiliency are also important in the coffee shop. Similar to an elastic load balancer and elastic queue, the number of customers and coffee cups awaiting processing can determine the required number of workers, although provisioning takes longer",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"This type of architecture, a hybrid multicloud fog, is a hybrid of not just private and public, but of a broad spectrum of environments ranging from legacy architectures such as mainframes or non-virtualized systems; special-purpose systems such as high-performance computing; private clouds; colocation and interconnection facilities; and public clouds. It is also typically not a single cloud or just multiple clouds, but a true multicloud: multiple clouds that work together in an integrated fashion, for example, to support a given workflow or business process, as choices in a dynamic cloud marketplace, or where one cloud is used as the BC/DR environment for another cloud. Finally, it is a hybrid of private or public hyperscale data centers and more highly dispersed facilities, ranging from server closets to content delivery network nodes to home Internet of Things (IoT) gateways and microcells which might be deployed in unusual (for cloud) locations, such as network service provider regen huts or switching centers.",10.1109/MCC.2017.13,The Economics of the Hybrid Multicloud Fog,15 March 2017,0
A problem solving ontology approach to pricing cloud computing services has been described that forms part of broader ontology based approach for mapping user requirements to cloud computing services. A constrained problem domain of Hybrid Meta-Heuristics has been modeled by overlaying ontology over a general problem solving ontology.,https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"Perhaps the cloud's biggest limitation is that it might impair innovation. Implemented properly, ERP represents a significant source of competitive advantage, but if ERP becomes a commodity – the cloud model's central premise – it limits a company's ability to innovate.",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"The need for virtualization has been suggested, eco-efficiency have been seen as a major way for an institution to reduce ICTs operation cost. Changing institution's Traditional computing system towards high efficiency and energy aware computing will need to be examined according to institution strategy technology and infrastructure support point of view. Taking into account HLIT computing environment and required, we have proposed stages to be considered in moving into cloud. These stages create eco-cloud awareness and effective adoption. The stages start with strategic preparation, planning and design, implementation and finally optimization of cloud resources.",https://doi.org/10.1109/SCAT.2014.7055151,Road map towards eco-efficient cloud computing adoption in higher learning institutions in Tanzania,5 March 2015,0
"While CPU and RAM are mostly equivalently arranged on most cloud data centres, the storage units differ from local to remote (network attached) storage, with various hybrid technologies like distributed block object storage (e.g. CEPH).",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"The microservices-based approach is in contrast to the traditional “monolithic” development of applications, where each application is a single, autonomous unit. For example, in a client-server application, the server is a monolithic entity that handles HTTP requests, executes logic, and retrieves or updates its data. The problem with such monolithic architectures is that even a small modification of the application's logic requires the deployment of a new running version of the entire code base. A microservice architecture is lightweight and easily shipped and updated. Hence, it's ideal for engineering applications where we cannot fully anticipate functionalities in advance (for example, the types of devices that might one day access the application). Microservice architectures are a part of a larger shift in IT departments to-wards a DevOps culture, in which development and operations teams work closely together to support an application over its lifecycle, and go through a rapid or even continuous release cycle.",10.1109/MCC.2016.112,Open Issues in Scheduling Microservices in the Cloud,11 November 2016,0
Confidential data is thus encrypted before outsourcing to cloud thereby resulting in privacy protection. This outsourced data will be safe with a service provider while a few selected data can be shared with the other service providers with respect to the service level agreement.,https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"The high maintenance costs of private datacenters and disaster-recovery requirements are causing cloud architectures to go distributed. Virtualization is expanding outside a single datacenter for compute, network, storage, and devices. Resource-specialized clouds are becoming federated, evolving from centralized to fully distributed infrastructures across heterogeneous resources-a cloud-of-clouds-and away from the datacenter to the edge.",10.1109/MCC.2016.110,User-Centric Security and Dependability in the Clouds-of-Clouds,11 November 2016,0
"Existing work on container security focuses mainly on the relationship between the host and the container.2–​5 However, containers are now part of a complex ecosystem, which includes containers and various repositories and orchestrators, that is highly automated. In particular, container solutions embed automated deployment chains6 that are meant to speed up the code deployment processes. These chains are often composed of third-party elements running on different platforms provided by different providers, raising concerns about code integrity. This can cause multiple vulnerabilities that an adversary could exploit to penetrate the system.",10.1109/MCC.2016.100,To Docker or Not to Docker: A Security Perspective,11 November 2016,0
"It's intrinsically difficult to restrain the scope of discussion when tackling topics related to the Internet of Things. The idea that a relatively small number of communication and automation methods can allow simple control over real-world devices is compelling, and the power of this idea naturally leads one to gloss over the many difficulties that come with implementing it. It's good to look at some counterexamples, therefore, from the outset.",10.1109/MCC.2017.23,Standards at the Edge of the Cloud,26 April 2017,0
"How long does your function take to execute? This will be different on each platform where you run it, and different based on real-time congestion levels, noisy neighbors, and varying generations of hardware infrastructure and thus performance. To get a true estimate for cost analysis, you really need to run it on Lambda and get the numbers from there. Running on your own machine or on static compute will produce different results. It's important to get a handle on this number if you want a reliable estimate because increasing the compute time for each transaction can affect your billing significantly at high volume. Remember that each function call is a multiplier on your billable execution time.",https://doi.org/10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"Cloud computing provides organizations and individuals with a cost-effective utility, empowering businesses by delivering software and services over the Internet to a large user base. According to an IHS report, worldwide spending for cloud infrastructure and services reached an estimated174.2billionin2014,up20percentfrom145.2 billion in 2013.[1] However, because the cloud is an open platform, it's susceptible to malicious attacks of continuously evolving natures. Security of stored data, access management, data utilization management, and trust are among the primary security aspects in cloud comnutinv.",10.1109/MCC.2015.45,"Security and Privacy in Cloud Computing: Vision, Trends, and Challenges",2 June 2015,0
"In parallel with these developments, the Internet of Things (IoT) has emerged, with sensors embedded in everyday devices to facilitate automatic monitoring of data produced by humans or their environment.7 Cloud computing and IoT together offer new opportunities for wide usage of this data, enabling the development of new applications that can impact our daily lives.1, 8, 9 The development of applications using cloud resources becomes easier when we use scalable storage, which can increase capacity and performance by dynamically adding new storage nodes; the high bandwidth data transmission speed and real-time analysis makes it even more attractive.",10.1109/MCC.2016.128,Internet of Things Architecture for Enhanced Living Environments,30 December 2016,0
"Although public clouds benefit from economies of scale from massive and centralized data centers with high utilization, and continuous improvements in cost per unit of processing capacity from Moore's law, they're unlikely to be able to drop prices more than 15 percent annually over the long haul, barring some massive technology discontinuity such as free electric power or disruptive new computing paradigms. The simple reason is that even if CPUs were free, there would still be infrastructure capital expenditures, such as for data centers, and ongoing operating expenses, such as for power. These cost elements don't follow Moore's Law.",10.1109/MCC.2017.42,The Limits to Cloud Price Reduction,29 June 2017,0
"The disadvantage of OpenVZ is that all virtual servers have to get along with the kernel version the host runs on. However, because it doesn't have the characteristics of a true hypervisor, it is faster and more efficient than XEN, KVM and VMware.",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"Depending on the used hypervisor to split the physical resources in virtual resources, this management layer further utilises additional resources e.g. for emulation.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"The security problems of traditional system such as virus, worms, and the problems due to hackers are as such available, and work as serious security concerns to the cloud and lead to more serious consequences due to the multi-tenant nature of cloud.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"Cooperation as a Service or CaaS allows the driver to access the application or services of their own interest and use the services such as traffic information, weather or road condition etc. by using minimal infrastructure.",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"Cloud computing is definitely a type of computing paradigm/architecture that will remain for a long time to come. In the near future, cloud computing can emerge in various directions. The main problem with the cloud is about its security model, although it has various features to provide it is still not promising when it comes to security. Implementation of each and every aspect which is discussed in this paper will definitely make the cloud more promising",https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"Amazon web services is used as an example of pricing of cloud-services [8]. Services are available from a number of vendors such as Google, Microsoft and others. Amazon web services will be used to develop a prototype pricing ontology that could be developed to represent generic pricing knowledge representation for pricing of any cloud service.",https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"However, as with many things, the devil is in the details and the economic benefits of serverless computing heavily depend on the execution behavior and volumes of the application workloads. In the same way that pennies per day can add up to thousands of dollars eventually, low “per hit” prices can not only add up as transaction volumes increase, but can make serverless economics unattractive relative to what have now become more traditional approaches, such as virtual machines or even dedicated hardware.",10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"As they age, many older adults have significant challenges in managing chronic health conditions and maintaining physical functions. early detection of health problems can help elders maintain good health and function by allowing timely health interventions. Traditional approaches of healthcare take place in medical centers or clinics, which require availability of transportation from the home. This is, however, a disadvantage for rural and sometimes suburban areas where travel distances can be very long. With emerging digital technology and multisensor techniques, new approaches for ongoing health assessment are emerging to realize enhanced living environments (ELEs) for eldercare.",10.1109/MCC.2017.46,Toward an ElderCare Living Lab for Sensor-Based Health Assessment and Physical Therapy,29 June 2017,0
"This means that same cloud can be shared among multiple users, so there is reduce in time and money. It is an important factor in the formation of Green Cloud.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"Today, we live in a digital universe in which information and technology are not only around us but also play important roles in dictating the quality of our lives. As we delve deeper into this digital universe, we're witnessing explosive growth in the variety, velocity, and volume of data[1],[2] being transmitted over the Internet. A zetabyte of data passed through the Internet in the past year; IDC predicts that this digital universe will explode to an unimaginable eight Zbytes by 2015. These data are and will be generated mainly from Internet search, social media, mobile devices, the Internet of Things, business transactions, next-generation radio astronomy telescopes, high-energy physics synchrotron, and content distribution. Government and business organizations are now overflowing with data, easily aggregating to terabytes or even petabytes of information.",10.1109/MCC.2014.22,Streaming Big Data Processing in Datacenter Clouds,10 July 2014,0
"Although VMs and containers are both virtu-alization techniques, they solve different problems. Containers are tools for delivering software-that is, they have a platform-as-a-service (PaaS) focus-in a portable way aiming at greater interoperability while still utilizing OS virtualization principles.[1] VMs, on the other hand, are about hardware allocation and management (machines that can be turned on/off and be provisioned)-that is, there's an infrastructure-as-a-service (IaaS) focus on hardware virtualization. Containers can be used as a replacement for VMs where the allocation of hard-ware resources is done through containers by componentizing workloads in between clouds.",10.1109/MCC.2015.51,Containerization and the PaaS Cloud,15 July 2015,0
The analysis of traditional digital forensic and cloud forensics is slightly different from the digital forensic analysis of the virtual machine in the cloud environment. As per the study cloud forensic as “the steps of applying all the digital forensic phases over the deployment model at cloud platform”.,https://doi.org/10.1109/I2CT.2018.8529806,Approaches for Detection of Digital Evidence in Cloud Computing Environment,11 November 2018,0
"Availability is an influential factor in relation to an organisation's decision to adopt cloud computing. Cloud computing offers resources online, meaning that the consumer can access the cloud from anywhere and at any time. This means the system needs to function properly and must be available to use whenever it is requested.",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"To ensure data privacy, existing research proposes to outsource only encrypted data to CSPs. However, the same or different users could save duplicated data under different encryption schemes at the cloud. Although cloud storage space is huge, this kind of duplication wastes networking resources, consumes excess power, and complicates data management. Thus, saving storage is becoming a crucial task for CSPs. Deduplication can achieve high space and cost savings, reducing up to 90 to 95 percent of storage needs for backup applications (http://opendedup.org) and up to 68 percent in standard file systems.1 Obviously, the savings, which can be passed back directly or indirectly to cloud users, are significant to the economics of cloud business.",10.1109/MCC.2016.29,Encrypted Data Management with Deduplication in Cloud Computing,25 May 2016,0
"Some machine learning like topic modeling (LDA), clustering, deep learning, dimension reduction, graph algorithms involve Map-Collective or Map-Point to Point iterative structure and benefit from HPC.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Through redundancy, the application's availability can increase. With environment-based availability, the provider does not ensure the availability of individual resources but only of a set of resources or an interface via which the customer or application can provision replacement resources.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"When the IoT smart devices share data with other devices, potential security issues arise such as data leakage, modification, integrity, and unauthorized access.5 Hence, it is essential that such shared data be ensured confidentiality, integrity, and access control while sharing at the edge. Furthermore, a secure data-searching technique is needed to search and retrieve the shared data by authorized devices.",10.1109/MCC.2017.9,Secure Data Sharing and Searching at the Edge of Cloud-Assisted Internet of Things,15 March 2017,0
It means that the cloud provider should get separate consent from a user before collecting the data and before processing that data and customers should have the freedom to withdraw their consent easily and without any harm in terms of efforts and funds.,https://doi.org/10.1109/CSNT.2015.141,Efficient Framework Approach to Extract Privacy Issues in Cloud Computing,1 October 2015,0
"The vehicles embedded with sensing devices, cameras, GPS devices etc. in onboard unit. If there is any malicious activity on the road then the vehicle to nearby vehicle and to the vehicular cloud regarding speed, location and direction of the victim. It also provide the information regarding road hazard ahead, road conditions, speed breakers, weather conditions etc.",https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"While collecting metrics about memory access for running applications like virtual machines or containers is usually due to performance degradation not possible, the resulting shortcomings like page faults or page errors are collectable.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"In the suggested system, multifactor authentication for user login to the cloud, homomorphic encryption for data storage with integrity verification, and integrity verification have all been implemented effectively. To illustrate the efficacy of the proposed strategy, an experimental investigation was conducted.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
Cloud controller constructs elastic dependency graph in runtime with a high-level view of metrics in service user perspective as well as cloud controller perspective. This graph helps in resolving conflicts between elasticity requirements of same and different abstraction levels too.,https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"While data integrity and distributed storage/access of blockchain offer opportunities for healthcare data management, these same features also pose challenges that need further study.21",10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"The workload the application experiences substantially affects its development after decomposition. Logical application components are commonly grouped and assigned to multiple tiers - for example, to multiple virtual servers.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"For profiling a virtual workload, it is further important to subtract the hardware specifics from the monitoring data, to generate a comparable profile for heterogeneous physical set ups.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"The Internet of Things (IoT) represents a paradigm for a smart world in which ubiquitous and pervasive computing and communication occur over a global network of heterogeneous and interconnected entities. The key enabling technologies for IoT are wireless sensor networks (WSN), machine-to-machine interfaces (M2M), RFID, and embedded sensor and actuator designs that enable sensing, command/control interaction, data communication/transfer, and limited analytical services.’ The main application areas that are being disrupted through the enabling of IoT include power systems and smart grid, e-health and assisted living systems, and large-scale industrial and environmental monitoring applications.1, 2 With the advent of constant Internet connectivity coupled with ubiquitous sensing, these applications are now producing vast amounts of data that have to be communicated, stored, processed, and analyzed in a secure and efficient manner to reach the targeted levels of smart functionality envisioned through the IoT.",10.1109/MCC.2016.30,Secure Data Analytics for Cloud-Integrated Internet of Things Applications,25 May 2016,0
"What is a Service, and when is a Service a Microservice? Good question. When using a service, we leverage a remote method or behavior versus simply extracting or publishing information to a remote system. Moreover, we typically abstract this remote service into another application known as a composite application, which is usually made up of more than one service.",10.1109/MCC.2016.114,Practical Use of Microservices in Moving Workloads to the Cloud,11 November 2016,0
"While there are several public clouds on the market, Google Apps (example of SaaS, includes Google Mail, Docs, Sites, Calendar, etc), Google App Engine [6] (example of PaaS, provides elastic platform for Java and Python applications) and Amazon EC2 (example of IaaS) are probably most known and widely used.",https://doi.org/10.1109/CCGRID.2010.56,SciCloud: Scientific Computing on the Cloud,24 June 2010,0
"deep learning doesn't exhibit massive parallelism due to stochastic gradient descent using small mini-batches of training data, but deep learning does use small accelerator enhanced HPC clusters. If this were to change, this would have important implications for Deep learning on HPC platforms.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"With node-based availability, the customer knows the availability of resources such as servers or middle-ware deployments that host the application components as an uptime percentage.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"The technologies used in cloud hide the internal details of technologies used for implementation of services and there management. It is the duty of provider to provide the security to the data, as the user can't secure its data at the level of hardware.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"In order to capitalize on the emerging architectural advancements and enhance the functionality of centralized data centers, it is imperative to identify applications that exhibit higher energy efficiency when deployed on nano servers. Consequently, these identified applications can be effectively executed on this platform. Furthermore, the utilization of the nano platform for running certain applications not only contributes to energy conservation but also presents an opportunity to reduce the energy consumption within data centers dedicated to serving these applications.",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"Components assigned to a single tier are more tightly integrated than those assigned to different tiers. Component interaction between tiers thus commonly requires some serialization and deserialization of data and interaction via a network, whereas communication within a tier can omit these steps, resulting in higher performance.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"The collection of resource utilisation for each virtual machine or container, besides the usually considered metrics have to gain focus (cf. Table I). For CPU, the CPU scheduler statistics are important to consider the CPU cycles stolen by other load due to overbooking.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"A given sensor network1 consists of tiny sensing devices deployed within an area of interest, such as a forest, within a building or along a motor-way, to measure certain environmental factors, such as temperature, humidity, vibrations, pollution and so on. Such devices are typically only capable of computing simple tasks on the collected data, such as simple aggregation and filtering operations, and sending the collected information to base stations using short-range wireless communications. These base stations are more powerful computing devices, with a rechargeable battery and a stable wired connection to a centralized remote server in charge of collecting all data, performing complex analytics, and presenting the results using visualization (see Figure 1).",10.1109/MCC.2017.30,Challenges of Connecting Edge and Cloud Computing: A Security and Forensic Perspective,26 April 2017,0
"With the rise of Internet of Things (IoT) technology, it is anticipated that large-scale sensor-based systems will permeate society, calling for novel methodologies to design, test, and operate these systems. IoT relies on networked, interconnected physical devices that often feature computational capabilities.1 The sheer number of these interconnected devices plays a key role in the IoT revolution. For example, Gartner research predicts that IoT will connect up to 50 to 100 billion devices by 2020.2 It is estimated that IoT will generate ∼1.7 trillion US dollars by this time, with an approximate growth rate of 20% year over year.",10.1109/MCC.2017.18,Modelling and Simulation Challenges in Internet of Things,15 March 2017,0
"Cloud storage services enable users to outsource their data to cloud servers and access that data remotely over the Internet. These services give users an efficient and flexible way to manage their data without deploying and maintaining local storage devices and services.1–​4 Specifically, users can process their data on their PCs, outsource the processed data to cloud servers, and use the data on other devices (for example, mobile phones). The great convenience provided by such services is leading to a growing number of cloud storage providers.",10.1109/MCC.2016.94,Cryptographic Public Verification of Data Integrity for Cloud Storage Systems,11 November 2016,0
"There are several ways in which computational capability and data storage facilities are provided to users. Users search for resources based on a variety of characteristics and provide access to large pool of data and computational resources through a variety of interfaces [9], [10]. Cloud Database Management system (CDBMS) is a distributed database that delivers computing as a service instead of product.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"There have been several concerted efforts by cloud service providers to prevent their services from being criminally exploited. For example, Dropbox has implemented a child abuse material detection software, whose details are not publically available, which allows searching within the files stored on Dropbox to identify breaches of the Terms of Use and Acceptable Use Policy. Similarly, Microsoft's PhotoDNA is designed to identify child abuse materials from the files stored by companies on their servers, and used in its cloud storage product.",10.1109/MCC.2017.39,Evidence and Forensics in the Cloud: Challenges and Future Research Directions,29 June 2017,0
"Distributed denial of service (DDoS) attacks have been a nightmare for enterprise operations, availability, and security. After the emergence of modern computing paradigms like cloud computing, these attacks saw major changes in scale, methods, aims, and targets. The advantages provided by cloud computing are available to both victims and the attackers. This has made the DDoS arms race interesting and quite complex.1 In 2004, the peak attack bandwidth was just 8 gigabits per second (Gbps). However, according to the report by Arbor Networks, there were much heavier DDoS attacks with attack bandwidths of more than 500 Gbps in 2015.2 The target services of DDoS attacks lie in each sector influenced by IT infrastructure, whether its government, banking, or media industry.",10.1109/MCC.2017.14,"Combating DDoS Attacks in the Cloud: Requirements, Trends, and Future Directions",15 March 2017,0
"Cloud computing adoption in HLIT brings many security, policy, technological and economic challenges that need to be solved. This challenges need to be addressed before cloud adoption to an institution. Clear design and use of well-known best procedures, and practices is very important to ensure cost effectiveness of cloud operations.",https://doi.org/10.1109/SCAT.2014.7055151,Road map towards eco-efficient cloud computing adoption in higher learning institutions in Tanzania,5 March 2015,0
"Hybrid cloud is a mixture of private and public cloud models that concentrate on the drawbacks of both models. In a hybrid cloud, one part of service infrastructure run in private cloud while another part runs in public cloud. Particularly, it provides tighter control and security over application data compared to public clouds, while still facilitating on-demand service expansion and contraction.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"The cloud computing paradigm provides a vision of IT where resources are consumed and leased on demand and on a pay-per-use basis. The immense benefits of the cloud in terms of flexibility, resource consumption, and simplified management, make it the first choice of users and industries for deploying their IT architecture, and for service provisioning and procurement. However, the benefits of the cloud are not free. Cloud computing raises several concerns due to lack of trust and transparency, while customers need guarantees on cloud services nonfunctional properties (such as security, privacy).1 Unfortunately, many cloud service providers still fail to provide complete transparency regarding the security and privacy compliance measures they have in place to protect their customers' sensitive information and intellectual property. Of course, cloud providers have deployed security controls to prevent attacks and unauthorized activities. Information about such controls' operation and their effectiveness is rarely made available to customers. Therefore, cloud users do not have access to all security intelligence and log information on potential threat vectors, which impairs their ability to estimate risks.",10.1109/MCC.2017.51,Towards Transparent and Trustworthy Cloud,29 June 2017,0
"In standard cloud computing, dedicated hardware is replaced by dynamically allocated, pay-per-use resources, such as virtual servers. Although called “pay-per-use,” these resources are typically billed based on allocation, not on actual use, potentially leading to a customer paying more than necessary. In “serverless,” no resources are typically allocated or chargeable until a function is called. It's like the difference between a rental car and a taxi: you will be charged for the rental car even if you park it for a week, unlike a taxi. Moreover, some cloud providers are offering seemingly massive amounts of serverless computing at no charge. This holds the promise of the most efficient processing possible—for free or at least what seem to be attractive prices. Moreover, serverless fits with the modern approach to application construction—composing microservices rather than building hard-to-manage and scale monolithic applications.",10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"Consolidation can be defined as establishing multiple data centers for the applications on one server using virtual techniques. It also administers balancing burden on nodes and decease usage of electricity and provides high available servers to users. Many researchers gave the idea about Dynamic Voltage Frequency Scaling consolidation, gateway based techniques on IaaS platform, living issues of consolidating imaginary servers.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"This work can be focused in two major tracks in future and are cloud computing in terms of minimal economy and real-time end user objectives. The second scope can be achieved in proper business plans and the decisions of IT Management to follow the right path. To design this Innovation Diffusion Theory (IDT) will be suitable tools that contributes to understanding the adoption process of organizations. To the overall, the privacy and security concerns defined here must be discovered more functionally through the field research that investigates the perceptions of organizations after adopting cloud computing and how they evaluate such experience",https://doi.org/10.1109/I-SMAC.2017.8058278,Research opportunities and challenges of security concerns associated with big data in cloud computing,5 October 2017,0
"Physical deployment is composed of two workstations: one is called the management node (process resources provisioning and user activity), and the other is called the computation node (carries the VMs, does computation tasks for the processing engine of the hypervisor).",https://doi.org/10.1109/CCAA.2015.7148478,Virtual computing lab (VCL) open cloud deployment,6 July 2015,0
"In a server farm with thousands of servers, the amount of resource statistics sums up to a reasonable data size quickly. Existing monitoring solutions typically measure resource utilization values like CPU counters or disk operation counters periodically and transmit them over network with push or pull to central monitoring data sinks.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Cloud computing offers a new way to deliver services by rearranging resources over the Internet and providing them to users on demand. It plays an important role in supporting data storage, processing, and management in the Internet of Things (IoT). Various cloud service providers (CSPs) offer huge volumes of storage to maintain and manage IoT data, which can include videos, photos, and personal health records. These CSPs provide desirable service properties, such as scalability, elasticity, fault tolerance, and pay per use. Thus, cloud computing has become a promising service paradigm to support IoT applications and IoT system deployment.",10.1109/MCC.2016.29,Encrypted Data Management with Deduplication in Cloud Computing,25 May 2016,0
Xen is a Virtual Machine Monitor (VMM) originally developed at the University of Cambridge. It represents a popular target for scientific research. It requires the guest OSs to be modified as it is considered a para-virtualization solution. Xen supports live migration.,https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created applications using programming languages and tools supported by the provider (e.g., java, python,. Net).",https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"Cloud computing provides organizations and individuals with a cost-effective utility, empowering businesses by delivering software and services over the Internet to a large user base. According to an IHS report, worldwide spending for cloud infrastructure and services reached an estimated",10.1109/MCC.2015.45,"Security and Privacy in Cloud Computing: Vision, Trends, and Challenges",2 June 2015,0
"Sensor networks offer economically viable solutions for a variety of applications. For example, current implementations monitor factory instrumentation, pollution levels, free- way traffic, and the structural integrity of buildings.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Environment-based availability. A cloud provider guarantees that the environment hosting individual nodes, such as virtual servers or hosted application components, will be available.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Simulations tend to need high precision and very accurate results (partly because of differential operators), however, data-intensive problems often don't need high accuracy as seen in trend to low precision (16 or 32 bit) deep learning networks, as there are no derivatives and the data has inevitable errors.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Community cloud allows sharing of computing infrastructure in between organizations of the same society. For example all administrative organization within Haryana, India may share computing infrastructure on the cloud to manage data related to general public residing in India.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"In [14], the authors intended to combine automatic license plate recognition technology and geographic information of street surveillance cameras to recover the trajectory of a vehicle given its license plate number. We have implemented this concept on the proposed PaaS. Ideally, such system may greatly simplify and accelerate the process of investigating certain security problems, e.g. searching for stolen cars. However, its success is also heavily dependent on some factors, such as the density and image quality offered by the cameras.",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
The problem solving ontology provides a set of off the shelf concepts and ontological components that have been designed and refined over a number of years. The pricing process can be seen as a problem solving exercise and thus fits into the problem solving ontology.,https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"Zaghdoudi et al. proposed a mobile cloud architecture based on MANET (Mobile Ad hoc Network) to dynamically manage mobile nodes [15], allowing mobile nodes to partition and execute computationally intensive tasks, but this architecture needed to be further lightweight.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"In a cloud environment, tiers can commonly scale independently. Therefore, an IT architect should consider the workload that components experience to ensure that those within a tier experience similar workload when logical components are summarized to tiers.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Modern data sinks are time series database (TSDB) systems like InfluxDB or Prometheus, which are specialized for horizontal scalability and to manage time based monitoring data.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"A microservices-based cloud application involves the interoperation of multiple microservices, each developed separately, that can be deployed, updated, and redeployed independently without compromising the application's ecosystem's integrity. The ability to independently update and redeploy the code base of one or more microservices increases applications' scalability, portability, updatability, and availability, but at the cost of expensive remote calls (instead of in-process calls) and increased overhead for cross-component synchronization.",10.1109/MCC.2016.112,Open Issues in Scheduling Microservices in the Cloud,11 November 2016,0
"With the increasing number and availability of smart devices, data sharing is offered within cloud-assisted IoT applications. The data are of little use if the smart devices do not share data with other devices. Data sharing at the edge allows smart devices to share data with lower latency and have fast data access and higher bandwidth. The next generation wireless communications technology (5G) will greatly depend on such solutions where massive IoT smart devices are interconnected with high data rates at ultralow latency. Yi et al. evaluate a performance comparison of the cloud and edge/fog server in terms of latency and bandwidth.4 The results show that when using fog and cloud server, the latencies are 1.416 and 17.989 ms, respectively, and the uplink/downlink bandwidth for fog and cloud are 83.723/101.918 and 1.785/1.746 Mbps, respectively.",10.1109/MCC.2017.9,Secure Data Sharing and Searching at the Edge of Cloud-Assisted Internet of Things,15 March 2017,0
"The high maintenance costs of private datacenters and disaster-recovery requirements are causing cloud architectures to go distributed. Virtualization is expanding outside a single datacenter for compute, network, storage, and devices. Resource-specialized clouds are becoming federated, evolving from centralized to fully distributed infrastructures across heterogeneous resources-a cloud-of-clouds-and away from the datacenter to the edge.",10.1109/MCC.2016.110,User-Centric Security and Dependability in the Clouds-of-Clouds,11 November 2016,0
"Cloud computing is inherently rooted in virtualization technologies. Recently, new lightweight virtualization technologies such as containers have become increasingly popular and are nowadays an essential part of cloud offerings. Containers also tightly integrate into the host operating system, reducing the software overhead imposed by virtual machines (VMs).1 However, this tighter integration also increases the attack surface, raising security concerns.",10.1109/MCC.2016.100,To Docker or Not to Docker: A Security Perspective,11 November 2016,0
"Cloud computing assumes communication among participating components. The boundary between the collection of these components and the world of humans and devices has acquired a set of names that encompass different concepts, including fog computing (implying a highly diffuse, distributed cloud), edge computing (implying a clean boundary between connected and non-connected devices), and the Internet of Things (IoT), These concepts all assume a degree of connectedness that requires development of standards.",10.1109/MCC.2017.23,Standards at the Edge of the Cloud,26 April 2017,0
"As they age, many older adults have significant challenges in managing chronic health conditions and maintaining physical functions. early detection of health problems can help elders maintain good health and function by allowing timely health interventions. Traditional approaches of healthcare take place in medical centers or clinics, which require availability of transportation from the home. This is, however, a disadvantage for rural and sometimes suburban areas where travel distances can be very long. With emerging digital technology and multisensor techniques, new approaches for ongoing health assessment are emerging to realize enhanced living environments (ELEs) for eldercare.",10.1109/MCC.2017.46,Toward an ElderCare Living Lab for Sensor-Based Health Assessment and Physical Therapy,29 June 2017,0
"Various forms of public cloud providers and software as a service companies also offer a development platform as a service. In general, the public cloud has significant limitations when used to construct business applications. These limitations are challenging enough that the migration to the cloud will primarily consist of a private cloud infrastructure that bears little resemblance to the public cloud.",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"Welcome to the inaugural Blue Skies column of IEEE's flagship cloud computing magazine. This column intends to provide an in-depth analysis of the most recent and influential research related to cloud technologies and innovations, focusing on streaming big data processing in datacenter clouds.",10.1109/MCC.2014.22,Streaming Big Data Processing in Datacenter Clouds,10 July 2014,0
The increasing power and complexity of modern HPC systems as exemplified by those involved in drive to build exascale class machines.,https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Node-based availability. A cloud provider guarantees that individual nodes are available, such as individual virtual servers, middle-ware components, or hosted application components.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"The cloud relies on virtualization techniques to achieve elasticity of large-scale shared resources. Virtual machines (VMs) have been the backbone at the infrastructure layer providing virtualized operating systems (OSs). Containers are a similar but more lightweight virtualization concept; they're less resource and time-consuming, thus they've been suggested as a solution for more interoperable application packaging in the cloud.",10.1109/MCC.2015.51,Containerization and the PaaS Cloud,15 July 2015,0
"The data stored in the cloud can be accessed and manipulated by using only a password. So, the attacker can at any time track our account and modify the sensitive data which becomes unworthy.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"In order to deal with these challenges, many have suggested the notion of off-chain storage of data, where data is kept outside of blockchain in a conventional or a distributed database, but the hashes of the data are stored in the blockchain. This is said to be the best of both worlds, as healthcare data is stored off-chain and may be secured, corrected, and erased as appropriate. At the same time, immutable hashes of the healthcare data are stored on-chain for checking the authenticity and accuracy of the off-chain medical records.",10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
In case of cloud computing the aspect of security is take care of with the help of keys. Therefore key of resources and data related to privacy are very important for use of the cloud by the user.,https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"The economics of computing in general and clouds in particular are complex, nuanced, and multi-dimensional. One can select solutions based on unit cost; total cost; revenue; profit; availability; time to market; time to value; flexibility and agility to respond to shifting market, customer, and competitive conditions; support for innovation; corporate strategy alignment; reciprocity; and more. These are just the rational factors. In addition, people often make decisions based on unique human quirks: cognitive biases and anomalies, heuristics, and other behavioral economic and human motivational factors. Adding to the decision-making challenge is the stochastic behavior of complex systems including computing resources and customer demand,3 and selecting a valid planning / financial horizon.",10.1109/MCC.2017.13,The Economics of the Hybrid Multicloud Fog,15 March 2017,0
"Amazon's commitment model is similar to the approach taken in Bhargava and Sundaresan (above). An interesting commitment model recently introduced are spot instances which provide an auction for cloud resources, which relates to the work of Martin et al [9].",https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"Given the limitations of existing SDN technology, building a RAN virtualization is difficult. Because SDNs adopt forwarding rules as the basic control unit to manage network traffic, the number of rules increases dramatically after network virtualization.6 If the rule space isn't large enough for processing new packets, network devices must communicate to the controller, which leads to much longer latency than direct processing.7 Although the additional latency has little influence on the overall performance, it will harm the quality of service (QoS), especially for some latency-sensitive applications (such as voice over IP and cloud gaming). Thus, in our RAN virtualization framework, we seek to both assign limited rule space to maximize the number of SIoT group vRANs and to satisfy the latency requirement. We also propose an efficient allocation algorithm, which we evaluate through simulation.",10.1109/MCC.2015.114,Radio Access Network Virtualization for the Social Internet of Things,2 February 2016,0
"The data collection has to address the main challenges overbooking, hardware independence and application specific metrics.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"The increasing use and sophistication of commercial and open cloud infrastructure (that can be used as IaaS, PaaS, SaaS, FaaS etc.)",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
IT resources with a utilization that grows or shrinks constantly over time experience continuously changing workload.,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
Elastic queue. The number of accesses via messaging lets the application adjust the number of required application component instances.,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Cloud computing provides a means to store user's sensitive data on cloud servers available in diverse insecure domains. It is necessary to understand and address different security issues in cloud environment, in order to keep the users data confidential and protect it against any unauthorized access in cloud environment. The important aspects of cloud security include proper authentication, strong encryption technique, and prevention of data loss.",https://doi.org/10.1109/I-SMAC47947.2019.9032545,"A Survey of Cloud Computing Security Challenges, Issues and their Countermeasures",12 March 2020,0
"As IT delivery methods meet the demand for the use of cloud services, communicative devices and employee-owned devices, new software vulnerabilities will be introduced, and financially motivated attackers will develop innovative attack paths.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
Sensor Capture Viewing Each sensor support package will implement an Android Activity that will provide an interface to view a sample capture from the specific sensor.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Also, it is able to manage unpredictable request patterns to scale resources according to change in resource requirement. This platform is estimating the required amount of resources correctly and providing the additional resources for SLA violations in the transient time.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"The above examples demonstrate the rise of big data applications, in which data has grown unre-strainedly. Conventional data processing technologies are now unable to process this data within a tolerable elapsed time. Such applications generate datasets that don't fit the data processing model frameworks of traditional relational databases (such as Oracle, MySQL, and DB2) and data mining (such as Microsoft Excel, Matlab, and R). Relational databases operate on archived data in response to queries such as “commit a credit card transaction” (as in e-commerce). That is, the data processing technologies are designed to maintain an efficient and fault-tolerant collection of data that's accessed and aggregated only when users issue a query or transaction request (and thus the data must be archived prior to processing).",10.1109/MCC.2014.22,Streaming Big Data Processing in Datacenter Clouds,10 July 2014,0
"WSN's is a specific technology that helps to create Smart space (smart cities, smart grid, smart building, etc.) [3], [15]. The aim is to create a distributed network of intelligent sensor nodes, which can measure many parameters for a more efficient management of the city.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"By the study of the past papers it is been concluded that we have discussed about the Green Cloud computing, energy saving measures, cloud computing and its harmful effects on the nature because the use of IT resources inefficiently. We also discussed about PUE, DCiE methods, GCA architecture and reviewed the Consolidation methods of servers.",https://doi.org/10.1109/ICICICT54557.2022.9917654,Energy Savings using Green Cloud Computing,18 October 2022,0
"The combination of new vulnerabilities and more targeted attacks will lead to continued growth in bottom -line financial impact because of successful cyber-attacks. Cyber-attacks against mobile platforms, especially smartphones, grew in 2010 and continuing with the subsequent years according to the recent Threat Quarterly Report published by the Threat IT Labs.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
The increasing functionality and use of Big Data software systems in conjunction with HPC.,https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Depending on the size of a data centre, one or many servers are required in addition only for hosting the monitoring infrastructure.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"In the coffee shop, the user group generates periodic workload: peaks occur in the morning when customers start their day, and in the afternoon when school is out. Because the coffee shop in our example has only one user group, all components experience this workload.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"V-BOINC sends these lightweight VirtualBox virtual machines from a V-BOINC Server to volunteer BOINC hosts when instructed by the host's installed modified BOINC client, called the V-BOINC Client. A regular BOINC client within the virtual machine is used to download a BOINC project's task.",https://doi.org/10.1109/CLOUD.2015.153,Ad Hoc Cloud Computing,20 August 2015,0
"After cloud computing have been adopted it is necessary to ensure optimal cost of resources/infrastructure. Review on power usage and the security issues associated with cloud computing will help in creating trust of cloud services to cloud users. In addition, optimization of cloud services will lower operation expenses of ICT facilities in higher learning institutions. This can be done through activities such as architectural reviews, security audit, Cost reduction exercises, process improvement, and tool customization [6], [5]",https://doi.org/10.1109/SCAT.2014.7055151,Road map towards eco-efficient cloud computing adoption in higher learning institutions in Tanzania,5 March 2015,0
Elastic load balancer. The number of synchronous accesses to an elastically scaled-out application determines the number of required application component instances.,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"The use of Cloud computing can provide substantial reductions in infrastructure expenses; nevertheless, it is important to note that this transition does result in increased costs associated with data communication. Specifically, the expenses incurred by reassigning the information of the organization to and from public communal cloud platforms are elevated.",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"Converting raw measurements also allows for less compute intensive handling in any kind of follow up analysis. Having a statistically meaningful profile allows direct comparison for alerting, or predictions for resource allocation decisions. The conversion does not have to take place during the analysis but when resource utilisation is changing at its source.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Data loss can occur if the cloud service provider accidently deletes the data or an attacker steals or modifies it. This can be solved, if any backup is used for all the data stored in it.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"Cloud computing isn't simply a matter of adding an infinite number of servers. Some problems and processes can't be solved simply by adding more nodes – they require different architectures of processing, memory, and storage.",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"A software-defined network (SDN)-enabled mobile or wireless network is one possible solution for combining the management of base stations and access networks with the decoupled control and data plancs.5 In an SDN-enabled network, all devices are managed by a centralized controller, and network operators can assign network virtualization strategies to the controller instead of different devices. Meanwhile, with their flexible control semantics, SDNs can provide fine-grained network control for each user in the same network. Here, we propose a framework that provides a vRAN over a single physical SDN-enabled RAN infrastructure (see the sidebar for some related work in this area).",10.1109/MCC.2015.114,Radio Access Network Virtualization for the Social Internet of Things,2 February 2016,0
The Honey bee foraging algorithm performs the work in different phases while creation of virtual images. The forage bees will search for the suitable image portion in the neighborhood and the scout bees will bring the found portion from the location indicated by the forage bees.,https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"WSNs provide unique opportunities of interaction between computing devices and their environment. The adhoc nature and wireless vulnerability make WSN a soft target for security attacks. In order to understand the security aspects of WSN in context of smart environment, we provide a brief description of the different attacks, existing behavior around the sensors and then present the possible solutions",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
Elasticity manager. The utilization of IT resources hosting an application determines the number of required application component instances.,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"The three primary microscopic architecture are: (i) Continuation of X86 systems, (ii) Many core systems (e.g., KNL) and (iii) non-traditional architectures (e.g., GPU, FPGA) etc.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Another option is Lambda@Edge, which has a higher per hit charge and no free tier, but it also rounds up to 50ms instead of 100ms, so when you run a cost analysis for your function, it's worth looking at both options to see which is more appropriate for your situation.",https://doi.org/10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"In IT applications, we often find a similar impact from workload, where input complexity is similar for all requests, but request handling in the back end has higher complexity.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"To limit the in best case linear growth of collected statistics, TSDBs aggregate and reduce older measurements to store only high resolution time series for the most recent values.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"One of the major characteristics of cloud computing is its capability of acquiring and releasing resources on-demand. The purpose of a service provider is to assign and de-allocate resources from the cloud to satisfy its service agreement. However, it is not clear how a service provider can handle this challenge.",https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"The cloud computing paradigm provides a vision of IT where resources are consumed and leased on demand and on a pay-per-use basis. The immense benefits of the cloud in terms of flexibility, resource consumption, and simplified management, make it the first choice of users and industries for deploying their IT architecture, and for service provisioning and procurement. However, the benefits of the cloud are not free. Cloud computing raises several concerns due to lack of trust and transparency, while customers need guarantees on cloud services nonfunctional properties (such as security, privacy).1 Unfortunately, many cloud service providers still fail to provide complete transparency regarding the security and privacy compliance measures they have in place to protect their customers' sensitive information and intellectual property. Of course, cloud providers have deployed security controls to prevent attacks and unauthorized activities. Information about such controls' operation and their effectiveness is rarely made available to customers. Therefore, cloud users do not have access to all security intelligence and log information on potential threat vectors, which impairs their ability to estimate risks.",10.1109/MCC.2017.51,Towards Transparent and Trustworthy Cloud,29 June 2017,0
"Although it is popular with companies and private users, cloud computing can be abused or targeted by criminals. This can range from stealing personal information stored and outsourced to the cloud, to frauds that are more sophisticated, and to attacks that are disruptive, such as compromising a company's day-to-day operations. Cloud storage services can also be abused by criminals, who use it to store and hide incriminating and illegal materials or to distribute copyright materials.",10.1109/MCC.2017.39,Evidence and Forensics in the Cloud: Challenges and Future Research Directions,29 June 2017,0
"Distributed denial of service (DDoS) attacks have been a nightmare for enterprise operations, availability, and security. After the emergence of modern computing paradigms like cloud computing, these attacks saw major changes in scale, methods, aims, and targets. The advantages provided by cloud computing are available to both victims and the attackers. This has made the DDoS arms race interesting and quite complex.1 In 2004, the peak attack bandwidth was just 8 gigabits per second (Gbps). However, according to the report by Arbor Networks, there were much heavier DDoS attacks with attack bandwidths of more than 500 Gbps in 2015.2 The target services of DDoS attacks lie in each sector influenced by IT infrastructure, whether its government, banking, or media industry.",10.1109/MCC.2017.14,"Combating DDoS Attacks in the Cloud: Requirements, Trends, and Future Directions",15 March 2017,0
"CorradoFederici has developed a Cloud Data Imager (CDI) library, which provides the facility of browsing folders and their files with metadata of cloud storage service [13]. He has built desktop based application that facilitates with the folder listing of showing the present, shared and deleted contents",https://doi.org/10.1109/I2CT.2018.8529806,Approaches for Detection of Digital Evidence in Cloud Computing Environment,11 November 2018,0
"Generate resource profiles instead of saving the raw measurements. These profiles should be designed for non-linear scalability with respect to time and amount of resources, but should compress the raw data without loosing meaningful information.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Maintenance of large surveillance camera network is important in order to ensure each surveillance camera is of good image quality and correct field of view. To minimize the efforts of system administrators, we have built a map-based web application which enables users to easily bring up live video feeds as well as locating the abnormal surveillance cameras with broken connection. In addition to hardware failure, we also adopted the image-based approach [15] to automatically detect camera anomaly events such as spray painting, blockage and defocusing.",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
KVM consists in creating a VM environment handled by the Linux kernel. It is included in the official stable Linux kernel releases since version 2.6.20 and is realized by adding support for the IntelVT and AMD-V virtualization hardware.,https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"The use of hybrid architecture can provide better services for mobile users, but also inevitably brings the problem of high complexity. So how to simplify the cooperation between heterogeneous cloud architecture remains to be further studied.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"We differentiate two types of state. Session state is the state of a user's interaction with an application - for example, a shopping basket in an online shop. Application state is the data an application handles, such as the customer data, the currently processed orders, and so on.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
Integrate static hardware characteristics in resource statistics to enable comparability between measurements from different hosts and allow advanced resource allocation scheduling.,https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"The capability provided to the consumer is to use the provider's applications running on a cloud infrastructure and accessible from various client devices through a thin client interface such as a Web browser (e.g., web-based email).",https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
Lesser delay to fine-tune means higher degree of elasticity. Modeled under provisioning penalty to penalize CSP and over provisioning penalty not lets the consumer pay for over-provisioned resources (provisioned but not utilized). Total Penalty is the combined measure of both under and over provisioning.,https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"Data security audits can provide this confidence. Data has various characteristics, such as integrity, which implies that only authorized users can change the data, and confidentiality, which means that only authorized users can read it.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"To validate our proposed idea, we conducted the experiments using real device. Java platform. In the experiment, the Nokia boost Mobile-Microsoft Lumia 635 4GW is chosen. The device is initially connected with cloud computing. The end user that uses device and communicating with another user. We used existing database designed for making emergency calls. Once communicating device losses the network coverage and having no internet to reach at the device, then our proposed method is applied and compared with Location tracking in a Wireless Sensor Network (LTWSN)[9] and Location-Based Overlapping Mobility-Aware Network Model (LOMNM) [10].",https://doi.org/10.1109/MobileCloud.2017.29,Mobile-Based Location Tracking without Internet Connectivity Using Cloud Computing Environment,12 June 2017,0
"Another practical issue is on how fit it is for blockchain to store healthcare data. Blockchain was originally designed to record transaction data, which is relatively small in size and linear. In other words, one only concerns itself about whether the current transaction can be traced backwards to the original “deal”. Healthcare data, such as imaging and treatment plans, however, can be large and relational that requires searching. How well blockchain storage can cope with both requirements is currently unclear.",10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
HyperV is a hypervisor-based virtualization system for x86-64 systems. It provides a foundational virtualization platform that enables users to transit to the Cloud. It is considered as a para-virtualization solution.,https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"An infrastructure [4], [11], [14] that allows truly pervasive computation using sensors as interface between physical and cyber worlds, the data-compute clusters as the cyber backbone and the internet as the communication medium.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"In recent years, the advance in virtualization is being driving the evolution of networking technologies. Even though the performance issues of the virtualized software are a matter of concern, virtualization technology is widely accepted by a large mass.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
The immense power of the cloud can only be fully exploited if it is seamlessly integrated into our physical lives.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"The major challenge in virtualized client-server interaction is its performance degradation, due to packet loss from a remote server. This major challenge can be addressed by introducing dedicated cloud terminals between virtual client and server.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"Cloud resource management and reallocation of workloads in general is a very intensively researched field, like in [9] or for cloud resource management with forecasting and profiling in [10].",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
Sensor Type Identification The sensor type identification scheme builds upon the mime-type support already present in the mobile application programming model. All sensors are identified using a basic mime-type of application/vnd.sensor.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Finally, the refined functional components must be assigned to tiers - for example, virtual servers. In this scope, we must consider the following pattern. With a multi-component image, virtual servers host multiple application components that might not be active at all times to reduce provisioning and decommissioning operations.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"The three primary macroscopic architectures are: (i) Data Center Model, (ii) Traditional supercomputers and, (iii) Clusters (with virtualization) such as those represented by NSF Comet.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
The vehicle can make a cloud autonomously while moving or idle. Any number of vehicles within the range formed the local cloud to exchange the information and necessary information on the local cloud must also be stored on the global cloud.,https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"However, at the simplest possible level, the basic economics of cloud computing can be boiled down to a few simple factors.4 The first is the unit cost of particular IT resources such as compute, storage, and networking for an enterprise's own internal IT capability vs. one or more cloud providers. Every situation is unique, but a rule of thumb is that smaller IT shops can't achieve the economies of scale and the ability to “amortize” investments such as custom orchestration and tooling across a large enough base to achieve unit cost advantages over public cloud providers; whereas large, capable organizations may well be able to achieve unit cost advantages.",10.1109/MCC.2017.13,The Economics of the Hybrid Multicloud Fog,15 March 2017,0
"However, to support group networks in the SIoT, network resources need more flexible and scalable methodologies. In a typical IoT structure, the devices are usually first connected to sink nodes or other aggregators, and then connected to the radio access network (RAN). Because network flows from massive devices are transferred in the same RAN, the existing RAN structure can't handle the division of network resources for distinct SIoT groups. Network virtualization provides an independent virtual RAN (vRAN) for each SIoT group connecting to the same network.4 Some forward-looking work proposes solutions that implement network virtualization in RANs. However, in existing RAN virtualization, base station virtualization and core network virtualization are two separate components. Because devices have different features, managing cooperation of two virtualized components is difficult.",10.1109/MCC.2015.114,Radio Access Network Virtualization for the Social Internet of Things,2 February 2016,0
"Seamlessly couples the physical environment with the digital world. Sensor nodes are small, low power, low cost, and provide multiple functionalities, such as, Sensing capability, processing power, memory, communication bandwidth, and battery power.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"In order to meet the requirements of future science applications, there must be a greater/richer set of analysis-as-a-service than currently available. Future analysis and associated middleware must utilize traditional performance capabilities, yet expose fundamentally new capabilities. Thus a prudent, if not only approach, is to (re-)design the software stack for analysis.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Rather than collecting data from individual sensors for every given query, sensors can be made to store their data in the network for point retrieval at a later time",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
By enabling virtual machine migration to balance load across the data centre we can be provided significant benefits in cloud computing via virtualization. By machine migration we can avoid hotspots. But detecting workload hotspots and initiating a migration lacks the ability to respond to sudden workload changes.,https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"In realistic environments, there exist more complicated application scenarios, such as migrating VM due to re-source preemption, which may lead to dynamic changes in reliability parameters of the host server",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
It's very challenging to scale sensor networks to large sizes. Operate in separate silos. Sensor data cannot be easily shared by different group of users.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"The employees of cloud service provider have complete access to the data being stored on cloud because the cloud does not maintain any security policy for the insiders. So, the possibility is more for them to view the customer's sensitive data.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"Today, we live in a digital universe in which information and technology are not only around us but also play important roles in dictating the quality of our lives. As we delve deeper into this digital universe, we're witnessing explosive growth in the variety, velocity, and volume of data[1],[2] being transmitted over the Internet. A zetabyte of data passed through the Internet in the past year; IDC predicts that this digital universe will explode to an unimaginable eight Zbytes by 2015. These data are and will be generated mainly from Internet search, social media, mobile devices, the Internet of Things, business transactions, next-generation radio astronomy telescopes, high-energy physics synchrotron, and content distribution. Government and business organizations are now overflowing with data, easily aggregating to terabytes or even petabytes of information.",10.1109/MCC.2014.22,Streaming Big Data Processing in Datacenter Clouds,10 July 2014,0
"These user interface and processing components must now communicate with each other. Message-oriented middleware provides asynchronous communication while hiding the complexity of addressing, routing, or data formats to make interaction robust and flexible.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Future platforms be usable by applications from both ends of the spectrum: traditional HPC applications that need Big Data (“All Exascale Applications are data-intensive problems“), as well as data-intensive applications that will increasingly need HPC (e.g., Deep Learning with HPC capabilities). Given the current separation of characteristics of HPC and data-intensive applications this requires a convergence of capabilities.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"The Web front-end server consists of three modules: the web portal, the scheduler, and the schedule database. Web portal provides the user and the management interfaces for virtual environment administration and reservation. Scheduler checks whether any hardware server is preloaded with the image requested by the user.",https://doi.org/10.1109/CCAA.2015.7148478,Virtual computing lab (VCL) open cloud deployment,6 July 2015,0
"Cloud is used for processing batch workloads to the web application and e-commerce transactions. Such applications expect fine-grained on demand elastic resource provisioning as a key property from the cloud. Schulte et al. proposed an architecture for eBPMS (elastic business process management system)[14], which addresses challenges on infrastructure, such as state management, resource allocation, process monitoring, scheduling and decentralized coordination.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
We are planned to propose the prototype by using Kalman filter algorithm to get the user location information. This approach was tested with systems for tracking the user location. It also outperforms as the traditional tracking methods. It also provides with an alternative to Costas Loop and DLL (Delay Lock Loop). The task of tracking with different PRN sequence is handled by EKF (Extended Kalman Filters),https://doi.org/10.1109/MobileCloud.2017.29,Mobile-Based Location Tracking without Internet Connectivity Using Cloud Computing Environment,12 June 2017,0
Sensor Selection and Communication Channel Identification The sensor selection and communication channel identification is built on the URI handling system already present in the mobile programming model.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Context ageent module answer for support client and coordinate manage the auto startup serivce of the large scale clusters. Besides, it also provide personal virtual machine services and can run both on nimbus cloud platform as well as EC2 through the backend service of EC2.",https://doi.org/10.1109/ISISE.2009.94,Comparison of Several Cloud Computing Platforms,15 April 2010,0
"Energy inefficiencies due to redundant data collection, central point of failure, hot spots near root, has to collect data at the highest frequency for all potential queries and all the time",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
It must allow easy integration of public and private clouds and allow HPC and cloud approaches to run well and run together,https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Acquisition of data feeds from numerous physical area (city, home, waterways, etc.) and wide area (water quality, weather monitoring, traffic signal, etc.) sensor networks in real time.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
Resource allocation is concerned with the physical cloud resources such as the CPU resources required to execute HMH tasks that use PSM storage requirements for domain models. Virtual machines instances required completing optimization problem tasks Pricing allocation uses the commitment models described earlier and pricing reasoning resources which broker resources with cloud providers.,https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"The I/O facility in existing method of client server virtualization involves the use of I/O operation of TCP for individual files when an operating system is to be downloaded from the server to the client. This creates a bottleneck for the client, mainly when the server sits apart and also if there is fairly high packet loss in the interaction.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
Reduce the need for duplicate monitoring systems on physical and virtual level but support monitoring as a service for customers. The challenges to be solved for this goal are many fold.,https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
Cloud message widowing will be done in order to reduce the delay for the first request from the client. Downloading individual files for both the computing environment and the operating system and then making it as an image is an extremely time consuming task.,https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"cloud applications could wait for feasible conditions, such as low utilization of resources or a reduced resource price to process requests. Of course, the coffee shop and cloud applications must both consider the assured service level for this delayed processing.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Modern smartphones have a variety of in-built sensors to detect, for example, movement, orientation, rotation, proximity, temperature and magnetic fields. The camera, the most widely used sensor on a phone, allows a device to “see” the outside world, while the microphone lets the device “hear.”",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
It is used to maximize resource utilization while minimizing energy. Virtual machine technology is used to consolidate virtual machines running on various under-utilized servers onto a single server for energy-saving. The problem of optimally consolidating servers in a data centre is NP-hard optimization problem [6].,https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
Phantom Flooding Phantom flooding shares the same insights as probabilistic flooding in that they both attempt to direct messages to different locations of the network so that the adversary cannot receive a steady stream of messages to track the source.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"It must allow the powerful features of modern clouds such as ABDS, XaaS to be useable on HPC hardware",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Sensors may use different communication channels to interact with the blackberry device: the nominal default communication channel is Bluetooth, but it is entirely possible to model internal",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"The motivation for cloud monitoring depends on the viewpoint, if physical or virtual level is considered, but can be combined due to similarities. Solely the cloud customers have restricted views on their virtual infrastructure.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"The ability to “hear” is further facilitated by any of the four wireless sensors (cell tower, Wi-Fi, Bluetooth, and GPS). Considering these communication devices as sensors naturally leads to methods of determining context, and providing an overall “sense” of the world around the device.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"With the batch processing component, requests are delayed until environmental conditions make their processing feasible.2 This component waits to handle processing requests from the request queue, much like the barista making frozen coffee might wait for multiple similar orders to come in to fill up the blender, thus reducing the overall processing time compared to making each frozen coffee individually.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
Flooding with Fake Messages This observation suggests that one approach to alleviate the risk of source-location privacy breaching is to augment the flooding protocols to introduce more sources that inject fake messages into the network.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"In mobile Ad hoc cloud model, how to encourage users to act as resource providers is a problem [19]. Yousafzai et al. proposed a directory-based approach to evaluate rewards and punishments for mobile devices [20]. This approach could encourage users to share their own resources, but would lead to resource management, privacy protection, security and other issues, so the incentive mechanism remains to be further studied.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
"Nowadays, cloud computing is used for solving many problems of wider scope and greater depth. It has given new avenues for performance as several companies and products finds newer ways to cut cost and improve productivity in the process.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"Virtual machine is the emulating software, which emulates a physical computing environment where in an operating system or a program can be installed and executed. Usually, virtual machines are deployed within a virtualization layer that runs over other operating system (OS), generally called as the host OS. Thus, many individual and independent virtual computing environments (i.e., guest OS) can be deployed on top of the host OS using a single virtualization layer.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"Detecting anomalies like failures in hardware or software, or unusual load from attacks lead to automated or manual interactions with data centre to react to irregular situations.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
It should support modern workflow and portals including Python based front ends; an area where simulations and Big Data have similar requirements.,https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"The strong data integrity feature of blockchain results in immutability that any data, once stored in blockchain, cannot be altered or deleted. However, if the record is healthcare data, then such personal data would come under the protection of privacy laws, many of them would not allow personal data to be kept perpetually—Article 17 of the soon-enforceable General Data Protection Regulation in the EU has strengthened the rights of individuals to request personal data to be erased. One of the principles of the Organization for Economic Cooperation and Development privacy guideline, on which many data protection laws are based, provides the right-to-erasure to individuals. Given the sensitivity of healthcare data, anyone planning to use blockchain to store them cannot ignore this legal obligation to erase personal data if warranted.",10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
"At the risk of sounding ironic, another limitation to using the cloud is the speed of light. As long as we rely on fiber-optic cables, we're limited by network speed (unfortunately, the speed of light isn't amenable to the kind of speed improvements associated with Moore's law).",https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
Hybrid Clouds are a combination of public and private cloud offerings that allow for transitive information exchange and possibly application compatibility and portability across disparate Cloud service offerings and providers utilizing standard or proprietary methodologies regardless of ownership or location.,https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"Probabilistic Flooding in probabilistic flooding, only a subset of nodes within the entire network will participate in data forwarding, while the others simply discard the messages they receive.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
Processing component. Elastically scaled components handle processing functionality. Functionality is made configurable to support different customer requirements.,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Monitor and Eavesdropping This is the most obvious attack to privacy. By listening to the data, the adversary could easily discover the communication contents.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"In mobile cloud network, each cell uses different frequency. This is to avoid unwanted interference and provide assured bandwidth for calling. Transceiver is one of the main components used in mobile network [6]. It functions as both transmitter and receiver.",https://doi.org/10.1109/MobileCloud.2017.29,Mobile-Based Location Tracking without Internet Connectivity Using Cloud Computing Environment,12 June 2017,0
"Proactive fault tolerance for HPC with xen virtualization has been proposed [6]. Processes are migrated from unhealthy nodes to healthy nodes based on failure predictor. In a system of high complexity such as cloud HPC system, it is quite difficult to predict all failures.",https://doi.org/10.1109/CCGrid.2012.80,A Fault Tolerance Framework for High Performance Computing in Cloud,14 June 2012,0
"The resource pool over which VMs run in cuCloud is not dedicated but shared with native users/tasks. We need to devise a mechanism to provide cloud services reliably and efficiently, while keeping the services from interfering with the native users/tasks at member nodes.",https://doi.org/10.1109/CLOUD.2017.99,"A ""No Data Center"" Solution to Cloud Computing",11 September 2017,0
"On average, about 80% of the invested time goes into assembling the right data to prepare for analysis and gathering resources for data processing from various resources due its diverse nature.",https://doi.org/10.1109/CLOUD.2010.80,Cloud Computing Infrastructure for Biological Echo-Systems,26 August 2010,0
"Sensor device and sensor network technologies will be presented along with their key applications onto smart buildings, home energy management systems, intelligent city transportation systems, urban precision agriculture, city environment, etc.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"User interface component. Customizable synchronous user interfaces are accessed by humans, whereas application - internal interaction is realized asynchronously to ensure loose coupling.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Baseline Flooding In the baseline implementation of flooding, every node in the network only forwards a message once, and no node retransmits a message that it has previously transmitted. When a message reaches an intermediate node, the node first checks whether it has received and forwarded that message before.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"To make a review on elasticity and energy efficiency on the cloud, we had collected numerous papers from different journals, magazines and conference proceedings. We concentrated more on problems and issues than the work of the articles. The main impact of such work is to provide the readers regarding ideas on current issues in the domain and motivate the research to provide solutions.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"The virtualization layer typically manages the requests arising from the VMs for resources, such as CPU, memory, network and other hardware resources, by translating these requests to the underlying physical hardware.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"Sensors networks in general pose considerable technical problems in data processing, communication, and sensor management. We cannot deploy such a critical technology, however, without first addressing the security and privacy research challenges to ensure that it does not turn against those whom it is meant to benefit",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"The cloud monitoring is necessary in this case to first measure and profile the system state defined as normal, to second compare the most recent state with this ideally automatically generated normal state.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"This study is based on VMX server and VMware cloud foundry, which is already gaining attention from various open source and cloud companies. The random arrival of load in a cloud server environment can cause some server to be heavily loaded while other server is idle or only lightly loaded [3]. So, the experts believe that cloud foundry has not offered robust service hence had shown two serious outages recently.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"Independent of the directionality, the future platform will be a software-defined system that works across different types of macroscopic and microscopic architectures as well as for different applications systems.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"The experimentation was carried out using CloudSim 5.0 Simulator considering heterogeneous environment. We have considered 4 types of VM instances with various processing capabilities. The algorithm is compared with other existing heuristics Max-Min, Min-Min, FCFS and MCT algorithms. Other factors like the bandwidth, memory, processing elements, storage and e.c.t are the same for all the instances",https://doi.org/10.1109/SmartCloud49737.2020.00015,An Efficient Task Scheduling Algorithm using Total Resource Execution Time Aware Algorithm in Cloud Computing,27 November 2020,0
"To preserve data integrity and security, cloud providers must provide secure access. This improves data management license, certification, and other factors. Many users in the cloud computing environment are dealing with dynamic responses to dynamically changing services.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
In examining the related work it can be seen that a number of pricing ontology and cloud ontology are being developed as addenda to cloud requirements and system specification. An approach that embeds pricing and other aspects into a single approach will reduce effort spent on cloud specification and ontology maintenance effort.,https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"Taking into consideration the proposed approach, we use cell phone as the base device to communicate the user location. Here, we use cloud network to identify the special type of calls which were made around the circle by the user and divert it to the right direction.",https://doi.org/10.1109/MobileCloud.2017.29,Mobile-Based Location Tracking without Internet Connectivity Using Cloud Computing Environment,12 June 2017,0
"OpenVZ is an OS-level produced by Virtuozzo. It is claimed to be highly scalable with strong isolation between containers. The OpenVZ team is contributing to Linux kernel and works by limiting the number of resources (memory, shares of the processor, etc.)",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
Eventual consistency. Performance and data availability during network partitioning are enabled by ensuring data consistency eventually and not at all times.,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Distributed database systems for TSDBs follow the NoSQL movement, while defining an extended key-value store. The key consists of the time stamp and optionally additional tags. Different metrics are hosted within buckets, to differentiate different time streams of key-value items.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Based on flooding-based routing protocols, Ozturk et al. have developed comparable methods for single path routing to try to solve the privacy problems in sensor network.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Simple examples for alerting systems are reading the most current measurement of resources and compare them with static thresholds (e.g. disk space, cpu utilisation).",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Multiple sensor data sets used for decision making may or may not be collocated. If these data sets and their corresponding access/search services are geographically distributed, the allocation of computational and storage and data migration become critical challenges.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"This algorithm is derived from honeybee foraging algorithm. It adapts the behavioral of honey bees for finding and bringing food [4]. This algorithm is based on the behavior of honey bee which forage (search widely for food). When the honey bee finds one location of food, it comes back to the beehive to inform this using a waggle dance.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"Strict consistency. Data is stored at different locations to improve response times and avoid loss in case of failures, while replica consistency is ensured at all times.",https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"We have highlighted the importance of the Big Data systems associated with Apache Foundation, such as Hbase, Hadoop, Spark, Storm etc., which we term the Apache Big Data Stack (ABDS), even though important components such as MongoDB and Tensorflow are not Apache projects.",https://doi.org/10.1109/CLOUD.2017.120,"Conceptualizing a Computing Platform for Science Beyond 2020: To Cloudify HPC, or HPCify Clouds?",11 September 2017,0
"Cloud data centers are comprised of a substantial quantity of rows containing servers that consume electricity. These servers are equipped with network, storage, and power supply systems, as well as heating, ventilation, and air conditioning equipment to prevent overheating. Nevertheless, despite the seeming cleanliness of these data centers, they do not actively contribute to the green initiative.",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"In this paper, we presented City Eyes, a cloud based platform designed for building intelligent video surveillance applications. The main innovation of City Eyes is a general framework which facilitates the development and deployment of video analysis engines. A suite of IVS applications have been built upon the proposed platform and it has been proven to be very useful for real-world practices of video surveillance.",https://doi.org/10.1109/iThings.2014.59,City Eyes: An Unified Computational Framework for Intelligent Video Surveillance in Cloud Environment,16 March 2015,0
"VMware is the global leader in virtual infrastructure technology, helping large and small organizations to increase the efficiency and cost-effectiveness of their IT operations. Using a VMware virtualization solution enables to transform the hardware resources of an x86-based computer to create a fully functional virtual machine.",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
Myles and colleagues [25] describe Architecture for a centralized location server that controls access from client applications through a set of validator modules that check XML/JSON-encoded application privacy policies.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"More complex systems replace the static threshold by computed values or metric correlations from historic monitoring measurements [13], [14].",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
Stateless component. State is handled external to application components to ease their scaling-out and make the application more tolerant to component failures.,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
"Doing this cost modeling is fairly complex as you have to account for everything mentioned above. Not every service will get the results shown in the table. If your function executes faster, you'll pay less per hit for serverless (up to the granularity of the billing increment) because the compute time charge will be lower, but if you get more hits per second, it adds up fast. Given the potential annual cost difference, it's smart to invest a few hours—or even months—modeling and testing execution time and understanding the financial implications.",https://doi.org/10.1109/MCC.2017.32,"Be Wary of the Economics of ""Serverless"" Cloud Computing",26 April 2017,0
"Welcome to the inaugural Blue Skies column of IEEE's flagship cloud computing magazine. This column intends to provide an in-depth analysis of the most recent and influential research related to cloud technologies and innovations, focusing on streaming big data processing in datacenter clouds.",10.1109/MCC.2014.22,Streaming Big Data Processing in Datacenter Clouds,10 July 2014,0
"The privacy and security issues posed by sensor networks represent a rich field of research problems. Improving network hardware and software may address many of the issues, but others will require new supporting technologies.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"The paradigm of cloud computing assumes an elastic resource allocation, where the actually required resources are allocated by customers. On virtual level, cloud orchestration tools manually triggered by an administrator or automatically from monitoring data adapts virtual resources at runtime.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"The asynchronous elevated load in the cloud terminals is a matter of concern when it deals with large ‘software as service’ infrastructure, like virtual computing infrastructure. For typical Cloud Computing Infrastructure, downloading may consume comparatively more load than Virtual Storage Infrastructure.",https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"Snekkenes [24] presents advanced concepts for specifying policies in the context of a mobile phone network. These concepts enable access control based on criteria such as time of the request, location, speed, and identity of the located object.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"The main objective of IAM is to ensure secure access to cloud resources. The main aspects related to IAM are auditing, authentication, and authorization. Authentication procedure checks the users identity before allowing access to any resource. There are different access policies defined that need to be followed to gain access. Authorization process verifies that whether the user has necessary credentials to any action or not. Authentication process verifies who is accessing the resource and authorization verifies what actions are allowed.",https://doi.org/10.1109/I-SMAC47947.2019.9032545,"A Survey of Cloud Computing Security Challenges, Issues and their Countermeasures",12 March 2020,0
"Many works in literature have surveyed Cloud properties, features, underlying technologies, security, and privacy. However, to the best of our knowledge, the literature lacks a detailed analysis of state of the art support for elastic properties of a Cloud for its energy efficiency. To address this gap, in this survey we provide future guidelines to address such problems.",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"For this approach, we have a plan of tracking the user location even if they are located in non-network cloud accessible area. This can be done via SOS call service which will use any network located in the area by which we can get the location details. We don't face any issues with good network coverage. We can use any third-party application to track the location. Our plan is to get the user location that is not under proper or no network coverage area.",https://doi.org/10.1109/MobileCloud.2017.29,Mobile-Based Location Tracking without Internet Connectivity Using Cloud Computing Environment,12 June 2017,0
"In the SIoT, a network is usually divided into distinct groups to control the degree of interaction among things that are friends. Further, the scalability of network groups is guaranteed similarly to human social networks.2 Cloud computing is a potential solution for supporting scalable groups in the SIoT because the computing capability can be divided and distinguished among social networks.3",10.1109/MCC.2015.114,Radio Access Network Virtualization for the Social Internet of Things,2 February 2016,0
"When working in the cloud, users are uninformed of the location of their data and have no idea which server is processing it. Because of the system's versatility, customers have no idea from which network these services or data are being transmitted. As a result, the user cannot protect data privacy in the cloud on their own. The cloud provider can divide the data centre into zones, and data can be stored on any node in any zone.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"The scope of parallel algorithm design is quite limited, and its use in power system data processing is not sufficiently extensive. Nevertheless, as the power system becomes more digitized and power data is increasingly quantified, the utilization of data mining technologies is progressively broadening. Parallel algorithms can be developed in several dimensions to optimize data processing efficiency and facilitate comprehensive power system production and dispatching.",https://doi.org/10.1109/ICAC3N60023.2023.10541395,A Survey on Energy efficiency in Cloud Computing Frameworks at Different Platforms,5 June 2024,0
"There has been recent interest in utilizing blockchain (made popular by the successful Bitcoin) in the provision of secure healthcare data management.18, 19, 20 Broadly speaking, blockchain is a technology able to build an open and distributed online database, which consists a list of data structures (also known as blocks) that are linked with each other (i.e. a block points to the following one, hence the name blockchain). These blocks are distributed among multiple nodes of an infrastructure, and are not centrally stored. Each block contains a timestamp of its production, the hash of the previous block and the transaction data, and in our context, a patient's healthcare data and the healthcare provider information.",10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0
Mobile cloud computing is poised to become a huge market. That huge market will attract the attention of criminals who want to make an easy profit by finding and exploiting weaknesses in mobile cloud ecosystems.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Total anonymity is a difficult problem given the lack of knowledge concerning a node's location. Therefore, a tradeoff is required between anonymity and the need for public information when solving the privacy problem.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"The organisational environment is a vital factor to define institutional structure and actions as institutional theory states [14], [15]. Institutional theory is a common theory used in a number of research studies for examining IT adoption. This theory includes new and important factors in the environmental element of the TOE framework.",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
"Cloud computing is a key supporting technology driving the fourth industrial revolution, spanning from the Internet of Things (IoT) and Cloud for Telecoms (C4T) to Industry 4.0 to Smart Cities. This pervasiveness of cloud technology is due to its ability to easily share and obtain resources on a pay-peruse and elastic provisioning model.",https://doi.org/10.1109/MCC.2018.032591614,Cloud Reliability: Possible Sources of Security and Legal Issues?,12 June 2018,0
"The concept of private authentication, and give a general scheme for building private authentication with work logarithmic in the number of tags in (but not limited by) RFID (radio frequency identification) applications.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Similarly the resource allocation for service providers is aware of placement decisions and schedules virtual resources on physical resources [15], [16]. Overbooking is a static or ideally a dynamic factor in solving this bin pack problem.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
The conclusion is that the asynchronous increasing load in the cloud computing terminal may be reduced when it incorporates the windowing strategy for image creation and honey bee foraging technique for downloading the image in scheduled manner.,https://doi.org/10.1109/CCAA.2017.8229996,Efficient distribution of virtual machines using Honey bee windowing in cloud computing,21 December 2017,0
"Decentralize Sensitive Data the basic idea of this approach is to distribute the sensed location data through a spanning tree, so that no single node holds a complete view of the original data.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"For implementing security and cyber investigation at the cloud is very difficult as different types of challenges are faced due to virtualization. Data hiding is one of the important part for the forensic analysis process and it is performed for various reasons like malware attacks, or offender hides useful information in his personal computer [16]. One of the method of hiding data is ADS (Alternate Data Streams).",https://doi.org/10.1109/I2CT.2018.8529806,Approaches for Detection of Digital Evidence in Cloud Computing Environment,11 November 2018,0
One possible trend is incorporation of hypervisors into smartphones. A hypervisor is a program that allows multiple operating systems to share a single computer. This development is intended to simplify smartphone management problems. It also has potential to simplify security management.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"The RRDTool stores resource statistics in binary files and provides functionalities to add and retrieve measurements. RRD files have a maximum file size in its metadata, which allows the RRDTool to automatically aggregate and reduce historic data",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
Stateful component. Multiple instances of a scaled-out application component synchronize their internal state to provide a unified behavior.,https://doi.org/10.1109/MIC.2014.101,Your Coffee Shop Uses Cloud Computing,28 August 2014,0
The idea on cloud based location tracking makes the usage range and measurement of network system. It was analyzed and the probability of rectifying only two range system [4]. Location tracking of the user was via mobile cloud network and in later stages via GPS service was addressed as privacy issues. And also illustrates the user privacy while tracking their location without their knowledge,https://doi.org/10.1109/MobileCloud.2017.29,Mobile-Based Location Tracking without Internet Connectivity Using Cloud Computing Environment,12 June 2017,0
It has been projected that 53% of total data center operational cost is used for powering and cooling [2]. A key challenge is to maintain a balance between application performance and energy savings.,https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"There are a variety of security risks with cloud computing due to the fact that it incorporates a wide range of technologies such as networks and databases, as well as operating systems, virtualization, and resource scheduling. Furthermore, the virtualization paradigm introduces new security concerns as a result of cloud computing.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"Currently, there are kinds of cloud computing platforms, each has its own characteristics and advantages. To better understand these platforms, we analyze in detail and give a comparison from different implementation aspects.",https://doi.org/10.1109/ISISE.2009.94,Comparison of Several Cloud Computing Platforms,15 April 2010,0
"DOUG also needs high speed connections between the nodes. Since the SciCloud instances are running on a single cluster, network latency is acceptable. To prove this, we experimentally measured performance latencies for several scientific computing tasks run on clusters and cloud nodes.",https://doi.org/10.1109/CCGRID.2010.56,SciCloud: Scientific Computing on the Cloud,24 June 2010,0
"It is crucial to investigate cloud resiliency and ensure that we have the means to provide a suitable level of resiliency to avoid potential Service Level Agreement (SLA) violations. In fact, cloud outages have an impact on enterprise workloads or popular consumer applications.",https://doi.org/10.1109/MCC.2018.032591614,Cloud Reliability: Possible Sources of Security and Legal Issues?,12 June 2018,0
Another trend is the growth of what is known as the Internet of Things. The growth in intelligent devices that are able to interact with the Internet is growing at a much greater rate than traditional computer technology.,https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"While the collectors presented in IV-Bare parts close to the system under observation, the actual handling of the retrieved monitoring data is handled by additional open source or commercial software systems.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"Resiliency can be defined as the ability of a system to keep its application running by keeping the right level of quality, despite any unexpected variations in the working conditions, such as applied workload, experienced fault load, or successful attacks.",https://doi.org/10.1109/MCC.2018.032591614,Cloud Reliability: Possible Sources of Security and Legal Issues?,12 June 2018,0
"Secure Communication Channel using secure communication protocols, such as SPINS [65], the eavesdropping and active attacks can be prevented.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Finally the visualization is relevant for end users on both levels, the cloud service providers and the cloud customers. The visualization helps administrators, consultants or developers to analyse the resource utilisation very quickly by analysing charts and diagrams [12].",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"With organizations moving to the cloud, especially for military defense, it is imperative to minimize some of the disruption, low performance, and availability. Therefore, it is important to ensure that the cloud platforms have the means to tolerate such faults.",https://doi.org/10.1109/MCC.2018.032591614,Cloud Reliability: Possible Sources of Security and Legal Issues?,12 June 2018,0
"Mobility - Mobile devices are being increasingly used for access to corporate data and smart environment. So, it's necessary to improve sensor enabled mobile OS in the following aspect",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Collectors for monitoring resource statistics exist and new ones appear frequently as open source or as commercial software. While traditional software exists for years, the approach for collecting resource statistics is changing from complete monitoring suites to pluggable collectors.",https://doi.org/10.1109/CLOUD.2018.00093,Reviewing Cloud Monitoring: Towards Cloud Resource Profiling,11 September 2018,0
"As wireless sensor networks continue to grow and become more common, we expect that further expectations of security will be required of these wireless sensor network applications. In particular, the addition of mobile sensing and sensor cloud computing services will likely make strong security a more realistic expectation in the future",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Node Mobility making the sensor movable can be effective in-defending privacy, especially the location. For example, the Cricket system [67] is a location-support system for in-building, mobile, location dependent applications.",https://doi.org/10.1109/CSA.2013.166,Mobile Sensor Cloud Computing: Controlling and Securing Data Processing over Smart Environment through Mobile Sensor Cloud Computing (MSCC),19 June 2014,0
"Virtualization allows Cloud service provider (CSP) to allocate a movable virtual resource, which is a part of the actual physical machine. Virtual resource migration enhances precise resource provisioning on-demand[3] [4]. Effective elastic cloud resource provisioning is an old research problem, still yet to be addressed[5].",https://doi.org/10.1109/ICPCSI.2017.8391816,The role of cloud computing infrastructure elasticity in energy efficient management of datacenters,21 June 2018,0
"The effectiveness of fine-grained controls has not been resolved so far. In the recent development, mobile app developers for iOS or Android designed in such a way to prompt a pop-up get permission from users to get the location service access.",https://doi.org/10.1109/MobileCloud.2017.29,Mobile-Based Location Tracking without Internet Connectivity Using Cloud Computing Environment,12 June 2017,0
Another problem is the lack of well-defined service-level agreements (SLAs) by cloud providers. What's the guaranteed uptime? What are the repercussions if the provider fails to meet these standards? What happens to customer data if the company moves to a different provider?,https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
"The pricing ontology is expressed as a problem solving ontology and therefore a common representation of problem solving and pricing is achieved, in effect pricing is another problem to be solved. This approach has a number of advantages. A common ontology and set of reasoning resources can be developed and there is no need for separate designs and software development.",https://doi.org/10.1109/CloudCom.2013.139,Pricing Intelligence as a Service for Cloud Computing,6 March 2014,0
"The API (Application Programming Interface) for the cloud services can be accessed from anywhere using the Internet. Hence, the possibility is more for the malicious attackers to defeat the confidentiality of the cloud services. They can use the authentication token for accessing the API and manipulate other user's data.",https://doi.org/10.1109/ICIPTM54933.2022.9753956,Scalable and Adaptable End-To-End Collection and Analysis of Cloud Computing Security Data: Towards End-To-End Security in Cloud Computing Systems,18 April 2022,0
"Unit cost doesn't tell the whole story, though, because another important factor is demand variability. Paying a thousand dollars a night for a hotel room during a once-in-a-lifetime trip to Paris or Manhattan may be expensive, but it's a lot less than building a house there. In other words, high unit costs under a pay-per-use pricing scheme can still lead to a lower total cost under conditions of variable demand. Consequently, to handle variable demand, a public cloud provider offering pay-per-use resources may be the only strategy required.",10.1109/MCC.2017.13,The Economics of the Hybrid Multicloud Fog,15 March 2017,0
"The Internet of Things (IoT) is rapidly gaining ground in modern wireless telecommunications.1 In addition, through unique addressing schemes and standard communication protocols, users can interact and cooperate with people they've formed social relationships with. As the IoT and social networks converge, the social IoT (SIoT) paradigm will improve the quality of everyday life with interconnected intelligent objects.",10.1109/MCC.2015.114,Radio Access Network Virtualization for the Social Internet of Things,2 February 2016,0
Cloud service providers virtual machine technology does not have access to the physical safety system of data centers; they must rely on the infrastructure provider to attain full data security [7].,https://doi.org/10.1109/CCAA.2015.7148468,Study on cloud computing and cloud database,6 July 2015,0
"VirtualBox, originally developed by Microsoft, supports para-virtualized drivers inside the guest OS in order to access hardware more efficiently.",https://doi.org/10.1109/NCCA.2011.28,A Comparative Study of the Current Cloud Computing Technologies and Offers,9 January 2012,0
"The project mainly targets the development of a framework, including models and methods for establishment, proper selection, state management (managing running state and data), auto scaling and interoperability of the private clouds.",https://doi.org/10.1109/CCGRID.2010.56,SciCloud: Scientific Computing on the Cloud,24 June 2010,0
Vehicular cloud provides trust management and authentication among the vehicles to build confidence on the road to exchange information with each other. This provides guarantees or trust to the vehicles that the information they received is genuine and not fake.,https://doi.org/10.1109/NGCT.2015.7375084,A survey on Vehicular Cloud Computing and its security,11 January 2016,0
"Cardellini et al. proposed a three-tier architecture for computation offloading [22]. Mobile users could autonomously decide if the computing tasks were offloaded to nearby cloudlet or remote cloud servers. However, the approach is only theoretically feasible now and has not yet been applied.",https://doi.org/10.1109/CIACT.2018.8480365,"Mobile Cloud Computing: the State of Art, Application Scenarios and Challenges",4 October 2018,0
Community Clouds are provided by a designated service provider related to a particular community and may offer either a single-tenant (dedicated) or multi-tenant (shared) operating environment with all the benefits and functionality of elasticity and the accountability/utility model of Cloud.,https://doi.org/10.1109/ICEEOT.2016.7755626,Cloud computing security analysis: Challenges and possible solutions,24 November 2016,0
"Abdollahzadehgan et al. [17] analysed only the effect of organisational factors on cloud computing adoption in small and medium size enterprises (SMEs). They identified three factors (top management support, firm size and technology readiness) using a TOE framework. These factors are very helpful for organisation to assess their situations if they want to adopt cloud, especially the SMEs.",https://doi.org/10.1109/CloudCom.2014.95,Factors Influencing an Organisation's Intention to Adopt Cloud Computing in Saudi Arabia,12 February 2015,0
The percentage of improvements in throughput is given in the IV-B. The minimum value can be observed in the workload size of 4000 tasks compared with the MCT algorithm which is 6%. The maximum value is 234% which is observed in the workload of task size of 1000 compared with the Max-Min algorithm compared. When considering the overall observations we can see that TRETA gives a significant amount of throughput improvement than other algorithms.,https://doi.org/10.1109/SmartCloud49737.2020.00015,An Efficient Task Scheduling Algorithm using Total Resource Execution Time Aware Algorithm in Cloud Computing,27 November 2020,0
"Good cloud computing adoption planning and design phase should end up with architecture blueprint, a migration roadmap, a common control framework, a security technology framework, physical safety and security, and future cloud services evolution [6].",https://doi.org/10.1109/SCAT.2014.7055151,Road map towards eco-efficient cloud computing adoption in higher learning institutions in Tanzania,5 March 2015,0
"We propose a framework that ensures that computational intensive applications with MPI implementation running on cloud HPC run smoothly. We achieve this with proactive and reactive fault tolerance techniques. In this framework we use process level redundant technique PLR, live migration and fault tolerance policy to reduce overhead introduced fault tolerance.",https://doi.org/10.1109/CCGrid.2012.80,A Fault Tolerance Framework for High Performance Computing in Cloud,14 June 2012,0
The cloud is often touted as a solution for organizations with large variations in computing demands. Less well known is the performance variability in the clouds themselves.,https://doi.org/10.1109/MIC.2010.136,Cloud Computing: The Limits of Public Clouds for Business Applications,1 November 2010,0
Therefore a strong access control framework must be implemented in cloud environment. Hence the issue of access control is considered for our further proposed research work. In which the issue of access control in the cloud environment using a cryptographic approach is to be considered. One of the most widely used approach for access control in cloud environment is Attribute based Encryption scheme. It gives a way to incorporate access policies by using cryptographic approach.,https://doi.org/10.1109/I-SMAC47947.2019.9032545,"A Survey of Cloud Computing Security Challenges, Issues and their Countermeasures",12 March 2020,0
"In addition to VCLD, a management node includes a provisioning engine, which is a deploy service environment on demand in three different layers: (a) The physical layer (Physical Deployer) (bare-machine loads are typically done using xCAT, but other loaders such as ESXi can be used); (b) The virtual layer (Virtual Deployer) (e.g., VMware, Xen, KVM); (c) New Deployer Module (adapt new resource types).",https://doi.org/10.1109/CCAA.2015.7148478,Virtual computing lab (VCL) open cloud deployment,6 July 2015,0
"Cloud users are able to execute such commands via the Interface, which in turn informs the server to instruct the ad hoc client to perform virtual machine commands via the VirtualBox API. Similarly, host users also have access to this and the regular commands of BOINC via our modified BOINC API.",https://doi.org/10.1109/CLOUD.2015.153,Ad Hoc Cloud Computing,20 August 2015,0
"Access control models have also been used to regulate and limit access to the data, based on predefined access policies.16 Such models can be particularly effective for external attacks, but are generally ineffective against internal attackers as they are likely to be authorized to access the data. There have also been approaches to integrate access control with some cryptographic primitives, such as attribute-based encryption.17",10.1109/MCC.2018.011791712,Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?,28 March 2018,0